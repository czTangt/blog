[{"categories":["reverse"],"content":"记录一下在逆向过程中常使用的算法，记录一下 python 脚本。 ","date":"2024.11.27","objectID":"/blog/posts/reverse/algorithm/:0:0","tags":["reverse","algorithm"],"title":"逆向中的算法","uri":"/blog/posts/reverse/algorithm/"},{"categories":["reverse"],"content":"base64\rfrom Crypto.Util.number import * # Base64 字符表 table = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\" def encode(data): n = bytes_to_long(data) # 转换为整数 pad = (3 - (len(data) % 3)) % 3 # 计算需要填充的字节数 n \u003c\u003c= 8 * pad # 左移填充 indices = [] # 存储 Base64 索引 while n: # 逐步取模 indices.append(n % 64) n //= 64 indices = indices[::-1] # 反转顺序 result = \"\".join([table[i] for i in indices]) # 索引映射到字符表 result += \"=\" * pad # 添加填充字符 print(result) encode(b\"flag{wecome_to_try_base64}\") 直接使用库来进行加解密 import base64 # Python3 中字符都是 unicode 编码，而 b64encode函数的参数为 byte 类型，所以必须先转码 enc = base64.b64encode(\"AlwaysBeta\".encode(\"utf-8\")) dec = base64.b64decode(enc) # 换表解密 new_table = \"ABCDEFQRSTUVWXYPGHIJKLMNOZabcdefghijklmnopqrstuvwxyz0123456789+/\" old_table = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\" cipher = \"zMXHz3TIgnxLxJhFAdtZn2fFk3lYCrtPC2l9\".swapcase() # swapcase 是大小写转化，大写转小写等 print(base64.b64decode(cipher.translate(str.maketrans(new_table, old_table)))) ","date":"2024.11.27","objectID":"/blog/posts/reverse/algorithm/:1:0","tags":["reverse","algorithm"],"title":"逆向中的算法","uri":"/blog/posts/reverse/algorithm/"},{"categories":["reverse"],"content":"RC4\rdef RC4(input, key): sbox = list(range(256)) j = 0 for i in range(256): j = (j + sbox[i] + key[i % len(key)]) % 256 sbox[i], sbox[j] = sbox[j], sbox[i] i, j = 0, 0 output = [] keystream = [] for k in range(len(input)): i = (i + 1) % 256 j = (j + sbox[i]) % 256 sbox[i], sbox[j] = sbox[j], sbox[i] keystream.append(sbox[(sbox[i] + sbox[j]) % 256]) output.append(input[k] ^ keystream[k]) return bytes(output), keystream key = b\"fun@eZ\" out = RC4(b\"Hello, world!\", key)[0] print(out) inp = RC4(out, key)[0] print(inp) ","date":"2024.11.27","objectID":"/blog/posts/reverse/algorithm/:2:0","tags":["reverse","algorithm"],"title":"逆向中的算法","uri":"/blog/posts/reverse/algorithm/"},{"categories":["reverse"],"content":"Tea 系列\r","date":"2024.11.27","objectID":"/blog/posts/reverse/algorithm/:3:0","tags":["reverse","algorithm"],"title":"逆向中的算法","uri":"/blog/posts/reverse/algorithm/"},{"categories":["reverse"],"content":"tea\rfrom ctypes import * def encrypt(rounds, v, k): v0, v1 = c_uint32(v[0]), c_uint32(v[1]) delta = 0x9E3779B9 sum = c_uint32(0) k0, k1, k2, k3 = c_uint32(k[0]), c_uint32(k[1]), c_uint32(k[2]), c_uint32(k[3]) for i in range(rounds): sum.value += delta v0.value += ((v1.value \u003c\u003c 4) + k0.value) ^ (v1.value + sum.value) ^ ((v1.value \u003e\u003e 5) + k1.value) v1.value += ((v0.value \u003c\u003c 4) + k2.value) ^ (v0.value + sum.value) ^ ((v0.value \u003e\u003e 5) + k3.value) return [v0.value, v1.value] def decrypt(rounds, v, k): v0, v1 = c_uint32(v[0]), c_uint32(v[1]) delta = 0x9E3779B9 sum = c_uint32(delta * rounds) k0, k1, k2, k3 = c_uint32(k[0]), c_uint32(k[1]), c_uint32(k[2]), c_uint32(k[3]) for i in range(rounds): v1.value -= (((v0.value \u003c\u003c 4) + k2.value) ^ (v0.value + sum.value) ^ ((v0.value \u003e\u003e 5) + k3.value)) v0.value -= (((v1.value \u003c\u003c 4) + k0.value) ^ (v1.value + sum.value) ^ ((v1.value \u003e\u003e 5) + k1.value)) sum.value -= delta return [v0.value, v1.value] v = [1, 2] k = [1, 2, 3, 4] enc = encrypt(32, v, k) print(\"%#x %#x\" % (enc[0], enc[1])) dec = decrypt(32, enc, k) print(\"%#x %#x\" % (dec[0], dec[1])) ","date":"2024.11.27","objectID":"/blog/posts/reverse/algorithm/:3:1","tags":["reverse","algorithm"],"title":"逆向中的算法","uri":"/blog/posts/reverse/algorithm/"},{"categories":["reverse"],"content":"xtea\rfrom ctypes import * def encrypt(rounds, v, k): v0, v1 = c_uint32(v[0]), c_uint32(v[1]) delta = 0x9E3779B9 sum = c_uint32(0) for i in range(rounds): v0.value += (((v1.value \u003c\u003c 4) ^ (v1.value \u003e\u003e 5)) + v1.value) ^ (sum.value + k[sum.value \u0026 3]) sum.value += delta v1.value += (((v0.value \u003c\u003c 4) ^ (v0.value \u003e\u003e 5)) + v0.value) ^ (sum.value + k[(sum.value \u003e\u003e 11) \u0026 3]) return [v0.value, v1.value] def decrypt(rounds, v, k): v0, v1 = c_uint32(v[0]), c_uint32(v[1]) delta = 0x9E3779B9 sum = c_uint32(delta * rounds) for i in range(rounds): v1.value -= (((v0.value \u003c\u003c 4) ^ (v0.value \u003e\u003e 5)) + v0.value) ^ (sum.value + k[(sum.value \u003e\u003e 11) \u0026 3]) sum.value -= delta v0.value -= (((v1.value \u003c\u003c 4) ^ (v1.value \u003e\u003e 5)) + v1.value) ^ (sum.value + k[sum.value \u0026 3]) return [v0.value, v1.value] v = [1, 2] k = [1, 2, 3, 4] enc = encrypt(32, v, k) print(\"%#x %#x\" % (enc[0], enc[1])) dec = decrypt(32, enc, k) print(\"%#x %#x\" % (dec[0], dec[1])) ","date":"2024.11.27","objectID":"/blog/posts/reverse/algorithm/:3:2","tags":["reverse","algorithm"],"title":"逆向中的算法","uri":"/blog/posts/reverse/algorithm/"},{"categories":["reverse"],"content":"xxtea\rfrom ctypes import * def MX(z, y, total, key, p, e): temp1 = (z.value \u003e\u003e 5 ^ y.value \u003c\u003c 2) + (y.value \u003e\u003e 3 ^ z.value \u003c\u003c 4) temp2 = (total.value ^ y.value) + (key[(p \u0026 3) ^ e.value] ^ z.value) return c_uint32(temp1 ^ temp2) def encrypt(n, v, key): delta = 0x9E3779B9 rounds = 6 + 52 // n total = c_uint32(0) z = c_uint32(v[n - 1]) e = c_uint32(0) while rounds \u003e 0: total.value += delta e.value = (total.value \u003e\u003e 2) \u0026 3 for p in range(n - 1): y = c_uint32(v[p + 1]) v[p] = c_uint32(v[p] + MX(z, y, total, key, p, e).value).value z.value = v[p] y = c_uint32(v[0]) v[n - 1] = c_uint32(v[n - 1] + MX(z, y, total, key, n - 1, e).value).value z.value = v[n - 1] rounds -= 1 return v def decrypt(n, v, key): delta = 0x9E3779B9 rounds = 6 + 52 // n total = c_uint32(rounds * delta) y = c_uint32(v[0]) e = c_uint32(0) while rounds \u003e 0: e.value = (total.value \u003e\u003e 2) \u0026 3 for p in range(n - 1, 0, -1): z = c_uint32(v[p - 1]) v[p] = c_uint32((v[p] - MX(z, y, total, key, p, e).value)).value y.value = v[p] z = c_uint32(v[n - 1]) v[0] = c_uint32(v[0] - MX(z, y, total, key, 0, e).value).value y.value = v[0] total.value -= delta rounds -= 1 return v v = [0x1, 0x2] k = [0x1, 0x2, 0x3, 0x4] n = 2 # 这里2为轮数，也就是 v 的个数 enc = encrypt(n, v, k) print(\"%#x %#x\" % (enc[0], enc[1])) dec = decrypt(n, enc, k) print(\"%#x %#x\" % (dec[0], dec[1])) ","date":"2024.11.27","objectID":"/blog/posts/reverse/algorithm/:3:3","tags":["reverse","algorithm"],"title":"逆向中的算法","uri":"/blog/posts/reverse/algorithm/"},{"categories":["config"],"content":"这里主要记录一下在 VsCode 中 Jupyter 的使用。 ","date":"2024.11.26","objectID":"/blog/posts/config/jupyter/:0:0","tags":["config"],"title":"Jupyter 使用","uri":"/blog/posts/config/jupyter/"},{"categories":["config"],"content":"配置环境\r我是用的就是 miniconda 环境和 VsCode。下载并配置环境之后，在 vscode 中下载插件 python 和 jupyter。之后在 settings 中输入 python path ，然后输入 miniconda -\u003e envs -\u003e python.exe 的文件位置，这样之后就会直接使用默认的 python 解释器（我猜的，还没有经过验证）。 配置 python 路径\r","date":"2024.11.26","objectID":"/blog/posts/config/jupyter/:1:0","tags":["config"],"title":"Jupyter 使用","uri":"/blog/posts/config/jupyter/"},{"categories":["config"],"content":"相关说明\r","date":"2024.11.26","objectID":"/blog/posts/config/jupyter/:2:0","tags":["config"],"title":"Jupyter 使用","uri":"/blog/posts/config/jupyter/"},{"categories":["config"],"content":"介绍\r对我来说，Jupyter Notebook 在编程时具有语法高亮、缩进、tab补全的功能。并且可以在代码块下方展示运行结果。对代码编写说明文档或语句时，支持 Markdown 语法，支持使用 LaTeX 编写数学性说明。我主要想的就是可以通过划分不同的代码块来加强代码的理解，同时还可以使用 markdown 语法来进行讲解，这个比 python 需要最后再运行强很多，我需要的就是这种划分代码段分别运行，最后还能关联在一起的效果。这里之后根据 官方指南 进行 jupyter 的讲解。 ","date":"2024.11.26","objectID":"/blog/posts/config/jupyter/:2:1","tags":["config"],"title":"Jupyter 使用","uri":"/blog/posts/config/jupyter/"},{"categories":["config"],"content":"运行细胞\r在这里，每一个代码块被称为一个 cell。要运行代码，可以在命令和编辑模式下使用键盘快捷键。要运行当前单元格，使用 Ctrl+Enter。要运行当前单元格并前进到下一个单元格，使用 Shift+Enter。之后也可以使用图形界面的选项来进行相关操作。 上文提到了命令模式和编辑模式，所以这里需要知道运行细胞存在三种个状态：未选中、命令模式和编辑模式。代码单元格和编辑器边框左侧的垂直条显示单元格的当前状态。 当没有可见的栏时，该单元格未被选中。选择单元格后，它可以处于命令模式或编辑模式 在命令模式下，单元格左侧将出现一个实心垂直条，该单元可以进行操作并接受键盘命令 在编辑模式下，单元格编辑器周围有一个实心垂直条由边框连接起来，单元格的内容可以修改 在键盘上，按 Enter 键可进入编辑模式，按 Esc 键可进入命令模式。 注意 有的主题不能呈现上述的颜色条变化，所以为了兼顾主题和 jupyter，我选择 Github Theme 中的 Complete Dark 主题，起码比较而言，它可以兼顾两者。 ","date":"2024.11.26","objectID":"/blog/posts/config/jupyter/:2:2","tags":["config"],"title":"Jupyter 使用","uri":"/blog/posts/config/jupyter/"},{"categories":["config"],"content":"快捷键\r命令模式\r快捷键 **备注 ** Enter 转入编辑模式 Shift/Alt+Enter 运行当前选定的单元格并在紧邻下方插入一个新单元格（焦点移至新单元格） Ctrl+Alt+Enter 运行当前选定的单元格 y 单元转入代码状态 m 单元转入markdown状态 up 选中上方单元 k 选中上方单元 down 选中下方单元 j 选中下方单元 a 在上方插入新单元 b 在下方插入新单元 dd 删除选中的单元 l 转换行号 Shift+Space 向上滚动 Space 向下滚动 编辑模式\r这里实际上就是 vscode 的内置快捷键，但是由于我下载了 IDEA 快捷键的插件和别的一些插件，所以目前 vscode 的快捷键很混乱，下main记录一下当前可以使用的快捷键操作。 快捷键 **备注 ** Esc 转入命令模式 Shift/Alt+Enter 运行当前选定的单元格并在紧邻下方插入一个新单元格（焦点移至新单元格） Ctrl+Alt+Enter 运行当前选定的单元格 Ctrl + X 剪切/剪切行（空选定） Ctrl + C 复制/复制行（空选定） Delete / Backspace 删除光标右边、左边的字 Alt + ↑ / ↓ 向上/向下移动行 Ctrl + D 向下复制行（来自 IDEA 的快捷键） Ctrl + Y 删除行（来自 IDEA 的快捷键） Ctrl + Shift + \\ 跳到匹配的括号 Ctrl + ] / [ 缩进/突出行 Ctrl + ← / → 光标到字首/字尾 Ctrl + / 切换行注释 Shift + Alt + A 切换块注释 ","date":"2024.11.26","objectID":"/blog/posts/config/jupyter/:2:3","tags":["config"],"title":"Jupyter 使用","uri":"/blog/posts/config/jupyter/"},{"categories":["config"],"content":"记录一下每次刷机和刷机之后需要的配置 ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:0:0","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"刷机\r这里记录一下刷机的流程，都是按照我的 pixel3 手机来的。 ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:1:0","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"解锁 OEM 和 BL\r首先是通过在设置 \u003e 系统 \u003e 关于手机多次点击版本号，知道提示进入开发者模式。之后在手机的设置 \u003e 系统 \u003e 开发者选项中找到 OEM 解锁，将其打开。 最后就是使用以下命令解锁 BL 锁，解锁之后，手机会重置。 adb devices # 先检查设备是否存在，存在则执行以下指令 adb reboot bootloader # 重启进入fastboot mode fastboot flashing unlock # 解锁 ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:1:1","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"驱动安装\rwindows 需要进行这一步，不然可能识别不了手机。从 官网 下载驱动安装，之后进入设备管理器 \u003e 其它设备下查看相应的设备，右键更新驱动程序，选择浏览我的电脑以查找驱动程序，将下载驱动解压缩路径选中，点击下一步，安装即可 ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:1:2","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"刷入官方镜像\r我使用的手机是 pixel3，所以直接从 google 镜像官网找 blueline 型号的镜像下载。解压压缩包之后进入目录，运行下面的命令，等待萨湖如官方镜像完成。 adb reboot bootloader # 先进入bootloader模式 ./flash-all.sh ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:1:3","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"使用 Magisk 进行 Root\r先从 官方 下载面具，之后使用 adb install xx.apk 来进行安装。之后从上面的官方镜像的 image-blueline-xxxxxx.zip 中得到 boot.img 文件，通过 adb push boot.img /sdcard/ 上传到手机之后，使用 Magisk，点击安装 \u003e 选择并修补一个文件对该文件进行修补，之后会得到 magisk_patched-xxx_xxx.img 文件。在把这个文件通过 adb pull /sdcard/Download/magisk_patched-xxx_xxx.img 下载到电脑，再次刷入即可 root。 adb reboot bootloader # 先进入fastboot mode fastboot flash boot magisk_patched-xxx_xxx.img 只需要在 adb shell 中执行 su 命令，Magisk 弹出确认，点击允许即可获取 root。 ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:1:4","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"软件下载\r","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:2:0","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"Magisk\r上面说了下载链接，这里就不展开述说了。面具的作用有很多，我觉得最主要的就是获取 root 权限，由此可以配合使用很多操作。 同时可以下载 zygisk，可以有更多修改能力，也可以下载 LSPosed，启动 Xposed Hook。 ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:2:1","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"CaptiveMgr\r去除 WiFi 受限无法连接叹号的问题，自己软件的下在链接忘了，贴一个别人存的地址，应该是一样的。相关博客。 ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:2:2","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"Termux\rTermux是一个适用于 Android 的终端模拟器，其环境类似于 Linux 环境。 无需Root或设置即可使用。 Termux 会自动进行最小安装 - 使用 APT 包管理器即可获得其他软件包。可以从 官方网址 进行下载。 Linux 中很多命令 Android 中都没有，下载又很麻烦，所以使用这个终端可以方便运行各项命令，因为可以直接使用包管理来进行软件下载。 ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:2:3","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["android"],"content":"借鉴讲解视频和文字记录做的笔记，主要觉得它们中有的地方说的不清楚，所以想再做一份。 这里以 ARM-v8a 架构中的 ls 举例讲解 ELF 文件格式。 ","date":"2024.11.24","objectID":"/blog/posts/android/elf/:0:0","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"基础配置\r这里使用 /system/bin/ls 文件来进行分析，首先将其复制一份放在 /data/local/tmp 目录中，之后 pull 到本地使用 010 Editor 进行修改，然后再 push 上去运行验证。下面为了方便采用 bat 脚本执行。 adb push ls /data/local/tmp/ls adb shell \"chmod 777 /data/local/tmp/ls\" adb shell \"cd /data/local/tmp \u0026\u0026 ./ls\" 要提及一下 Toybox，它是一个小型、高效的命令工具集，为嵌入式系统和 Android 提供了常用命令的实现。同时它也是单一的可执行文件，集成了多个常用命令，如 ls、cp、mv、mkdir 等。我们使用的 ls 就是 Toybox 的软链接，它通过识别程序调用时的名称（即 argv[0]）决定执行的具体命令。所以我尝试把 ls 更改名称为 modify-ls，一开始能用，然后后面就报错 toybox: Unknown command modify-ls 了，所以还是使用原来的名称。 ","date":"2024.11.24","objectID":"/blog/posts/android/elf/:1:0","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"elf_header\relf_header\r上图就是 elf_header 的结构，它包含数个结构信息。下面主要展示真正起作用的部分和相关知识点，其余没有用处的部分一笔带过，这里有没有用处的评价标准是相对于在 Linux 中正常运行而言的，不影响运行就是没有作用的。 ","date":"2024.11.24","objectID":"/blog/posts/android/elf/:2:0","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"结构分析\re_ident\relf_header 下面有一个子结构体 e_ident，它里面其实只有第一个 file_identification 是有用的，并且是固定的，为 .ELF。 file_identification\r其余的属性，例如 ei_class_2_e，它是用来描述 elf 的位数的，32位和64位。但是实际上 linker 加载该 elf 文件的时候，根本不会在意这个值。如果把这个结构中除了 file_identification 全部更改为 EE（FF为 -1，可能存在作用），程序依然可以正常运行。 e_type\r这个的值虽然是一个枚举，但是是实际上无论是 exe 还是 so，它们的值都必须是 ET_DYN (3) ，如果是一个 exe 文件，将这个值改成 ET_EXEC (2)，它反而不能运行。 e_machine\r这个字段说明 CPU 平台，比如 x86，arm32，arm64 等。如果这个地方给错了，不能正常运行。 e_entry_START_ADDRESS\r这个是 elf 加载到内存时执行的初始地址，也就是程序加载后，加载器将控制权转移到的第一条指令地址，通常是 _start 函数的地址，之后这个函数会调用 libc 的启动函数 __libc_start_main，而 __libc_start_main 就会调用用户定义的 main 函数。这里它是一个虚拟地址，表示的相对偏移，真实的虚拟地址 = 加载的虚拟地址的基址 + 这个相对偏移。 PROGRAM_HEADER_OFFSET\r指 e_phoff_PROGRAM_HEADER_OFFSET_IN_FILE，它是 program_header_table 段的偏移。elf_header 后面就是 program_header_table，斯普哦它一般也是 elf_header 的大小。除非有人故意在这两者之间插入一些无用的数据。 SECTION_HEADER_OFFSET\r指 e_shoff_SECTION_HEADER_OFFSET_IN_FILE，它表示 section header table 段的偏移，但是没有什么用处，实际上跟 section 有关的都没啥用，因为 elf 加载的时候根本就不使用 section 相关的东西。上面是 Android 8 之前的版本，而 Android 8 及以后还是会读取 section header的，但不是所有的 section 都会读取。但是我使用 Android 9 进行实验，SDK 为 28，我发现按照之前的修改方式进行，程序还是可以运行。这里是 Android14 的 linker 代码，可以看到它存在 ReadSectionHeaders()、ReadDynamicSection() 函数来读取相关信息。 修改 section header table\r但是 IDA 是使用 section 来进行解析的。我们将 section header 都覆盖为 EE。之后可以正常运行，但是 IDA 解析一开始会报错，之后发现解析不了段信息。实际上加载一个 so 文件的时候，IDA 的 segment view 里面就是解析的 section header。如果我们破坏了甚至是弄一个假的 .text/.data section，那么 IDA 就没有办法正常解析了。 IDA 解析\r","date":"2024.11.24","objectID":"/blog/posts/android/elf/:2:1","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"其余信息\re_ehsize_ELF_HEADER_SIZE：没有用处，加载的时候根本不检查，它是根据位数的默认大小，所以改动 elf_header 的大小会有不可预料的后果 e_phentsize_PROGRAM_HEADER_ENTRY_SIZE_IN_FILE：program_header_table 是一个数组，这个表示数组中每个元素的大小 e_phnum_NUMBER_OF_PROGRAM_HEADER_ENTRIES：这个表示上面数组中元素的个数 ","date":"2024.11.24","objectID":"/blog/posts/android/elf/:2:2","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"总结\r所以最后可以把 elf_header 修改成下面的形式，它也是可以正常运行的。下面保留的相关结构就是 file_identification、e_type、e_machine、e_entry_START_ADDRESS、e_phoff_PROGRAM_HEADER_OFFSET_IN_FILE、e_phentsize_PROGRAM_HEADER_ENTRY_SIZE_IN_FILE、e_phnum_NUMBER_OF_PROGRAM_HEADER_ENTRIES。 修改后ELF\r","date":"2024.11.24","objectID":"/blog/posts/android/elf/:2:3","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"program_header_table\r这是一个数组，拥有数个元素结构体 program_table_element，元素个数和元素大小都在 elf_header 中展示出来了。这里是对单个元素结构进行分析，它每一个元素结构描述的都是内存和文件的对应关系。 program_header_table\r","date":"2024.11.24","objectID":"/blog/posts/android/elf/:3:0","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"结构分析\rp_type\r段类型，为 1 表示可加载段，然后根据读写权限可以分成代码段和数据段。这两个可加载段最为重要，其它段就是服务这两个段而存在的。 p_flags\r段属性。表示段为可读，可写，可执行等。对于加载段很重要，区分了代码段和数据段，其它段就基本没什么意义。 FROM_FILE_BEGIN\r指 p_offset_FROM_FILE_BEGIN，它表示段在文件中的偏移，可以直接在文件中根据偏移进行查看。 VIRTUAL_ADDRESS\r指 p_vaddr_VIRTUAL_ADDRESS，它表示段的虚拟地址。它表示的是一个相对偏移，因为段被加载到的虚拟地址是不确定的，所以真实的虚拟地址 = 加载的虚拟地址的基址 + 这个相对偏移 PHYSICAL_ADDRESS\r指 p_paddr_PHYSICAL_ADDRESS，它表示段的物理地址。因为都运行在用户态，没有物理地址的概念，所以所有段的这个都没有用。段只有虚拟地址才有意义。 SEGMENT_FILE_LENGTH\r指 p_filesz_SEGMENT_FILE_LENGTH，表示段在文件中的长度。 SEGMENT_RAM_LENGTH\r指 p_memsz_SEGMENT_RAM_LENGTH，表示段在内存中的长度。 p_align\r段的对齐方式。ELF 中的对齐都是内存对齐，不存在文件对齐，它都是密集排列的。它没有什么作用，加载器中写定了内存对齐都是 4K。 ","date":"2024.11.24","objectID":"/blog/posts/android/elf/:3:1","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"文件内存映射\rprogram_header_table 中的每个元素，描述的其实是将段加载到内存中时，elf文件中的段映射到了内存中。 p_offset_FROM_FILE_BEGIN 与 p_filesz_SEGMENT_FILE_LENGTH 表示了文件中的段。 p_vaddr_VIRTUAL_ADDRESS 与 p_memsz_SEGMENT_RAM_LENGTH 表示了内存中的段。 这两者构成一个映射关系，linker 在加载 elf 的时候采用的是 mmap。p_filesz_SEGMENT_FILE_LENGTH 与 p_memsz_SEGMENT_RAM_LENGTH 的大小不一定一样，因为为了节省 elf 文件大小，有些值为 0 的段，比如 .bss 就不占文件空间。但是加载到内存后，还是要分配空间的。 ","date":"2024.11.24","objectID":"/blog/posts/android/elf/:3:2","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"Program Header\r这个段里只有两块数据有用，其余都可以忽略。 Program Header\r文件偏移与虚拟地址，它们都是 0x40，而且这个值与 elf_header 必须是相等的。这个值某种意义上就是 elf_header 的大小。那为什么还需要在这里再储存一次呢？ 可以简单理解，linker 里面有一些指针指向的是 elf_header，而有些指针指向的是 program_header，互相转换的时候，会使用指针偏移来计算，偏移大小就是这里的 0x40，所以就在这里也记录了值，偏于指针计算。 p_data 就是整个 program_header_table 的内容。 p_type 不知道有没有用，没试过改这里，假定有用吧。 ","date":"2024.11.24","objectID":"/blog/posts/android/elf/:3:3","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"Interpreter Path\r这个段就是描述解析器（linker）路径的，它与上面的 Program Header 段必须要出现在可加载段前面。 Interpreter Path\r这个段需要关注的数据就是 p_data，可以发现它是一个字符串 /system/bin/linker64，那么 LENGTH 就都是指的容纳这个字符串的长度，在这里也就是最多 0x15 长度的字符串。ELF 的可加载段就是由这个路径文件来加载的，包括重定位操作等等。 我们可以根据这个路径获取系统的 linker，之后在入口点写入死循环，然后更改 ls 文件的解析器路径为我们修改的 linker 的路径。这里因为字符串的长度不能超过 0x15，同时需要以 00 字节结尾，所以更改 linker64 为 li64。 文件修改\r之后运行 ls 文件，发现卡死了，所以查看其 maps 信息。这里发现相比之前的死循环，这里少了很多东西，像是 libc 相关的东西也没有了。这是因为现在进程卡在了非常早的时机，连这个 ELF 文件自身的段的重定位都没有做，只是光将 ELF 文件中的东西放到内存里面了。 但是可以发现下图前面两行表示 ls 文件被加载了，这又是为什么？我们已经在 linker 的入口函数加了一个死循环，linker 根本不会执行加载逻辑才对。其实这是因为这两个可执行段不是由 ls 中指定的 linker 加载的，而是其他进程中的 linker 加载的，目前先简单的理解为是 init 进程干的吧（感觉需要更为细致的判断，这里的理解是猜测）。剩下的其他 ELF 依赖文件，比如 libc 等则将由路径中指定的 linker 来加载。 修改后 maps 信息\r我们可以使用 IDA 附加进程来更为细致的查看。在 Modules 中可以发现只有两个 so 被加载。 IDA Modules 信息\r之后还原 linker 的入口地址指令，让其继续执行，并且在 ls 的入口地址加上断点。按 F8 步过 linker_init 函数，发现此时 linker 加载了很多的 so。同时这里的 linker 存在一个特点，他没有 imports（导入表）。这是因为它不依赖其他 so，它也不能依赖其他 so。它运行的时候，其他 so 都没有加载。比如 open 函数，它就不能使用 libc 中的 open 函数，它必须自己实现 open 函数。所以它必须实现所有自己需要的函数。 IDA Modules 信息\r","date":"2024.11.24","objectID":"/blog/posts/android/elf/:3:4","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"Android9 可加载段\r重要说明\r这里加载段和上面的内容都是对于我 Android9 的设备来看，与其它 Android 的版本存在差异。 这里最为重要的就是下面的两个可加载段了，根据其权限可以判断出，具有 R_X 属性的段为代码段，具有 RW_ 属性的段为数据段。 可加载段\r代码段\r之前根据 elf_header 的 e_entry_START_ADDRESS 值，我们可以知道代码的入口在虚拟地址 0xD760。对于程序在内存运行，段的加载就是根据它的虚拟地址和内存长度来进行排列的。这里代码段的虚拟地址为 0x0，可以判断它是排在第一个的。同时代码入口和段的真实虚拟地址都是 加载的虚拟地址的基址 + 相对偏移 得来的，它们的加载虚拟地址基址都是一样的，同时段的大小为 0x6041C，比 0xD760 大，所以代码的入口在代码段中。 代码段信息\r同时代码段的文件大小和内存大小相同，且段在文件中的偏移也是 0，所以可以判断它们为 1对1 映射。所以该入口地址在文件中也是在代码段中的（0x0 + 0xD760），我们可以直接查找 0xD760 来找到入口的代码。 修改前首地址\r之后修改为 00 00 00 14 ，它在 ARM64 中表示 b #0，是死循环代码，这样可以帮助我们查看内存中的段分布。 修改后首地址\r之后启动文件，通过 ps -a 查看进程信息，之后通过 proc/self/maps 查看内存中段信息。 内存段信息\r根据上图可以看到段在内存中的分布，这里第一个可读可执行的就是代码段，而后面三个一起就是数据段。这里代码段的起始位置 0x60a053e000 就是加载的虚拟地址的基址，因为代码段的相对偏移为 0。之后我们得到代码段的大小为 0x6041C，二者相加等于 0x60A059E41C，然后是 4K 对齐，结束地址为 0x60A059F000。同时我们用户的起始代码地址为 0x60a053e000 + 0xD760 = 0x60A054B760。在下图 IDA 的分析中，可以看到起始地址代码刚好为我们更改的结果。 IDA 中起始地址\r在 IDA 的分析中，这里的代码在名为 .text 的 segment 中，它是 IDA 根据 section 的信息分析的，在 section 中，.text的起始位置为 0xD740，刚好和这里的图片相对应。由此也可以验证 IDA 的分析是根据 section 来进行的，但是运行是根据 program 来进行的。 IDA 代码段信息\r数据段\r而后面三个一起为数据段，我们查看数据段信息，可以知道它的虚拟地址为 0x7CFC0，而基址为 0x60a053e000，二者相加为 0x60A05BAFC0。因为内存页都是 4K 对齐的，所以不能从这个地址开始给其赋予可读可写的权限，必须是给整个内存页赋予权限，所以这里就从 0x60a05ba000 开始赋予权限，但是真实的地址还是 0x60A05BAFC0。 同时数据段的大小为 0x89EE，0x60a05ba000 + 0x89EE = 0x60A05C29EE，根据 4kb 对齐就是 0x60A05C3000。这个地方应该和三部分的末尾相对应，但是我这里差了 1kb 的空间，每次都是这样，怀疑我这个系统往这个里面添加了什么数据，但是目前不知道。所以这里就当作它是刚好映射到结尾吧。 数据段信息\r这里从 IDA 的 Segments View 中可以看出，这个地址对应的 segment 就是 .preinit_array，也就是说这个数据段从这里往后进行放置。我们可以根据该段的文件偏移找到这个地方的代码，可以发现二者是相对应的。 IDA 数据段信息\r但是问题还是在这里，为什么这个数据段被分成了三部分？这是因为数据段中的一部分权限会被修改，它是被下面的 GNU Read-only After Relocation 段给修改的。这个段描述的就是，在重定位之后，将虚拟位置 0x7CFC0 且大小为 0x3040 字节的区域的权限改为只读。这里 0x7CFC0 就是数据段的起始位置，之后计算数据段的第一部分大小， 0x60a05be000 - 0x60a05ba000 = 0x4000，它刚好是 0x3040 4kb 对齐的结果，这说明第一部分就是这个段修改权限所产生的。 GNU Read-only After Relocation\r而剩余的两部分也都是数据段的内容，它们都是可读可写的，第一个后面存在文件路径，而后面那个没有。这是因为这个数据段的文件大小小于映射后的 RAM 大小，所以 RAM 超出文件的部分就没有文件映射了，也就没有文件路径了。 ","date":"2024.11.24","objectID":"/blog/posts/android/elf/:3:5","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["compile"],"content":"这里记录符号表、语义属性相关知识。 ","date":"2024.11.21","objectID":"/blog/posts/compile/semantics-symboltable-ag/:0:0","tags":["compile"],"title":"03 Semantics SymbolTable Ag","uri":"/blog/posts/compile/semantics-symboltable-ag/"},{"categories":["compile"],"content":"Symbol Table\r符号主要指变量名、函数名、类型名、标签名。在语义分析中需要进行符号检查，即检查程序是否会出现符号乱用的情况，例如前一句将符号 symbol 定义为变量，之后又把它当作函数来进行函数调用了。而符号表就是用于保存各种符号相关信息的数据结构，它不仅在前端语法分析之后会发挥作用，还会在后端的生成中间代码的过程进行使用。下面就是一个符号表的示例。 符号表\r但是对于符号检查而言，最为困难的就是作用域了。“领域特定语言”（DSL），例如简单的键值对，它们通常只有单作用域（全局作用域），而对于我们真正要分析的“通用程序设计语言”（GPL），它通常就需要嵌套作用域了，这时就需要不同的哈希表来进行符号存储了，由此每个符号表代表了一个作用域，不同的作用域需要通过树结构来维护。 多作用域符号表\r下面就是每个作用域需要提供的接口： 作用域接口\r符号表相关的类层次结构设计如下，它是 Lab3 的一部分，表示了符号表的设计。 符号表类层次结构\r","date":"2024.11.21","objectID":"/blog/posts/compile/semantics-symboltable-ag/:1:0","tags":["compile"],"title":"03 Semantics SymbolTable Ag","uri":"/blog/posts/compile/semantics-symboltable-ag/"},{"categories":["compile"],"content":"语义分析\r这里讲述的就是属性文法，它指的就是为上下文无关文法赋予语义，分析的就是如何基于上下文无关文法做上下文相关分析。 因此得出在语法分析过程中实现属性文法，就是通过在推导过程中嵌入语义动作，例如 $B \\rightarrow X \\{ \\textcolor{red}{a} \\} Y$。语义动作嵌入的位置决定了何时执行该动作，基本思想就是一个动作在它左边的所有文法符号都处理过之后立刻执行。在 antlr4 中，使用参数的形式来表示继承属性，使用返回值来表示综合属性。 ","date":"2024.11.21","objectID":"/blog/posts/compile/semantics-symboltable-ag/:2:0","tags":["compile"],"title":"03 Semantics SymbolTable Ag","uri":"/blog/posts/compile/semantics-symboltable-ag/"},{"categories":["compile"],"content":"语法制导定义\rSDD（语法制导定义，Syntax-Directed Definition）是一个上下文无关文法的属性及规则的结合。 每个文法符号都可以关联多个属性 每个产生式都可以关联一组规则 SDD 唯一确定了语法分析树上每个非终结符节点的属性值，但它没有规定以什么方式、什么顺序计算这些属性值。顺序是根据不同的语法分析器的情况而言的，比如 antlr4 是深度优先遍历，那么它呃顺序也就是这个了。 antlr 遍历\rS 属性定义\r综合属性和 S 属性\r属性依赖关系\r由上图可以看出 S 属性的含义。本质而言，他就是父节点的信息需要依赖于子节点的传递，只有子节点首先处理完得到了结果，才能传递给父节点进行使用。 S 属性性质\rL 属性定义\r集成属性\r由上图，$T^{’}$ 有一个综合属性 syn 与一个集成属性 inh。这里继承属性 $T^{’}.inh$ 用于在表达式中从左向右传递中间计算结果。 L 属性\r上述的定义就是排除依赖右兄弟节点的情况，因为这种情况对于深度优先建立的语法分析树而言是不可能实现的。 例子\r属性文法计算后缀表达式\r后缀表示\r后缀表达 S 属性\r数组类型文法举例\r综合信息的流向是从下向上传递信息，继承信息流向是从左向右、从上到下传递信息。所以为了把二者进行结合，那么就先通过继承属性从左向右、从上到下传递信息，再通过综合属性从下向上传递信息。 数组类型\r","date":"2024.11.21","objectID":"/blog/posts/compile/semantics-symboltable-ag/:2:1","tags":["compile"],"title":"03 Semantics SymbolTable Ag","uri":"/blog/posts/compile/semantics-symboltable-ag/"},{"categories":["config"],"content":"记录一下 IDA 的使用。 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:0:0","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"下载\r这里贴一个 IDA9.0rc1 的 来源，虽然不是从这里获取的资源，但是想来应该都差不多。之后就是使用评论区给出的 keygen2.py 文件进行 patch 和生成 License，也就是 idapro.hexlic 文件，这样就可以正常使用了。 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:1:0","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"配置\r","date":"2024.11.20","objectID":"/blog/posts/config/ida/:2:0","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"修改 python 版本\r想让 IDA 使用自己的 python，那么就需要进行相关配置，这里直接使用 idapyswitch.exe 进行切换即可，下面的命令就会更改 IDA 使用的 python 版本。我这里使用的是 miniconda 的虚拟环境，但是都是一样的，只要找到 python3.dll 就行。 .\\idapyswitch.exe --force-path E:\\xxxxx\\miniconda3\\envs\\re\\python3.dll ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:2:1","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"插件\rIDA 有很多好用的插件，但是按照之前 beta 的版本，有一些会产生冲突，所以这里记录目前可以使用或者被修改过的插件。 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:3:0","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"keypatch\r从 修改仓库 获取的，直接把 keypatch.py 放在 plugins 目录中就可以使用了。具体使用可以看链接的 README 文件 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:3:1","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"lazyida\r从 官方仓库 获取的，作者修改了错误的地方，配置方式和上面一样，具体使用也是看 README。 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:3:2","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"D810\r从 官方仓库 获取的，反正最开始的时候没有报错，当作可以正常使用 🐶。之后使用时选择适当的规则，然后点击 start，就可以按 F5 自动反编译，解决 OLLVM 混淆。如果已经存在 F5 缓存，可以将一段代码 nop 掉，之后撤销操作，再 F5 反编译即可 D810使用\r","date":"2024.11.20","objectID":"/blog/posts/config/ida/:3:3","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"findcrypt-yara\r从 官方仓库 获取之后，把 findcrypt3.py 和 findcrypt3.rules 放在 plugins 目录中。之后因为 yara-python 版本的问题，需要进行 修正，直接将下面的代码覆盖原来的即可。同时也可以给 rules 添加国密SM4算法的识别规则。 def yarasearch(self, memory, offsets, rules): print(\"\u003e\u003e\u003e start yara search\") values = list() matches = rules.match(data=memory) for match in matches: for stringR in match.strings: name = match.rule for string in stringR.instances: if name.endswith(\"_API\"): try: name = name + \"_\" + idc.GetString(self.toVirtualAddress(string.offset, offsets)) except: pass value = [ self.toVirtualAddress(string.offset, offsets), match.namespace, name + \"_\" + hex(self.toVirtualAddress(string.offset, offsets)).lstrip(\"0x\").rstrip(\"L\").upper(), stringR.identifier, repr(string.matched_data) ] idaapi.set_name(value[0], name + \"_\" + hex(self.toVirtualAddress(string.offset, offsets)).lstrip(\"0x\").rstrip(\"L\").upper() , 0) values.append(value) print(\"\u003c\u003c\u003c end yara search\") return values ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:3:4","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"ipyida\r可以在 IDA 中配置 ipython 来执行 python 代码。直接从 官方仓库 执行命令下载即可。然后使用 Shift + . 就可以打开进行使用了，注意 exit 的使用，它会直接退出 IDA，然后分析文件会遗留，但是是分散的格式。 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:3:5","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"bindiff\r直接去 官网 下载 bindiff，我这里下载的是 bindiff 8。然后在它的 Plugins 目录下存在 IDA 的插件，我这里是找到 IDA-9.0-rc1 的 适配 版本，直接放到 IDA 的 plugins 目录下，然后点击 File 就可以看到 bindiff 并使用了。 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:3:6","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"使用\r可以查看别人的 博客 来学习具体的使用方法和小技巧。 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:4:0","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"日常使用\r快捷方式\rctrl + e 找到main函数 Shift + f12 可以打开 string 窗口，一键找出所有的字符串，右击setup，对窗口的属性进行设置。同时附加时使用可以显示 strings Shift + f7 可以查看 Segments 窗口。查看不同的段 空格 在Text View和Group View中来回切换 f5/Tab 一键反汇编，Tab可以在汇编界面与伪代码界面来回切换 Ctrl + X 交叉引用 Ctrl + Alt + K(Keypatch快捷键) 进行patch Alt + T 在汇编界面中搜索汇编语言 Shift + E 类型更改\rD （DATA） 转换为原始数据 C （CODE）转换为汇编代码 P 重新生成函数 a 将数据转换为字符串，主要可以应对小端序存储 N 更改变量的名称 Y 更改变量的类型，比如把 _int64 更正为 BYTE*（或者char *） U undefine，取消定义函数、代码、数据的定义，转化为原始字节的形式 V 简化函数的格式，有时候函数没有 return 时可以使用，查看更方便 M 枚举所有相同的数据 ; 在反汇编后的界面中写下注释 / 在反编译后伪代码的界面中写下注释 \\ 在反编译后伪代码的界面中隐藏/显示变量和函数的类型描述 有时候变量特别多的时候隐藏掉类型描述看起来会轻松很多 右键点击 Hide casts 也可以隐藏类似 *(DWORD) 的类型描述 动态调试\r快捷键\rF2 增加断点 F7 单步步入，遇到函数，将进入函数代码内部 F8 单步步过，执行下一条指令，不进入函数代码内部 F4 运行到光标处（断点处） F9 继续运行 Ctrl+F2 终止一个正在运行的调试进程 Ctrl+F7 运行至返回,直到遇到RETN(或断点)时才停止 附加\r应对一些强壳，可以先启动 .exe 程序，之后使用IDA的附加功能 (Debugger-\u003eattach)，附加进程，可以越过壳。之后可以使用 Shift + f12 和 Shift + f7 定位关键字符位置和段属性，将该程序的 Code 段使用 IDAPYTHON 转化为反汇编形式进行动调。 from ida_ua import * cur_addr = 0x401000 #起始地址 end_addr = 0x410000 #终止地址 def make_insn(start,end): adr = start out_ins = insn_t() while True: if(adr \u003e= end): break create_insn(adr) size = decode_insn(out_ins,adr) adr += size print(\"end!\") make_insn(cur_addr,end_addr) print(\"Done\") 可能 Code 段很大，编译很慢，可以结合手动按c反汇编结合查看 ELF 文件\r以下就是注意事项，具体流程直接上网查找即可。 Linux开启远程连接服务，在虚拟机中打开 IDA 在 Linux 中的调试工具 首先需要将文件提权，否则不能运行，也就不能调试了 IDA连接虚拟机，开始动调 Linux进行附加时，需要先打开 linux_server 服务，然后另起端口打开运行的程序，之后就可以附加了。这里需要先使用 sudo vim /etc/sysctl.d/10-ptrace.conf 更改最后一行 kernel.yama.ptrace_scope = 0，重启系统后，普通用户就可以使用 attach ID 连接程序调试了。 注意 wsl 的 Hosrname 可以设置为 127.0.0.1，有时候设置成 wsl 的 ip 不太起效果 为了方便 IDA 中的 application，可以使用 realpath ./file 直接获取文件的路径 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:4:1","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"idapython\ridapython 可以对相关数据进行操作，学习可以参照下面的文章。 IDA Python 使用总结 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:4:2","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"相关技巧\r从IDA中获取数据时，如果在分析程序中发现数据的排列为 qword 等，建议不要以小端序转化，而是直接从 IDA 的 IDA View-RIP 界面复制，不用 Ctrl + e 提取数据。除此之外， qword 的转化可能会出现一些多余数据，记得识别 这里补充一点：若是在 IDA View-RIP 界面中的数据不是正规数据（这里指十六进制），则采用 Ctrl + e 进行十六进制提取，再分别以4个字节为一组，然后倒转称为小端序的顺序进行解密操作 总而言之 可以首先使用 Ctrl + e 进行提取，然后手动进行倒转转换 也可以使用 D 进行打乱，再分别使用 D 聚合成每4个字节为一组的形式 也可以使用插件 lazyida，在数据上 右键 -\u003e convert -\u003e Covern to …… DWORD list（这里注意看前面的标识进行相依字节长度的转化）就可以在下方output框看见正确的小端序数组 Patch 函数的时候，可以直接使用汇编。然后另存为文件即可跳过函数 mov eax,0x1 retn x ;这里的 x 需要根据函数末尾的返回来抄写，防止栈不平衡 遇到 (_BYTE *)\u0026qword_4058 之类的，若是知道这是表示的数组，那么可以再汇编界面按 D 变成数据，之后 F5 重新生成伪代码，则可以看到数组变成 byte_4058[] 之类的数组形式 若是函数格式中有 (_BYTE) 等干扰分析时，可以： 使用 Y 更改变量的类型，比如把 _int64 更正为 BYTE*或者 (char *) 使用 V 简化函数的格式，有时候函数没有 return 时可以使用，这样看更方便 IDA在识别花指令时，很可能在一个连续的函数中显示红色的 sub_3D9 endp ; sp-analysis failed 类似的信息，这个时候可以使用 Edit -\u003e Function -\u003e Delete function 删除函数定义，然后在正确的位置 retn 使用 Edit -\u003e Function -\u003e Set function end 设置函数结尾。之后 F5 反编译可以看到正常的函数 有时候 U + P 不能生成函数，可以先删除函数定义，选中函数块之后按 P 定义函数 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:4:3","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["compile"],"content":"这里记录上下文无关文法、LL算法相关知识 ","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:0:0","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"CFG\r","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:1:0","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"语法\rDefinition(Context-Free Grammar, 上下文无关文法)，上下文无关文法 G 是一个四元组 G = (T, N, S, P)： T 是 终结符号（Terminal）集合，对应于词法分析器产生的词法单元 N 是 非终结符号（Non-terminal）集合 S 是 开始（Start）符号（$S \\in N $且唯一） P 是 产生式（Production）集合 $$ A \\in N \\rightarrow \\alpha \\in (T \\cup N)^* $$ 头部/左部（Head）A：单个非终结符 体部/右部（Body）$\\alpha$：终结符与非终结符构成的串，也可以是空串$\\epsilon$ ","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:1:1","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"语义\r上下文无关文法 G 定义了一个语言 L(G)。语言是串的集合，从文法得到串的过程就是推导（Derivation）。推导就是将某个产生式的左边替换成它的右边，每一步推导需要选择替换哪个非终结符号，以及使用哪个产生式。对于下面的推导式而言，E 就是非终结符，id 就是终结符，目的就是从左边推到为右边，得到只包含终结符的式子。 $$ E \\rightarrow E + E \\mid E * E \\mid (E) \\mid -E \\mid \\text{id} $$ 对于推导也存在区分，如果一直选择最左边的非终结符进行推导，就称为 Leftmost Derivation，如下所示： $$ E \\implies -E \\implies -(E) \\implies -(E + E) \\implies \\pmb{-(\\text{id} + E)} \\implies -(\\text{id} + \\text{id}) $$ 如果一直选择最右边的非终结符进行推导，就称为 Rightmost Derivation，如下所示 $$ E \\implies -E \\implies -(E) \\implies -(E + E) \\implies \\pmb{-(E + \\text{id})} \\implies -(\\text{id} + \\text{id}) $$ 由上述推导规则可以得到相关简单表示： $$ \\begin{align} E \u0026\\implies -E \\text{ : 经过一步推导得出} \\\\ E \u0026\\xRightarrow{\\text{+}} -(\\text{id} + E) \\text{ : 经过一步或多步推导得出} \\\\ E \u0026\\xRightarrow{\\text{*}} -(\\text{id} + E) \\text{ : 经过零步或多步推导得出} \\end{align} $$ 在推导的过程中，除了最左边的 program 和最后边的 文法写的程序，中间产物都被称为句型（Sentential Form），即 如果 $S \\xRightarrow{*} \\alpha$，且 $\\alpha \\in (T \\cup N)^*$，则称 $\\alpha$ 是文法 G 的一个句型。而最右边的结果被称为句子（Sentence），即 如果 $S \\xRightarrow{*} w$，且 $w \\in T^*$，则称 $w$ 是文法 G 的一个句子。 那么此时就可以定义文法 G 生成的语言 L(G) 了，即 文法 G 的语言 L(G) 是它能推导出的所有句子构成的集合 $L(G) = { w \\mid S \\xRightarrow{*} w }$。 ","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:1:2","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"LL(1) 语法分析算法\r自顶向下的、递归下降的、基于预测分析表的、适用于 LL(1) 文法的 LL(1) 语法分析器。 ","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:2:0","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"自顶向下\r这里指语法分析树从上往下进行构建，根节点是文法的起始符号 S，叶节点是词法单元流 w$，仅包含终结符号与特殊的文件结束符 $(EOF)，中间节点表示对某个非终结符应用某个产生式进行推导。那么这里的问题就是选择哪个非终结符，以及选择哪个产生式。这里对于 LL(1) 而言，第一个 L 就是表示从左向右读入词法单元；第二个 L 表示在推导的每一步，LL(1) 总是选择最左边的非终结符进行展开。即构建最左推导；1 表示只需向前看一个输入符号便可确定使用哪条产生式。 ","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:2:1","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"递归下降\r这里指实现方式，就是为每个非终结符写一个递归函数，内部按需调用其它非终结符对应的递归函数，下降一层。 递归下降的典型实现框架\r递归下降过程\r","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:2:2","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"基于预测分析表\r设计预测分析表就是源于上述递归下降过程的一个问题，在上图展开非终结符 S 的过程中，为什么前两次玄策了 $S \\implies (S + F)$，而第三次选择了 $S \\implies F$？这里就是因为它们面对的当前词法单元不同。由此根据不同的词法单元，形成了一张预测分析表，之后就可以使用预测分析表来确定产生式。 预测分析表\r这里指明了每个非终结符在面对不同的词法单元或文件结束符时，该选择哪个产生式（按编号进行索引）或者报错（空单元格）。下面就是递归下降、基于预测分析表的实现方法，这里根据预测分析表，从左往右逐个字符进行匹配。 实现方法\r那么如何得到这个预测分析表呢，就需要先知道两个概念。 FIRST 集合\r$FIRST(\\alpha)$ 是可从 $\\alpha$ 推导得到的句型的首终结符号的集合。即对于任意的（产生式的右部）$\\alpha \\in (N \\cup T)^*$： $$ \\text{FIRST}(\\alpha) = \\{ t \\in T \\cup \\{ \\epsilon \\} \\mid \\alpha \\overset{*}{\\Rightarrow} \\textcolor{red}{t} \\beta \\lor \\alpha \\overset{*}{\\Rightarrow} \\epsilon \\} $$ 因此对于这个集合而言，考虑非终结符 $A$ 的所有产生式 $A \\rightarrow \\alpha_1, \\quad A \\rightarrow \\alpha_2, \\quad \\ldots, \\quad A \\rightarrow \\alpha_m$，如果它们对应的 $FIRST(\\alpha)$ 集合互不相交，则只需查看当前输入词法单元，即可确定选择哪个产生式（或报错）。 符号 X 的 FIRST 集合计算\r符号串 $X\\beta$ 的 FIRST 集合计算\r具体可以看下面的例子： 后面跟的为终结符 ... A-\u003eaB|ε A-\u003ec ... First(A) = {a，ε，c} 后面跟的为非终结符 # 情况一 ... A-\u003eBa B-\u003eb ... First(A) = {b} # 情况二 ... A-\u003eBc B-\u003eb|ε ... First(A) = {b, c} # 情况三 ... A-\u003eBC B-\u003eb|ε C-\u003ec|ε ... First(A) = {b, c, ε} FOLLOW 集合\r$FOLLOW(A)$ 是可能在某些句型中紧跟在 $A$ 右边的终结符的集合。即对于任意的（产生式的左部）非终结符$A \\in N$： $$ \\text{FOLLOW}(A) = \\{ t \\in T \\cup \\{ \\text{\\$} \\} \\mid \\exists s.\\ S \\overset{*}{\\Rightarrow} s \\triangleq \\beta A \\textcolor{red}{t} \\gamma \\} $$ 这里的 $\\$$ 就是文法开始符，只在第一个字符的 $FOLLOW$ 集合中进行添加。考虑产生式 $A \\rightarrow \\alpha$，如果从 $\\alpha$ 可能推导出空串（$\\textcolor{red}{\\alpha \\overset{*}{\\Rightarrow} \\epsilon}$），则只有当当前词法单元 $t \\in FOLLOW(A)$，才可以选择该产生式。 符号 X 的 FOLLOW 集合计算\r符号串 $X\\beta$ 的 FOLLOW 集合计算\r构建预测分析表\r根据上述对于 FIRST集合 和 FOLLOW集合 的描述，可以计算给定文法 G 的预测分析表：对应每条产生式 $A \\rightarrow \\alpha$ 与终结符 $\\textcolor{blue}{t}$，如果 $$ t \\in \\text{FIRST}(\\alpha) \\\\ \\alpha^* \\Rightarrow \\epsilon \\land t \\in \\text{FOLLOW}(A) $$ 则在表格 $[\\textcolor{red}{A}, \\textcolor{blue}{t}]$ 中填入 $A \\rightarrow \\alpha$（编号）。 综合例子\r对于下面的例子，可以得到它们的 FIRST 和 FOLLOW 集合。 $$ X \\rightarrow Y \\\\ X \\rightarrow \\alpha \\\\ Y \\rightarrow \\epsilon \\\\ Y \\rightarrow c \\\\ Z \\rightarrow d \\\\ Z \\rightarrow XYZ $$ FIRST集合 FOLLOW集合 $FIRST(X) = \\{a, c, \\epsilon \\}$ $FIRST(Y) = \\{c, \\epsilon \\}$ $FOLLOW(X) = \\{a, c, d, \\$ \\}$ $FITST(Z) = \\{a, c, d \\}$ $FOLLOW(Y) = \\{a, c, d, \\$ \\}$ $FITST(XYZ) = \\{a, c, d \\}$ $FOLLOW(Z) = \\empty$ $FITST(YZ) = \\{a, c, d \\}$ 关于 FIRST 和 FOLLOW 的更多讲解和例子可以看 这篇文章。之后根据上面信息，可以构建相应的预测分析表。也可以看 这个视频 来学习两个集合的构造方法。 预测分析表\r","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:2:3","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"适用于 LL(1) 文法\r这里主要说明它的局限性。对于上面预测分析表的构建，需要定义 LL(1) 文法，即如果文法 G 的预测分析表是无冲突的，则 G 是 LL(1)文法。无冲突就是每个单元格里只有一个产生式（编号）即仅根据当前 token 即可递推 production。那么根据这个无冲突的预测分析表，对于当前选择的非终结符，仅根据输入中当前的词法单元（LL(1)）即可确定需要使用哪条产生式。这里根据 LL(1) 文法的定义就可以看到其局限性，它需要的就是预测分析表是无冲突的，其他情况就不适用这个文法了。 ","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:2:4","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"Adaptive LL(*) 语法分析算法\r看 视频 和 论文 理解吧。 记录一下别人的 博客1，博客2。第二篇是视频的笔记，虽然它只是截图保存🐶。 ","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:3:0","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["AI"],"content":"这里记录在学习人工智能，主要是大语言模型时的相关知识点，用以梳理逻辑。 ","date":"2024.11.12","objectID":"/blog/posts/ai/ai_knowledge/:0:0","tags":["AI"],"title":"AI Knowledge","uri":"/blog/posts/ai/ai_knowledge/"},{"categories":["AI"],"content":"人工智能相关\r","date":"2024.11.12","objectID":"/blog/posts/ai/ai_knowledge/:1:0","tags":["AI"],"title":"AI Knowledge","uri":"/blog/posts/ai/ai_knowledge/"},{"categories":["AI"],"content":"基础概念\r简单而言，人工智能是一个很宽泛的概念，只是一个广义上的称呼，这里主要还是区分机器学习、神经网络、深度学习的相关概念。 机器学习：这是人工智能的基础，通过提供大量样本数据来建立模型，以识别和预测新的事物。例如，通过输入一张图片并经过一系列的运算后，模型可以判断这张图片属于哪一类。机器学习的核心目的是从数据中发现模式和规律，并通过构建一个模型来处理数据，实现预测和决策。通过训练数学模型，机器学习能够根据已知的数据和结果的映射关系，在遇到新数据时准确预测输出结果。 神经网络：神经网络模仿动物大脑的结构和功能，本质上是用数学公式来构建模型。它是机器学习的一个分支。机器学习本身依赖数学公式进行计算，而神经网络的特别之处在于拥有大量“神经元”，即隐藏层。可以简单地理解为，机器学习是基于数学公式建模的总体概念，而神经网络和其他方法（如k-means聚类）则是不同的具体实现形式，主要差异体现在算法，即数学公式的不同。如下图，机器学习的每个类别对应一种算法。具体细节可参考这个视频，虽然标题涉及机器学习，但讲解的重点主要是神经网络的原理和概念。同时也可以观看这个视频，讲解更为细致全面。 深度学习：这是人工神经网络的一个特例，其复杂性远超一般神经网络。深度学习通过增加神经网络的隐藏层数量来实现更高难度的任务。与一般神经网络相比，深度学习网络结构更为深层和复杂。其他类型的神经网络是在不同方面进行了改进，因此产生了不同的类别，但它们都包含隐藏层这一特征。 关系图\r更为详细的解释可以看这篇文章，讲述了更为细节的内容。 ","date":"2024.11.12","objectID":"/blog/posts/ai/ai_knowledge/:1:1","tags":["AI"],"title":"AI Knowledge","uri":"/blog/posts/ai/ai_knowledge/"},{"categories":["AI"],"content":"大语言模型\r","date":"2024.11.12","objectID":"/blog/posts/ai/ai_knowledge/:2:0","tags":["AI"],"title":"AI Knowledge","uri":"/blog/posts/ai/ai_knowledge/"},{"categories":["AI"],"content":"自然语言处理阶段\r第一阶段：统计模型 + 数据（特征工程） 决策树、SVM、HMM、CRF、TF-IDF、BOW 第二阶段：神经网路 + 数据 Linear、CNN、RNN、GRU、LSTM、Transformer、Word2vec、Glove 第三阶段：神经网络 + 预训练模型 + （少量）数据 GPT、BERT、ROBERTa、ALBERT、BART、T5 第四阶段：神经网络 + 更大的预训练模型 + Prompt ChatGPT、Bloom、LLaMA、Alpaca、Vicuna、MOSS、文心一言、通义千问、星火 ","date":"2024.11.12","objectID":"/blog/posts/ai/ai_knowledge/:2:1","tags":["AI"],"title":"AI Knowledge","uri":"/blog/posts/ai/ai_knowledge/"},{"categories":["AI"],"content":"Transformer\r使用 GPT 进行举例，它的全称为 Generative Pre-trained Transformer。显而易见，Transformer 就是它技术的关键所在，这里可以通过这篇文章详细了解它们之间的联系，以及 Transformer 的核心 Self-Attention。然后这个视频更为细致的讲解其底层知识。 ","date":"2024.11.12","objectID":"/blog/posts/ai/ai_knowledge/:2:2","tags":["AI"],"title":"AI Knowledge","uri":"/blog/posts/ai/ai_knowledge/"},{"categories":["android"],"content":"RiskGuard app 的总览，介绍该项目的相关信息。 ","date":"2024.11.9","objectID":"/blog/posts/android/riskguard/:0:0","tags":["android"],"title":"RiskGuard","uri":"/blog/posts/android/riskguard/"},{"categories":["android"],"content":"UI 设计\r跟随 Project Manager 进行 UI 设计，采用 kotilin 进行了实现，延续该项目的配色风格，在此基础上添加自己的模块。这里补充一下状态栏的设计，在 res/values/themes.xml 中删除 style 标签下所有内容，转化为下面的内容，那么状态栏就会透明的，图标和文字为深色，这样 UI 会更适配。 配置状态栏\r","date":"2024.11.9","objectID":"/blog/posts/android/riskguard/:1:0","tags":["android"],"title":"RiskGuard","uri":"/blog/posts/android/riskguard/"},{"categories":["android"],"content":"展开二级列表\r一开始是想的实现珍惜大佬 hunter 的 UI 设计，所以一直寻找可折叠的 textview 项目，但是发现都不尽如人意。直到找到了 ExpandableRecyclerView 这个项目，所以就使用这个进行二级列表的设置。也因此改为 kotilin 作为 UI 界面的语言，这样便于直接进行代码移植。之后把之前的设备信息获取代码移植后，配置了列表的折叠和展开后，也添加了一个全部展开/折叠功能。 ","date":"2024.11.9","objectID":"/blog/posts/android/riskguard/:2:0","tags":["android"],"title":"RiskGuard","uri":"/blog/posts/android/riskguard/"},{"categories":["programming"],"content":"学习 C++ 的使用，主要区分 C++ 和 C 的区别。 ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:0:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"C++ 历史速览\r这里通过求和的案例来记录 C、C++98、C++11、C++17 的变化。 古代 C 语言，采用 malloc 和 free 来管理内存，同时数据需要自己进行定义，并通过 for 循环实现求和操作。同时打印采用 printf，需要声明打印数据的类型才可以正确打印。 #include \u003cstdlib.h\u003e #include \u003cstdio.h\u003e int main() { size_t nv = 4; int *v = (int *)malloc(nv * sizeof(int)); v[0] = 4; v[1] = 3; v[2] = 2; v[3] = 1; int sum = 0; for (size_t i = 0; i \u003c nv; i++) { sum += v[i]; } printf(\"%d\\n\", sum); free(v); return 0; } 近代 C++98 引入 STL 容器库，这样就不需要自己进行内存的释放了，离开了当前作用域会自己进行销毁。这里的创建和销毁实质上就是 STL 容器的构造函数和析构函数。同时引入了重载的 cout 函数，因此不需要指定变量类型，可以直接进行打印， #include \u003cvector\u003e #include \u003ciostream\u003e int main() { std::vector\u003cint\u003e v(4); v[0] = 4; v[1] = 3; v[2] = 2; v[3] = 1; int sum = 0; for (size_t i = 0; i \u003c v.size(); i++) { sum += v[i]; } std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } 近现代 C++11 引入了 {} 初始化表达式和 range-based for-loop 机制。这样可以通过花括号来进行赋值，并且支持通过迭代器来进行遍历，应用函数。 #include \u003cvector\u003e #include \u003ciostream\u003e #include \u003calgorithm\u003e int sum = 0; void func(int vi) { sum += vi; } int main() { std::vector\u003cint\u003e v = {4, 3, 2, 1}; // 在 \u003calgorithm\u003e 中进行实现 std::for_each(v.begin(), v.end(), func); std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } 同时近现代 C++11 还引入了 lambda 表达式。如下可以看出不需要定义全局变量 sum 了，可以对局部变量进行相关操作。 #include \u003cvector\u003e #include \u003ciostream\u003e #include \u003calgorithm\u003e int main() { std::vector\u003cint\u003e v = {4, 3, 2, 1}; int sum = 0; std::for_each(v.begin(), v.end(), [\u0026] (int vi) { sum += vi; }); std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } 现代 C++14 支持 lambda 用 auto 自动推断类型。 #include \u003cvector\u003e #include \u003ciostream\u003e #include \u003calgorithm\u003e int main() { std::vector\u003cint\u003e v = {4, 3, 2, 1}; int sum = 0; std::for_each(v.begin(), v.end(), [\u0026] (auto vi) { sum += vi; }); std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } 当代 C++17 拥有 CTAD（compile-time argument deduction），可以进行编译期参数推断，但是需要在 CMAKE 中添加 set(CMAKE_CXX_STANDARD 17)。同时还引入常用数值算法。 #include \u003cvector\u003e #include \u003ciostream\u003e #include \u003calgorithm\u003e int main() { std::vector v = {4, 3, 2, 1}; int sum = 0; std::for_each(v.begin(), v.end(), [\u0026] (auto vi) { sum += vi; }); std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } #include \u003cvector\u003e #include \u003ciostream\u003e #include \u003cnumeric\u003e int main() { std::vector v = { 4, 3, 2, 1 }; // 下面三者效果等同 //int sum = std::reduce(v.begin(), v.end(), 0, [](int x, int y) { // return x + y; //}); // 下面两种就是引入常用数值算法，主要实现在 \u003cnumeric\u003e 头文件中 //int sum = std::reduce(v.begin(), v.end()); int sum = std::reduce(v.begin(), v.end(), 0, std::plus{}); std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:1:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"头文件\rC++ 包含标准 C 语言头文件，对于原本 C 的头文件，C++ 有两种方式进行引用，一种是原有的方式（后面跟 .h），一种就是去掉 .h，在库前面添加一个 c 标识这是原本 C 的头文件。对于自己写的头文件还是原方式进行引用，即 \"\"。 #include \u003ciostream\u003e // 基本输入输出 #include \u003ccstdio\u003e // 在原来 C 语言的库前面加一个 c，去掉 .h #include \u003cstdio.h\u003e // 采用原有方式进行引用 #include \"myFile.h\" // 自己的文件，采用原有方式引用 ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:2:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"命名空间\r","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:3:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"基础知识\r命名空间增加了标识符的使用率，减少因为命名产生的冲突。对于命名空间而言，其中的变量和函数等都是属于自己这个空间的，需要通过标识空间名来指明数据的归属，这样可以使得不同命名空间可以存在同样名称的数据，它们之间不会产生冲突。 声明命名空间：namespace 空间名{}，命名空间的声明不能写在函数中 访问数据：空间名::空间中的成员名 省略前缀的方式：using namespace 空间名，表示从这个地方开始，后面都可以省略前缀。 #include \u003ciostream\u003e using namespace std; // 标准命名空间 namespace A{ int num = 1; void print(){ printf(\"A\\n\"); } } namespace B{ int num = 2; void print(){ printf(\"A\\n\"); } } namespace C{ namespace D{ int cd_num = 3; } } int g_num = 1001; int main(){ // 使用省略前缀的方式，可以直接使用其中的函数 cout \u003c\u003c \"命名空间\" \u003c\u003c endl; std::cout\u003c\u003c \"命名空间\" \u003c\u003c endl; // 不同命名空间访问数据 A::num = 2; B::print(); // 省略前缀方式访问数据 using namespace A; num = 3; // A 命名空间数据 using namespace B; B::num = 4; // B 命名空间数据，省略前缀需要注意二义性的问题，所以还需要标识命名空间 // 嵌套命名空间 C::D::cd_num = 5; using namespace C::D; cd_num = 5; // :: 为作用域分辨符，同时可以用于指明全局变量 int g_num = 11; printf(\"num %d\\n\", g_num); // 变量访问采用就近原则，这里就是访问上面的局部变量，返回 11 printf(\"num %d\\n\", ::g_num); // 使用作用域分辨符，指明访问全局变量，返回 1001 return 0; } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:3:1","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"内联命名空间\r对于嵌套命名空间，访问需要使用多层空间名，但是可以采用内联命名空间的方式直接进行访问。 #include \u003ciostream\u003e using namespace std; namespace Version{ inline namespace v2017{ void showVersion(){ cout \u003c\u003c \"v2017\" \u003c\u003c endl; } } namespace v2020{ void showVersion(){ cout \u003c\u003c \"v2020\" \u003c\u003c endl; } } } int main(){ // 上面采用内联命名空间，即添加了 inline，设置了默认的情况，使得下面的两个语句效果等价。 // Version::v2017::showVersion(); Version::showVersion(); } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:3:2","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"动态内存分配\rC 的动态内存采用函数 malloc calloc realloc free，具体可以从 堆基础 获取详细介绍。而 C++ 使用 new delete 操作符进行动态内存分配。但是当前这种分配方式还是容易产生一系列问题，所以引入了 RAII（Resource Acquisition Is Initialization）的思想，它认为资源获取就是初始化，反之，资源释放就是销毁，具体可以看下面 RAII 与智能指针 的部分，那么之后面对这样的情况，就应该使用智能指针，不再使用 new delete。 #include \u003ciostream\u003e using namespace std; void showArr(int* arr, int len){ for (int i = 0; i \u003c len; i ++){ cout \u003c\u003c arr[i] \u003c\u003c \" \"; } cout \u003c\u003c endl; } int main(){ // C 内存分配 int *p = (int*)calloc(5, sizeof(int)); showArr(p, 5); // calloc 会初始化为 0，所以可以直接打印 free(p); p = nullptr; // free 只是清除空间，还需要制空指针，不然就是一个野指针 // C++ 内存分配 int* page = new int; // 申请一个 int *page = 19; // 这里简单 new 不会初始化为 0，需要自行设置值 // int* page = new int(19); // 可以使用 c++ 的括号赋值直接进行赋值 cout \u003c\u003c *page \u003c\u003c endl; delete page; page = nullptr; page = new int[29]; // 申请一个数组，这里也不会初始化，所以可以采用下面的括号赋值，后面自动初始化为 0；或者使用 for 循环进行赋值 // page = new int[29]{1, 2, 3, 7, 12, 12}; showArr(page, 29); delete[] page; page = nullptr; return 0; } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:4:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"Lambda 表达式\rC++ 中 lambda 表达式语法为 [capture](parameters) -\u003e return_type { body }，相关描述如下： capture：变量捕获，定义了 lambda 如何捕获上下文中的变量 parameters：函数参数列表 return_type（可选）：定义返回类型（通常省略，由编译器推导） body：函数体 ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:5:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"Capture Clause\r这里定义的就是 lambda 是否可以捕获上下文的相关变量，直接写变量就是 按值捕获，加上 \u0026 就是按 引用捕获。 [] 表示不捕获上下文变量 [N, \u0026M] 表示 N 为按值捕获，不能修改原变量的值，M 为引用捕获，可以修改外围变量的值 [\u0026] 表示按照引用捕获，捕获所有封闭范围的变量，也就是所有在 lambda 外部作用域中定义的变量都通过引用传递给 lambda [=] 同上含义，但是表示所有的变量都按值捕获 [\u0026, =N] 表示 N 为按值捕获，其他变量都是按引用捕获 [this] 在某个 class 中使用匿名函数，可以通过这个方式捕获当前实例的指针 [*this] C++17，之后还可以按值捕获该实例 [N, \u0026M, K=5] C++14 之后，可以在捕获语句中定义新的变量并初始化，这样的变量 K 无需出现在匿名函数外围环境中 ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:5:1","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"Parameters\rC++ 14 之后，参数列表支持 auto 类型，例如 [](auto a, auto b) {return a + b;}，这个让匿名函数变的更通用更泛型。 ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:5:2","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"枚举类型\rC 和 C++ 都提供了枚举类型，两者有一定的区别。这里主要就是 C++ 的枚举类型，不涉及 C 的。 ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:6:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"enum 枚举类型\rC++ 中的 enum 就是枚举类型的标识符，它只允许赋值枚举值；同时枚举元素会暴露在外部作用域，两个不同枚举类型若是含有相同枚举元素，会产生冲突；不同的枚举可以直接进行比较 // 定义 enum WEEK {MON, TUE, WED, THI, FIR, SAT, SUN}; enum SHAPE {CIRCLE, RECT, POINT, LINE}; // 只允许赋值枚举值，前面的 enum 不进行添加就可以使用 WEEK today = 3; // 错误 error C2440：“初始化”：无法从“int”转换为“main::WEEK” today = CIRCLE; // 错误 error C2440：“=”：无法从“main::SHAPE”转换为“main::WEEK” // 枚举元素暴露在外部作用域 enumc OTHER {RECT}; // 错误 error C2365：“RECT”：重定义；以前的定义是“枚举数” Int RECT = 12; // 错误同上，但是可以通过枚举名访问指定的枚举属性 OTHER::RECT; // 正确 // 不同类型的枚举也可以直接比较 if (CIRCLE == MON){ cout \u003c\u003c \"yes\" \u003c\u003c endl; } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:6:1","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"enum class 强枚举类型\r这里强枚举类型不会将枚举元素暴露在外部作用域，必须通过枚举名去访问；同时不相关的两个枚举类型不能直接比较，编译报错 // 定义 enum class WEEK {MON, TUE, WED, THI, FIR, SAT, SUN}; enum class SHAPE {CIRCLE, RECT, POINT, LINE}; // 不暴露在外部作用域 cout \u003c\u003c SHAPCE::RECT \u003c\u003c endl; // 输出 1 // 不相关的两个枚举类型不能直接比较 if (SHAPCE::RECT == WEEK::MON){ // error c2676：二进制“==\"：“main::SHAPE\"不定义该运算符或到预定义运算符可接收的类型的转换 cout \u003c\u003c \"yes\" \u003c\u003c endl; } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:6:2","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"内联函数\r函数调用时，需要跳转到函数的地址去执行，执行完成后返回到被调用函数，比较费时，因此，C++中提供了一种操作方式，允许编译时直接把函数替换到调用处，即内联函数，它没有普通函数调用时的额外开销（压栈，跳转，返回）。在函数前面加上 inline 申明为内联函数。 内联函数声明时 inline 关键字必须和函数定义结合在一起，否则编译器会直接忽略内联请求。 C++ 编译器不一定准许函数的内联请求（只是对编译器的请求，因此编译器可以拒绝） 现代C++编译器能够进行编译优化，因此一些函数即使没有 inline 声明，也可能被编译器内联编译 #include \u003ciostream\u003e using namespace std; // 宏定义，会在编译的时候（预处理）进行替换，节省空间和时间，效率高，不会类型检查 #define MAX(a, b) a \u003e b ? a : b; // 内联函数，用来替换宏定义。inline 是关键字 /* 1. 不能存在任何形式的循环语句，不能存在过多的条件判断语句 2. 函数体不能过于庞大，不能对函数进行取址操作 3. 编译器对于内联函数的限制并不是绝对的，内联函数相对于普通函数的优势只是省去了函数调用时压栈，跳转和返回的开销。因此，当函数体的执行开销远大于压栈，跳转和返回所用的开销时，那么内联将无意义。 */ inline int mmax(int a, int b){ return a \u003e b ? a : b; } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:7:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"强制类型转化\rC 风格的强制类型转换很简单，据使用 Type b = (Type)a 形式进行转换。但是 C 风格的类型转换有不少缺点：万物皆可转，不容易区分，不容易查找代码。因此 C++ 提供了四种类型转换操作符来应对不同场合。 类型转换操作符 作用 static_cast 静态类型转换，编译器做类型检查，基本类型能转换，指针不能 reinterpret_cast 重新解释类型 const_cast 去const属性 dynamic_cast 动态类型转换，运行时检查类型安全（转换失败返回nullptr）如子类和父类之间的多态类型转换 #include \u003ciostream\u003e using namespace std; class Animal { public: virtual void cry() = 0; virtual ~Animal(){} }; class Dog:public Animal { public: void cry() override{ cout \u003c\u003c \"狗吠\" \u003c\u003c endl; } void seeHome(){ cout \u003c\u003c \"看家\" \u003c\u003c endl; } }; class Cat:public Animal { public: void cry() override{ cout \u003c\u003c \"猫叫\" \u003c\u003c endl; } void catchMouse(){ cout \u003c\u003c \"抓老鼠\" \u003c\u003c endl; } }; void obj(Animal* base){ base-\u003ecry(); // Dog：看家 // ((Dog*)base)-\u003eseeHome(); // 这种行为，不会根据传入参数的实际对象进行相应函数调用，而是只要转换就进行调用，也就是这样没有安全检查 Dog* dog = dynamic_cast\u003cDog*\u003e(base); // 这里运行时进行判断，如果转换成功返回子类所在地址，转换失败返回空指针 if (dog) { dog-\u003eseeHome(); } // Cat：抓老鼠 //((Cat*)base)-\u003ecatchMouse(); Cat* cat = dynamic_cast\u003cCat*\u003e(base); if (cat) { cat-\u003ecatchMouse(); } } int main(){ // 1. static_cast 类似 C 风格的强制转换，进行无条件转换，静态类型转换。 /* 基本数据类型转换，enum，struct，int，char，float 等。static_cast 不能进行无关类型（如非基类和子类）指针之间的转换。 可以用于 void* 和其他指针类型之间的转换（但是不能用于非 void 指针之间的转换） 不能用于两个不相关类型的转换，如 int 和 int* 之间的转换，虽然二者都是四个字节，但他们一个表示数据，一个表示地址，类型不相关，无法进行转换。 */ int age = 10; // double d = age; // 隐式类型转换 // double d = (double)age; // C 风格转换 double d = static_cast\u003cdouble\u003e(age); int* p = \u0026age; // double* pd = (double*)p; // 正确 // double* pd = static_cast\u003cdouble\u003e(p); // error C2440：“static cast”：无法从“int *”转换为“double *” void* pv = static_cast\u003cvoid*\u003e(p); // 正确 double* pdd = static_cast\u003cdouble*\u003e(pv); // 正确 // 2. reinterpret_cast 专门用来转换指针 double *pd = reinterpret_cast\u003cdouble*\u003e(p); // 正确 // 3. const_cast 去掉 const 属性 const int week = 7; // week = 5; // 错误，不能直接修改常量 int\u0026 rint = const_cast\u003cint\u0026\u003e(week); rint = 5; // 正确，可以去掉 const 属性，但是原先的值没有进行修改 // 4. dynamic_cast 把父类指针转为子类指针（判断父类指针指向的是哪个子类对象） Animal* pdog = new Dog; Animal* pcat = new Cat; obj(pdog); obj(pcat); } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:8:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"RAII 与智能指针\r","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:9:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"unique_ptr\r在没有智能指针的 C++ 中，我们只能手动去 new 和 delete 指针。这非常容易出错，一旦忘记释放指针，就会导致内存泄露等情况。因此 C++11 引入了 unique_ptr 容器，它的结构函数中会调用 delete p，因此不会造成忘记释放指针的情况，同时这里释放之后，就会把指针设置为 nullptr，防范了空悬指针的情况。 #include \u003ccstdio\u003e #include \u003cmemory\u003e struct C { C() { printf(\"分配内存!\\n\"); } ~C() { printf(\"释放内存!\\n\"); } }; int main() { std::unique_ptr\u003cC\u003e p = std::make_unique\u003cC\u003e(); if (1 + 1 == 2) { printf(\"出了点小状况……\\n\"); return 1; // 自动释放 p } return 0; // 自动释放 p } 同时 unique_ptr 删除了拷贝构造函数，所有直接进行调用会出错，也就是 func(std::unique_ptr\u003cC\u003e p) -\u003e func(p) 会因为触发一次拷贝而报错。因此需要分以下两种情况进行调用。 #include \u003ccstdio\u003e #include \u003cmemory\u003e struct C { C() { printf(\"分配内存!\\n\"); } ~C() { printf(\"释放内存!\\n\"); } void do_something() { printf(\"成员函数!\\n\"); } }; void func1(C *p) { p-\u003edo_something(); } std::vector\u003cstd::unique_ptr\u003cC\u003e\u003e objlist; void func2(std::unique_ptr\u003cC\u003e p) { objlist.push_back(std::move(p)); // 进一步移动到 objlist } int main() { std::unique_ptr\u003cC\u003e p = std::make_unique\u003cC\u003e(); // func1() 不需要资源的占有权，即不需要生命周期，那么就可以使用原始指针 func1(p.get()); // func2() 需要生命周期，所以可以使用移动构造函数 printf(\"移交前：%p\\n\", p.get()); // 不为 null func2(std::move(p)); // 通过移动构造函数，转移指针控制权 printf(\"移交后：%p\\n\", p.get()); // null，因为移动会清除原对象，如果需要保留，那么就提前使用 C *raw_p = p.get(); 进行获取 return 0; } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:9:1","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"shared_ptr\rshared_ptr 是更为智能的指针，它牺牲效率换来自由度，允许拷贝，它解决重复释放的方式是通过引用计数： 当一个 shared_ptr 初始化时，将计数器设为1 当一个 shared_ptr 被拷贝时，计数器加1 当一个 shared_ptr 被解构时，计数器减1。减到0时，则自动销毁他指向的对象 这样就可以保证，只要还有存在哪怕一个指针指向该对象，就不会被解构。同时我们可以使用 p.use_count() 来获取当前指针的引用计数。 #include \u003ccstdio\u003e #include \u003cmemory\u003e #include \u003cvector\u003e struct C { int m_number; C() { printf(\"分配内存!\\n\"); m_number = 42; } ~C() { printf(\"释放内存!\\n\"); m_number = -2333333; } void do_something() { printf(\"我的数字是 %d!\\n\", m_number); } }; std::vector\u003cstd::shared_ptr\u003cC\u003e\u003e objlist; void func(std::shared_ptr\u003cC\u003e p) { objlist.push_back(std::move(p)); // 这里用移动可以更高效，但不必须 } int main() { std::shared_ptr\u003cC\u003e p = std::make_shared\u003cC\u003e(); // 引用计数初始化为 1 func(p); // shared_ptr 允许拷贝！和当前指针共享所有权，引用计数加 1 func(p); // 多次也没问题，多个 shared_ptr 会共享所有权，引用计数加 1 p-\u003edo_something(); // 正常执行，p 指向的地址本来就没有改变 objlist.clear(); // 刚刚 p 移交给 func 的生命周期结束了！引用计数减 2 p-\u003edo_something(); // 正常执行，因为引用计数还剩 1，不会被释放 return 0; // 到这里最后一个引用 p 也被释放，p 指向的对象才终于释放 } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:9:2","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"指针相关\r下面列举了使用指针类型取相关变量的数据，这里假设 eax = 0x401234 它存储了一个地址，而这个地址存储数据 0x12345678，那么对于下面的指针会获取不同的数据。 *(char*)eax; *(int*)eax; 对于 *(char*)eax;，首先 (char*)eax 将寄存器 eax 的值转换为 char* 类型，意味着 eax 被看作是指向一个字符的指针。而 *(char*)eax 是对该地址处的数据进行解引用操作，因为已经把 eax 强制转换为 char*，所以此时解引用会得到这个地址处的一个字符。因此它只会取得该地址处的 最低字节，即 0x78（注意小端序存储，0x78 0x56 0x34 0x12 顺序的数据会转化为 0x12345678） 对于 *(int*)eax; 也是同样的理解，最终会获取数据 0x12345678。 ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:10:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["config"],"content":"关于 Android Studio 的使用和配置。 ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:0:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"Gradle下载配置\r直接更换国内腾讯 镜像源，打开 gradle - wrapper -gradle-weapper.properties 进行更改。然后点击 Sync Now 进行同步。参考-\u003e Android导入项目时Gradle下载速度慢_导入gradle项目特别慢 #Sun Feb 25 20:22:32 GMT+08:00 2024 distributionBase=GRADLE_USER_HOME distributionPath=wrapper/dists distributionUrl=https\\://mirrors.cloud.tencent.com/gradle/gradle-8.2-bin.zip # 这里就对应替换为腾讯的镜像地址 zipStoreBase=GRADLE_USER_HOME zipStorePath=wrapper/dists 但是这样也是很慢，还是得等，有时候还会突然跑到源地址去下载，搞不明白。(后续补充：有时候改了国内源，然后停止加载zip文件，之后重试一下就快很多了) ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:1:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"新版 AS 添加依赖\r这里是在 settings.gradle.kts 文件中添加 maven 仓库，然后在 app 的 build.gradle.kts 文件中添加依赖。查看这里Android Studio | 2022.3.1版本解决创建项目下载gradle缓慢问题 // settings.gradle.kts 文件中 dependencyResolutionManagement { repositoriesMode.set(RepositoriesMode.FAIL_ON_PROJECT_REPOS) repositories { google() mavenCentral() maven { url = uri(\"https://jitpack.io\") }// as改版后的新添加方式 } } // build.gradle.kts 文件中 dependencies { implementation(\"com.github.Hitomis:CircleMenu:v1.1.0\") // as改版后的新添加方式 } ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:2:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"SD卡读写权限\r对于低版本 sdk，只需要以下权限即可(在AndroidManifest.xml中修改)，在manifest标签中添加 \u003cuses-permission android:name=\"android.permission.READ_EXTERNAL_STORAGE\"\u003e\u003c/uses-permission\u003e \u003cuses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\"\u003e\u003c/uses-permission\u003e 而对于高版本的 sdk，这里是34，则需要添加东西。新加入的在application标签中添加 \u003cuses-permission android:name=\"android.permission.READ_EXTERNAL_STORAGE\"\u003e\u003c/uses-permission\u003e \u003cuses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\"\u003e\u003c/uses-permission\u003e \u003cuses-permission android:name=\"android.permission.MANAGE_EXTERNAL_STORAGE\"\u003e\u003c/uses-permission\u003e android:requestLegacyExternalStorage=\"true\" ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:3:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"dataBinding使用\r刚开始创建的 Launch Activity 不用理会，但是对于新增加的Activity，想要使用 dataBinding 功能，就需要先在 build.gradle.kts文件中添加下面代码： android { ...... buildFeatures { dataBinding = true // 确保这里启用了数据绑定 } } 然后在相关 xml 文件中，对准 androidx.constraintlayout.widget.ConstraintLayout按下alt + enter 转化为 databinding 的模式。这样后续的 activity 才可以使用并编译apk成功。 ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:4:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"图片导入\r资源主要就是存放在 res 目录下，如下表所示各个目录的作用。 目录 作用 drawable 存放所有的图片及图标配置（xml文件展示） layout 布局，创建一个Activity一般会同步创建一个布局。 mipmap 存放各种分辨率的图标，平常用的就是 xxhdpi values 一些固定的配置，例如值，主题等 这里 drawable 存放的东西大多就是 图标的配置，在 As 中可以利用 File → New → Android Resource File 来生成一个配置文件，例如背景之类的可以重复使用。 同时使用File → New → Image Asset 可以创建 app 应用的图标，提供 svg 图片即可自动创建。使用File → New → Vector Asset 则是创建图片，将一个 svg 格式的图片转化为 xml 文件形式，然后供 ImageView 等控件使用。如果只有 png 格式的图片，首先需要转化为 svg 格式，这里推荐网站，其余网站转化的 svg 可能存在问题，As 不一定可以使用。 ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:5:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"So文件生成\r","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:6:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"添加新文件\r对于头文件 .h 首先在 cpp 目录下创建相应文件，然后在 CmakeLists.txt 文件中添加下面的代码 include_directories( basic.h ) 对于文件 .cpp 在 cpp 目录下创建，然后在 CmakeLists.txt 文件中的 add_libraty 添加新创建的 .cpp文件。这样多个 .cpp 文件就会编译为一个 so 库。 add_library(${CMAKE_PROJECT_NAME} SHARED # List C/C++ source files with relative paths to this CMakeLists.txt. native-lib.cpp checkfrida.cpp) 添加文件\r","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:6:1","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"编译多个so文件\r这里就是再添加一个 add_library 文件，这样就可以编译为多个了。 add_library( # so 文件的名字 checkroot # 共享库 SHARED # List C/C++ source files with relative paths to this CMakeLists.txt. checkroot.cpp) 编译多个文件\r","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:6:2","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"引入第三方库\r使用第三方库的函数 这里就是利用 target_link_libraries 进行引用，注意对于每一个so文件，都需要进行引用操作。这里上面的是默认的，要是能在 checkroot.cpp 文件中使用 log，那么就需要自己手动进行引用了。 target_link_libraries( checkroot # List libraries link to the target library android log ) 引入库\r","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:6:3","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"使用汇编配置\r起因就是需要使用 SVC 这条汇编语句完成 frida 的检测，但是查阅资料不知道怎么进行，最后终于尝试成功了，在此记录流程。 代码设置\r这里是复制 参考资料 的代码，然后做了删减达到了下面的效果。 bionic_asm.h ，它包含了汇编语言需要的一些基础配置，例如 \u003casm/unistd.h\u003e 中的系统调用号，MAX_ERRNO 是最大错误号的定义。最为关键的就是对于 ENTRY 和 END 的定义，没有这个定义，下面的汇编语言也就是会识别错误。同时这里和下面的 syscall.S 文件一样，只定义了 aarch64 ， x86_64 两个架构，所以在build.gradle.kts 的 abiFilters 选项也只能存在两个架构，不然会因为其他架构的汇编不存在而报错。 #pragma once #include \u003casm/unistd.h\u003e /* For system call numbers. */ #define MAX_ERRNO 4095 /* For recognizing system call error returns. */ #define __bionic_asm_custom_entry(f) #define __bionic_asm_custom_end(f) #define __bionic_asm_function_type @function #define __bionic_asm_custom_note_gnu_section() #if defined(__aarch64__) #define __bionic_asm_align 16 #elif defined(__x86_64__) #define __bionic_asm_align 16 #endif #define ENTRY_NO_DWARF(f) \\ .text; \\ .globl f; \\ .balign __bionic_asm_align; \\ .type f, __bionic_asm_function_type; \\ f: \\ __bionic_asm_custom_entry(f); \\ #define ENTRY(f) \\ ENTRY_NO_DWARF(f) \\ .cfi_startproc \\ #define END_NO_DWARF(f) \\ .size f, .-f; \\ __bionic_asm_custom_end(f) \\ #define END(f) \\ .cfi_endproc; \\ END_NO_DWARF(f) \\ /* Like ENTRY, but with hidden visibility. */ #define ENTRY_PRIVATE(f) \\ ENTRY(f); \\ .hidden f \\ /* Like ENTRY_NO_DWARF, but with hidden visibility. */ #define ENTRY_PRIVATE_NO_DWARF(f) \\ ENTRY_NO_DWARF(f); \\ .hidden f \\ #define __BIONIC_WEAK_ASM_FOR_NATIVE_BRIDGE(f) \\ .weak f; \\ #define ALIAS_SYMBOL(alias, original) \\ .globl alias; \\ .equ alias, original #define NOTE_GNU_PROPERTY() \\ __bionic_asm_custom_note_gnu_section() 这里就是 syscal.S 文件，它这里实现了对于 openat 函数的底层汇编，但是因为这里找不到 __set_errno_internal 这个函数所在的文件，没有办法链接，所以直接注释掉。因为这个就是对于错误进行处理的函数，就是运行失败之后进入错误处理再返回，告知错误的类型。我这里不需要进行维护，所以错误的类型可有可无，直接注释即可。 #include \"bionic_asm.h\" #if defined(__aarch64__) ENTRY(my_openat) mov x8, __NR_openat svc #0 cmn x0, #(MAX_ERRNO + 1) cneg x0, x0, hi // b.hi __set_errno_internal ret END(my_openat) #elif defined(__x86_64__) ENTRY(my_openat) movl $__NR_openat, %eax syscall cmpq $-MAX_ERRNO, %rax jb my_openat_return negl %eax movl %eax, %edi // call __set_errno_internal my_openat_return: ret END(my_openat) #endif 然后最后在需要使用外部汇编文件的代码中加入下面这一条代码。这样才可以进行函数的调用。 extern \"C\" int my_openat(int dirfd, const char *const __pass_object_size pathname, int flags, mode_t modes); AS 配置\rCMakeLists.txt\r添加 enable_language(ASM)，允许使用汇编语言，不加这个就会报错。同时下面链接库添加新增的上面的两个文件，保证可以整合到一个 so 文件中。 enable_language(ASM) add_library( # so 文件的名字 checkfrida # 共享库 SHARED # List C/C++ source files with relative paths to this CMakeLists.txt. checkfrida.cpp asm/bionic_asm.h asm/syscall.S ) build.gradle.kts\r在 android-—defaultConfig 的路径下添加 ndk，这里的 abiFilters 和官网给的样例不一致，具体看 参考资料，需要使用特定格式进行架构的添加。这里查看下面 使用不同结构的代码。同时这里因为只写了两种架构的 SVC 汇编，所以固定了架构，因此最后生成的 so 就只有这两种架构的文件了。如果不定义这个配置，那么默认就是会存在四种架构的 so 文件。 ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:6:4","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"使用不同架构\rAs 进行了改版，所以之前的方式不能使用了。这里是在 app 的 build.gradle.kts 文件中添加。下面展示了两种方式。 android { ... defaultConfig { ... ndk { // 第一种方式 abiFilters.addAll(arrayOf(\"arm64-v8a\", \"x86_64\")) // 第二种方式 //abiFilters.add(\"arm64-v8a\") //abiFilters.add(\"x86_64\") //abiFilters.add(\"armeabi-v7a\") //abiFilters.add(\"x86\") } } } ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:6:5","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"相关操作\r","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:7:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"存储空间管理\r移动 .gradle 到指定位置 将 .gradle文件 从C盘移动到D盘，这里同时还需要相应修改 idea.plugins.path 和 idea.log.path 移动 .android 到指定位置 解决方案 ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:7:1","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"生成apk\rbuild -\u003e Generate Signed Bundle or APK：选择APK，然后创建key（注意需要路径完整），之后再选择 release 即可 生成的 app-debug.apk 在路径 /app/build/outputs/apk/debug/ 下面，或者在 /app/build/intermediates/apk/debug/ 目录下。这里不知道是什么的变化引起的生成存放目录的变化。 build → Generate Signed Bundle or APK 可以生成签名后的 apk（release版本），它存放在和 debug类似的目录下。这里我的 vivo 手机不能使用 debug 版本，只能下载 release 版本。 ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:7:2","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"报错汇总\r遇到问题 Cannot use connection to Gradle distribution 'https://mirrors.cloud.tencent.com/gradle/gradle-8.2-bin.zip' as it has been stopped. 这里直接关闭项目，再重新打开即可。 Error running 'app': Default Activity not found 这里修改 configuration，更改 Launch Options -\u003e Launch:nothing android studio怎么运行没有activity的service、broadcastReceiver、cotentProvicer等 日志不能在 As 中显示 检查算法助手有没有 hook 对应程序，如果存在，那么它好像开机自启，自动将日志捕获了。关闭应用 hook 就可以显示日志了 ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:8:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"自己对于 FixIt 主题的一些配置 ","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:0:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"大致流程\r这里我使用的就是Git 子模块的安装方式，更详细的流程参照这篇快速上手。在必要的配置后，博客就可以进行本地浏览了。之后我使用 Github Action 的方式，将本地博客的所有文件上传到一个私密仓库，之后创建 Github Action 将通过 hugo --gc --minify 命令构建的 public 目录上传到另一个公开仓库 blog 中，这样就可以设置静态网站进行博客访问了，具体可以参考Huogo 主题配置。这样博客基本上就好了，可以开始额外的操作了。 ","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:1:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"图片自适应\r我使用的图片都是存储在图床中的，使用的就是 Markdown 的经典语法。但是它在 FixIt 的渲染中会左对齐，有时还会在图片后面跟随文字，感官很不好，所以思考怎么进行改进。在参考FixIt主题使用lightgallery自适应显示图片之后，自己进行了调整，达到了现在的效果。 这里主要参照上述参考文章的两种尝试，采用 lightgallery 来呈现图片。我参照 FixIt配置篇 将 lightgallery 设置为 \"force\" 但是如果没有 alt 和 title 属性，我的图片不会按照画廊形式呈现，所以我只能另辟蹊径。因为我使用 PicGo 进行图床配置，刚好它支持修改本地输出图片链接的格式，因此我修改PicGo的配置，把 Custom Output Format 配置为![${uploadedName}](${url} \"${uploadedName}\")。这样它会自己填充 alt 和 title，我只需要按照自身需求修改 alt 属性即可。 另外点击图片之后会显示 alt 和 title 两个信息，所以打开 F12 进行观察，发现第一行来自标签 \u003ch2\u003e，也是 alt 属性，第二行来自标签 \u003cp\u003e，是 title 属性。这部分都是在 themes/layouts/partials/plugin/image.html 中，所以直接修改主题文件，把这里的 \u003cp\u003e 删除，然后 \u003ch2\u003e 移动到中间，这样渲染的时候只会在下面出现 alt 属性了，放大图片和鼠标移动到图片上才会看到 title 属性。 修改配置文件\r","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:2:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"GitHub 提交记录贪吃蛇动画\r参照GitHub 提交记录贪食蛇动画进行配置，不过我将 Github Action 写在了同名仓库中了，这样就少创建了一个仓库，其他都是按照参考文章所述的进行配置即可。插一嘴，本来想把 github-metrics.svg 单独放在一个分支中，但是不熟悉自动化部署脚本，配置了一会儿发现总是部署失败，所以直接使用GitHub 个人主页美化教程来进行配置了。 ","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:3:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"配置文章修改时间\rFixit 的 frontmatter 有一个属性 lastmod，它就是文章最后修改时间，一开始的配置不知道有没有效果，但是还是参照 loveit主题配置 之后，形成了现在的配置。 当前配置是在 atchetypes/default.md 文件中，设置 lastmod: {{ .Date }}。config/_default/hugo.toml 中设置 enableGitInfo = true， 同时在 config/_default/params.toml 中，找到 [gitInfo] 选项，设置 repo 为自己 public 目录发布的仓库地址。这样就会在文章左下角和一开始的信息标识处显示更新时间。 这里的文章修改时间很玄学，要么新创建的文章上面信息展示的地方没有修改时间，要么地下的修改时间没有提交的 hash 值，要么修改的文章信息没有变化。最近一次成功修改还是通过 git 将 content 和 public 中的所有文件都删除，然后再提交之后才可以进行时间修改的，但是这个时候所有文章的修改时间都一样了。所以目前初步认为起关键作用的还是 content 目录下面文件的 git 提交时间，之后修改了文件，就不直接使用 add 进行添加了，而是把文件先删除，之后再提交，这样不知道会不会正确显示修改时间。 验证发现 git add . 也能发挥作用，但是修改后直接进行 hugo --gc --minify 提交发现不会出现修改信息，之后本地使用 hugo server -D 反而出现了修改时间。之后尝试首先本地部署，再进行生成，发现该效果会呈现出最新的修改时间。（这里的办法没用，目前得到的信息就是本次的修改不会改变本次的修改时间，只有下一次的 push 才会真正显示出上一次的修改，所以目前只能这样了，只要修改时间不像之前一样突然没有了就行）。 ","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:4:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"网站图标\r对于网站图标实在是束手无策，一开始采用官网配置，但是给的利用网站不能生成符合要求的一系列文件，同时把生成文件都放在/static目录下，最后会把这些文件生成在/public根目录下，很不喜，所以放弃了这种方法。后来尝试和 author 的 avatar 属性配置一样，把 svg 图片放在images目录下，但是展示不出来。最后看到别人文章，发现直接使用图床的图片可以生成，所以我现在也是利用这样的方式展示网站图标。 ","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:5:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"阅读原始文档\r可以看到左下角存在 阅读原始文档 的选项，点击就直接可以看到 markdown 的原文本了，当然这个是我们不想要的（虽然网页直接下载 pdf 也是一样的）。因此我们可以设置配置中的 outputs.toml 文件，在 page 中去除 markdown，这样点击就不会看到我们的源码了。 配置修改\r","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:6:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"Git 提交\r受上面 配置文章修改时间 的影响，记录下这里的 git 操作，以便之后忘记了还可以看这里进行会议。 # 本地预览渲染效果 hugo server -D # 最小化生成渲染文件 hugo --gc --minify # 将修改和新增的文件信息都添加到暂存区 git add . # 将删除文件信息添加到暂存区 git rm xxx # 根据暂存区信息提交代码到本地仓库 git commit -m \"xxx\" # 推送本地仓库代码到远程仓库 git push -u origin main 经过上面的操作，就会把代码传到 github 上了，之后使用 GitHub Action 把 public 传到公开仓库中，之后就可以根据静态页面进行查看了。这里还可以使用 Vscode 的提交板块，它应该和 jetbrains 的产品一样，内置了删除的操作，所以我们只需要写 commit 信息然后一直点击按钮就可以进行提交了，不需要区分添加修改和删除操作（这里我没有试过，只是猜测，但是 jetbrains 和 As 的 commit 是这样设计的）。 ","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:7:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"数学公式\r本来这个只是一个小问题，但是后来发现只要公式渲染出现问题，大概就是这个原因，所以记录一下 fixit 的数学公式渲染。主要的解决方案就是在 fixit 数学公式 的“关于转义字符相关的注意事项”，这里就是 Hugo 渲染的时候，数学公式中的有些字符和 HTML 产生冲突，所以需要转义处理。这里已经罗列了很多需要转移的字符，但是除此之外还有一些，这里通过 Latex 语法来显示额外也需要进行转义的字符： { -\u003e \\\\{ } -\u003e \\\\} $ -\u003e \\\\$ ","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:8:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"一些关于 git 的操作 git流程\r","date":"2024.11.1","objectID":"/blog/posts/config/git/:0:0","tags":["config"],"title":"Some about Git","uri":"/blog/posts/config/git/"},{"categories":["config"],"content":"相关命令\r# 本地仓库初始化 git init # 将文件提交到暂存区 git add [file name] git add . # 添加全部修改和新增文件 # 将文件提交到本地仓库 git commit [file name] git commit -m \"commit information\" [file name] git commit -m \"commit inforamtion\" # 提交全部到本地仓库 # 添加远程仓库，这里是因为存在多个 git 用户所进行的配置，正常为 git@github:czTangt/blog.git git remote add origin git@github_czTangt:czTangt/blog.git # 提交到远程仓库 git push -u origin [branch name] git push -f # 强制提交 # 分支操作 git checkout [branch name] # 切换分支 git branch -a # 查看所有分支 git checkout -b local_dev origin/remote_dev # 创建本地分支并于远程分支连接 git push origin --delete remote_dev # 删除远程分支 ","date":"2024.11.1","objectID":"/blog/posts/config/git/:1:0","tags":["config"],"title":"Some about Git","uri":"/blog/posts/config/git/"},{"categories":["config"],"content":"文件修改\r对于 git 而言，git add . 会将所有修改和新增的文件信息提交到暂存区，之后使用 git commit -m \"xxx\" 会将暂存区的文件信息提交到本地仓库。但是这种方法是对于新增和修改的文件而言，对于删除的文件信息不会进行更新，所以可以采用两种方案： 使用 git rm xxx 一个一个手动删除文件（rm 命令没有办法使用 git rm . 一起更新全部的文件删除信息），之后这些文件删除信息就提交到暂存区了，后续就可以继续使用 git commit -m \"xxx\" 来将代码提交到本地仓库 使用 git commit -am 命令，该命令会在提交到本地仓库时，先更新修改和删除的文件信息到暂存区（注意它不会提交新增加的文件信息）。所以加了 -a 在 commit 的时候，可以帮助省一步 git add，但是也只是对修改和删除文件有效，新文件还是要 git add，不然就是 untracked 状态。 综上所述：git add 和 git rm 都是等价的操作，前者添加修改和新增文件信息，后者添加删除文件信息，他们都是将文件信息提交到暂存区，之后使用 git commit -m \"xxx\" 来将暂存区的文件信息提交到本地仓库，最后使用 git push -u origin main 来提交本地仓库代码到远程仓库的 main 分支。 ","date":"2024.11.1","objectID":"/blog/posts/config/git/:2:0","tags":["config"],"title":"Some about Git","uri":"/blog/posts/config/git/"},{"categories":["config"],"content":"远程仓库到自己仓库\r拉取别人的仓库到自己仓库，主要应对github中没有对应仓库的情况繁琐指南，存在对应仓库，直接进行 fork，然后在本地添加自己的远程。简单的操作如下： git branch -r | grep -v '\\-\u003e' | while read remote; do git branch --track \"${remote#origin/}\" \"$remote\";done # 获取所有远程分支到本地 git fetch --all # 获取该项目远程库的所有分支及其内容 git fetch --tags # 获取该项目远程库的标签(没标签就不必了) git remote rename origin old-origin # 将原来的origin重命名一下 git remote add origin git@172.28.3.77:xs-soc/test-code.git # 指定需要迁移到新的目标地址(自己的仓库) git push origin --all # 推送所有分支及其内容 git push --tags # 推送所有标签及其内容 git remote rm origin # 删除当前远程库 git branch -M main # 重命名主要分支仓库 git push -u origin main # 推送到指定分支 ","date":"2024.11.1","objectID":"/blog/posts/config/git/:3:0","tags":["config"],"title":"Some about Git","uri":"/blog/posts/config/git/"},{"categories":["config"],"content":"Git 加速\rgit失败的原因绝大多数都是网络问题，所以挂代理是最为推荐的选择。以下是起作用的一些方法 通用方法，更换 git 的代理为 443 SSH：连接到主机github.com端口22：连接时间超时 但是对于 wsl，直接使用最新 wsl2 共用主机的代理即可（最为推荐），不嫌麻烦可以给配置个代理 配置wsl镜像 Windows10系统下配置WSL2自动走Clash代理，之后clash打开allow lan模式即可 WSL2内使用Windows的v2ray代理 | Nafx’s Blog，这是v2的模式，首先最后面设置，然后前面配置bashrc 有时候最后的方法会起点作用 git clone失败解决方案 ","date":"2024.11.1","objectID":"/blog/posts/config/git/:4:0","tags":["config"],"title":"Some about Git","uri":"/blog/posts/config/git/"},{"categories":["config"],"content":"这里就是对于 Vscode 的 PicGo 插件进行配置 ","date":"2024.10.31","objectID":"/blog/posts/config/picgo/:0:0","tags":["config"],"title":"VScode PicGo 插件配置","uri":"/blog/posts/config/picgo/"},{"categories":["config"],"content":"上传配置\r这里因为使用 vscode 来写 Markdown 语法，所以想着仿照之前 Typora + PicGo 配置的剪切板粘贴上传图片功能。这里因为之前在 PicGo 应用中配置过，所以这次就直接获取参数然后输入即可。 配置信息\r这里的配置信息直接从软件中抄过来，或者随便看看阿里云图床的配置文章就可以知道大致该怎么填写了。之后这里 Aliyun: Path 选择之前自己创建的目录，可以通过 OSS -\u003e Bucket -\u003e 文件列表 来查看。另外选择 Pic Bed: Current 为 aliyun，这样上面的配置才可以生效。同时还设置了快捷键，对于使用截图软件，把图片放在剪切板上的情况，修改快捷键为 ctrl + alt +w，这样和普通粘贴分割开了，更加方便。 ","date":"2024.10.31","objectID":"/blog/posts/config/picgo/:1:0","tags":["config"],"title":"VScode PicGo 插件配置","uri":"/blog/posts/config/picgo/"},{"categories":["config"],"content":"文件名设置\rCustom Output Format 就是文件在 vscode 中的展现形式，这里针对 Fixit 主题中 Image 的要求 进行了修改。这样后面的 title 可以直接生成，然后我们需要修改的就是前面的 alt 了。 layouts/partials/plugin/image.html 文件在之前进行修改了，所以图片下面的图标显示的就只有 alt 了，只有鼠标放在图片上面和放大图片显示的才是 title。 本地格式\rCustom Upload Format就是上传文件的格式，随便设置即可，因为不会有太多的格式要求，这里就是默认的配置。 上传格式\r","date":"2024.10.31","objectID":"/blog/posts/config/picgo/:2:0","tags":["config"],"title":"VScode PicGo 插件配置","uri":"/blog/posts/config/picgo/"},{"categories":["config"],"content":"保存路径\r这里有一个 Data Path，vscode 插件会把每次的提交形成 json 数据添加到这个文件中，所以可以设置存储路径，之后查看图片可以迅速找到相关信息。这里我也将路径设置为博客的仓库，使其作为附属信息上传到 github 上。 路径配置\r","date":"2024.10.31","objectID":"/blog/posts/config/picgo/:3:0","tags":["config"],"title":"VScode PicGo 插件配置","uri":"/blog/posts/config/picgo/"},{"categories":["compile"],"content":"这里记录词法分析，正则表达式，自动机的相关知识。 ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:0:0","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"正则表达式与自动机理论\r","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:1:0","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"课程目标\r这里讲解怎么写一个自动化词法分析器生成器。根据前面的理论，我们使用 ANTLR4 来生成词法分析器，其实质上是我们使用 ANTLR4 利用正则表达式（regular expression -\u003e RE）的规则来进行生成词法分析器。同时我们还学习了利用 java 来手写词法分析器，实质就是在使用 java 代码模拟状态转移图，它也就是自动机。那么我们来看 ANTLR4 原理，他就是把 .g4 文件转化为 .java 文件，也就是把正则表达式转化为了自动机，然后通过模拟自动机就可以得到词法分析器了。 因此我们的目标就是通过正则表达式来直接得到得到一个词法分析器。 conversion\r由上图，我们构建词法分析器就是把 RE 转化为 DFA（有穷状态自动机 Deterministic FInite Automata），然后再转化为词法分析器，但是这个过程往往是困难的，所以我们采用简略的方法，通过先转化为 NFA（不确定的又穷状态自动机Nondeteeministic Finite Automata），再转化为 DFA，再进行后续的操作。 ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:1:1","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"编程语言介绍\r语言是字符串构成的集合。 根据这句高度抽象的结论，我们会一层层进行解剖。 字符 字母表 $\\Sigma$ 是一个有限的符号集合，符号没有意义，它的语义是后来自己赋予的。 字符串 字符表 $\\Sigma$ 上的串(s) 是由 $\\Sigma$ 中符号构成的一个有穷序列。 其中 $\\epsilon$ 是空串，我们定义它为零，即 $|\\epsilon| = 0$ 字符串之间存在运算 连接运算， $x = day, y = houce, xy = dayhouce, \\epsilon s = s \\epsilon = s$ 指数运算，$s^{0} \\triangleq \\epsilon$，$s^{i} \\triangleq ss^{i-1}, i\u003e0$，这里存在上标就是连接的意思 语言 语言是给定字母表 $\\Sigma$ 上一个任意的可数的串集合。 $\\empty$，这一个是空集，什么语言都没有；${ \\epsilon }$，这个里面有一个语言，不过是个空串 举例：id：${a,b,c,d,a1}$；ws：${blank, tab, newline }$，if：${ if }$ 我们知道语言是串的集合，正因为是集合，所以我们可以通过集合操作构造新的语言 rules\r","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:1:2","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"RE\r每个正则表达式 r 对应一个正则语言 L(r)。正则表达式是语法（ID：[a-zA-Z][a-zA-Z0-9]*），正则语言是语义（{a1,a2,ab,……}） ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:2:0","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"语法\r给定字母表，$\\Sigma$ 上的正则表达式由且仅由以下规则定义： $\\epsilon$ 是正则表达式 $\\forall a \\in \\Sigma$，a 是正则表达式 如果 r 是正则表达式，则 (r) 是正则表达式 如果 r 与 s 是正则表达式，则 r | s，rs，r* 也是正则表达式 运算优先级：$() \\succ * \\succ 连接 \\succ |$ ，例子：$(a) \\mid ((b)^{*} (c)) \\equiv a | b^{*} c$ ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:2:1","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"语义\r正则表达式对应的正则语言 $L(r)$ $L(\\epsilon) = { \\epsilon}$ $L(a) = a, \\forall a \\in \\Sigma$ $L((r)) = L(r)$ $L(r|s)=L(r) \\cup L(s)\\quad L(rs)=L(r)L(s)\\quad L(r^{*})=(L(r))^{*}$ ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:2:2","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"符号\rsymbol\rsymbol\r","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:2:3","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"自动机\r","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:3:0","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"NFA\r语法\r非确定性有穷自动机 $\\mathcal{A}$ 是一个五元组 $\\mathcal{A} = (\\Sigma, S, s_0, \\delta, F)$ 字母表 $\\Sigma (\\epsilon \\notin \\Sigma)$ 有穷的状态集合 $S$ 唯一的初始状态 $s_0 \\in S$，这里的唯一不是强求，因为可以转化为唯一形态，转化方法就是前面再添加ige初始状态，然后通过 ${\\epsilon }$ 边转移到原始初始状态即可。 状态转移函数 $\\delta$，$\\delta: S \\times (\\Sigma \\cup {\\epsilon}) \\rightarrow 2^S$ 接受状态集合 $F \\subseteq S$，下图的 3 就是接受状态 这里非确定一个就是指接受统一字符的状态转移不唯一，如下图的 0 号节点，它接受字符 a 可以跑到两个状态上去；另一个就是可能存在 ${ \\epsilon }$ 边，在没有字符驱动的情况下自发的跑到另外一个状态。 state transfer\r上面的状态转移图没有规定如果碰到其他的字符该怎么处理，所以下图就约定所有没有对应出边的字符默认指向 空状态 $\\empty$，也就是 $(\\Sigma \\cup {\\epsilon})$，它表示达到自身，也意味着一个死状态。 state transfer\r语义\r有穷自动机是一类及其简单的计算装置，它可以识别（接收/拒绝）$\\Sigma$ 上的字符串 接收 （非确定性）有穷自动机 $\\mathcal{A}$ 接受字符串 x，当且仅当存在一条从开始状态 $s_0$ 到某个接受状态 $f \\in F$ 、标号为 x 的路径。 对于上面的状态转移图，只有 3 是接受状态，因此 $aabb \\in L(\\mathcal{a}), ababab \\notin L(\\mathcal{A})$ 因此，$\\mathcal{A}$ 定义了一种语言 $L(\\mathcal{A})$：它能接受的所有字符串构成的集合。所以根据上方状态转移图，可以得到自动机语言：$L(\\mathcal{A}) = L((a|b)^*abb)$ 由上面的语义，我们可以得到自动机的两个基本问题 Membership 问题：给定字符串 $x$，$x \\in L(\\mathcal{A})?$ $L(\\mathcal{A})$ 究竟是什么？ ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:3:1","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"DFA\r语法\r确定性有穷自动机 $\\mathcal{A}$ 是一个五元组 $\\mathcal{A} = (\\Sigma, S, s_0, \\delta, F)$ 字母表 $\\Sigma (\\epsilon \\notin \\Sigma)$ 有穷的状态集合 $S$ 唯一的初始状态 $s_0 \\in S$，这个唯一是一定需要的 状态转移函数 $\\delta$，$\\delta: S \\times \\Sigma \\rightarrow S$ 接受状态集合 $F \\subseteq S$，下图的 3 就是接受状态 state transfer\r这里的约定就是：所有没有对应出边的字符串默认指向一个“死状态” 语义\r上图的自动机语言还是 $L(\\mathcal{A}) = L((a|b)^*abb)$，也就是上面的 NFA 和下面的 DFA 等价的。因此可以看出 NFA 适合去表达一个语言，容易得出语言是什么；而 DFA 则是因为状态的转移确定，适合写词法分析器。即 NFA 简介易于理解，便于描述语言 $L(\\mathcal{A})$；DFA易于判断$x \\in L(\\mathcal{A})$，适合产生词法分析器。那么转换就是 $RE \\Rightarrow NFA \\Rightarrow DFA \\Rightarrow$ 词法分析器。 ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:3:2","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"相互转换\r这里就是根据下面这张图，使得正则表达式和自动机之间相互转换。 conversion\r","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:4:0","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"RE -\u003e NFA\r采用 Thompson 构造法，使得 $r \\Rightarrow NFA$，要求 $L(N(r)) = L(r)$，即两个语言等价。这里就是对于正则表达式语法的每个规则来定义自动机，然后最后将这些自动机按规则进行组合就得到了 NFA。 $N(r)$ 的性质以及 Thompson 构造法复杂度分析 $N(r)$ 的开始状态和接受状态均唯一 开始状态没有入边，接受状态没有出边 $N(r)$ 的状态数 $|S| \u003c 2 \\times |r|$（$|r|: r$ 中运算符和运算分量的总和） 每个状态最多有两个 $\\epsilon \\text{-}$ 入边与两个 $\\epsilon \\text{-}$ 出边 $\\forall a \\in \\Sigma$，每个状态最多有一个 $a \\text{-}$ 入边与一个 $a\\text{-}$ 出边 自动机构造如下： Thompson\r","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:4:1","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"NFA -\u003e DFA\r原理\r采用子集构造法，也就是用 DFA 模拟 NFA。 子集构造法\r下面就是从 NFA 到 DFA 的构造对应表，有了这张表就有了自动机。之所以是子集构造法，是因为构造出来的 DFA 对应于 NFA 的一个状态子集。同时这里因为在 NFA 中 10 是接受状态，所以在 DFA 中，对应的 E 也是接收状态。 构造对应表\r形式化描述子集构造法\r这里根据上图的转化，会得到两个重要的公式： $\\epsilon$ 闭包：从状态 s 开始，只通过 $\\epsilon \\text{-}$ 转移可达的状态集合 $\\epsilon\\text{-closure}(s)={t\\in S_N|s\\xrightarrow{\\epsilon^*}t}$，这个公式的含义就是把 NFA 中的初始状态归结于 DFA 中的初始状态。上图中 NFA 的 ${0,1,2,4,7}$，它是初始状态，在 NFA 中，从 0 开始，通过 $\\epsilon$ 边进行连接的状态在 DFA 中都是初始状态。之后进行扩展操作 $\\epsilon \\text{-closure(T)} = \\bigcup_{s \\in T}\\epsilon \\text{-closure(s)}$，这个就是把上面的初始状态都添加在一起，转化为了集合形式，即状态集合，它为下面的 move 公式提供操作变量。 $\\text{move(T,a)} = \\bigcup_{s\\in T} \\delta(s,a)$，这个公式就是根据集合的当前状态，然后根据转移函数 $\\delta$，逐个查看集合中每个元素在同一个字符作用的目标元素是什么，最后将目标元素添加到新集合中，这个集合就是 DFA 中的下一个状态。 之后就可以形式化描述子集构造法：子集构造法($N \\rightarrow D$) 的原理： $$ \\begin{array}{l} N: (\\Sigma_N, S_N, n_0, \\delta_N, F_N) \\\\ D: (\\Sigma_D, S_D, d_0, \\delta_D, F_D) \\\\ \\Sigma_{D} = \\Sigma_{N} \\\\ S_{D} \\subseteq 2^{S_{N}} \\quad (\\forall s_{D} \\in S_{D} : s_{D} \\subseteq S_{N}) \\end{array} $$ 初始状态：$d_{0} = \\epsilon \\text{-closure}(n_{0})$ 状态转移：$\\forall a \\in \\Sigma_{D} : \\delta_{D}(s_{D}, a) = \\epsilon\\text{-closure}(\\operatorname{move}(s_{D}, a))$ 接受状态集：$F_{\\mathcal{D}} = { s_{D} \\in S_{\\mathcal{D}} \\mid \\exists f \\in F_N \\colon f \\in s_{D} }$ 子集构造法的复杂度分析：（$|S_N=n|$，下面的符号就是算法分析中的分析符号） $$\\left|S_{D}\\right| = \\Theta\\left(2^{n}\\right) = O\\left(2^{n}\\right) \\cap \\Omega\\left(2^{n}\\right)$$ 对于任何算法，最坏情况下，$|S_{D}| = \\Omega\\left(2^{n}\\right)$。 ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:4:2","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"DFA最小化\r方法\r我们还是查看之前使用 NFA -\u003e DFA 的转换图来看，下面的 DFA 就是使用子集构造法将 NFA 转化而来的，毫无疑问，与上面的图相比，它不是最小的，所以这里需要探究的就是如何将 DFA 转化为最小化的形式。 conversion\r这里DFA最小化算法基本思想：等价的状态可以合并。对于等价而言，如果存在某个能区分状态 s 与 t 的字符串，则称 s 与 t 是可区分的；否则，称 s 与 t 是等价的。这里的字符串 x 区分状态 s 与 t，就是指如果分别从 s 与 t 出发，沿着标号为 x 的路径到达的两个状态中只有一个是接受状态，则称区分了状态 s 与 t，也就是s 与 t 不等价。 所以状态等价就是说，对于两个状态而言，在任意同一个字符的驱动下从当前状态进行转换，转换后的状态也是等价的。它可以用下面的公式进行表示： $$ \\begin{array}{l} s \\sim t \\iff \\forall a \\in \\Sigma. \\left( (s \\xrightarrow{a} s’) \\land (t \\xrightarrow{a} t’) \\implies (s’ \\sim t’) \\right)\\\\ s \\nsim t \\iff \\exists a \\in \\Sigma. \\left( (s \\xrightarrow{a} s’) \\land (t \\xrightarrow{a} t’) \\land (s’ \\nsim t’) \\right) \\end{array} $$ 基于该定义，不断合并等价的状态，直到无法合并为止。但是我们的定义是一个递归的，不知道一开始要从什么地方入手，同时我们又得到所有的接受状态并不是等价的。所以这里采取的办法就是划分，利用反例公式 $s \\nsim t \\Longleftrightarrow \\exists a \\in \\Sigma. ( s \\xrightarrow{a} s’ ) \\land ( t \\xrightarrow{a} t’ ) \\land ( s’ \\nsim t’ )$ 进行划分，而非合并。也就是首先根据接受状态与非接受状态必定不等价先划分为两类 $\\Pi = {F, S \\setminus F}$，然后在这个基础上根据上面的反例公式进行分裂，直至再也无法划分为止，这里就到达了不动点，之后就是将同一等价类里的状态合并。 划分步骤\r上面就是分裂的过程，在 $\\Pi_0$ 到 $\\Pi_1$ 的过程中，${A,B,C}$ 和 ${D}$ 在经过 b 进行传递的状态是不等价的，此时 D 转移到 E 上了，E 输出 $S \\setminus F$，所以不等价。之后的操作也是这样挑选字符看转移后的状态处于哪一个集合中，如果不在本身的集合，那么就是不等价，需要进行分裂。 合并\r上图就是最后的分裂之后再合并得到最小化 DFA 的转换。 注意\r需要注意处理\"死状态\"，也就是指向 ${ \\empty}$ 的一些没有画出来的边，在进行分裂时需要添加上，即${F, S \\setminus F, { \\empty }}$ 刚刚的算法不适用于 NFA 最小化，NFA最小化问题是 PSPACE-complete 的，复杂度很高。 ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:4:3","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"DFA -\u003e 词法分析器\r这里对于词法分析器的构造，需要注意一下几个要求，然后按照之前使用 java 模拟的方法进行构造即可： 需要满足最前优先匹配和最长优先匹配，与此同时，因为需要生成词法分析器的特定目的，所以要保留各个 NFA 的接受状态的信息，表明匹配的是什么正则表达式 需要消除 “死状态”，避免词法分析器徒劳消耗输入流。如果加上死状态，那么词法分析器就有可能走这条路径，然后会进行一直匹配，最后匹配出的也是死状态，妨碍正确匹配。 进行模拟的过程如下图所示，和之前 java 模拟的过程一样。 模拟过程\r最后需要注意初始划分需要考虑不同的词法单元。之前的划分按照接受状态和非接受状态进行划分，但是这里需要写词法分析器，所以最后的接收状态对应了不同的词法单元，所以也需要进一步划分为不同的集合。 特定词法单元\r","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:4:4","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["programming"],"content":"这里是 python 使用技巧的记录，包括日常使用和数据之间的转换。 ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:0:0","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"基础知识\r","date":"2024.10.31","objectID":"/blog/posts/programming/python/:1:0","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"字符串\r\"\"\" \"\"\" 可以存储数行字符串 str = \"\"\"learn python the smart way 2nd edition hello word\"\"\" 使用 enumerate() 可以获得元素的序号 for idx, c in enumerate(str): print(idx, c) str.split 会把字符串划分为一个列表，依照空格进行划分 for word in str.split(): print(word) str.splitlines 会把字符串划分为一个列表，依照\"\\n\"进行划分 for line in str.splitlines(): if(line.startswith(\"hello\")): # startswith print(line) ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:1:1","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"函数\r接收不定长参数，*args 表示参数数目不定，可以看成一个元组，把第一个参数后面的参数当作元组中的元素 def add(x, *args): total = x for arg in args: total += arg return total 上面的函数不能使用关键词传入参数，要使用关键词 **kwargs，它表示参数数目不定，相当于一个字典，键和值对应于键值对 def add(x, **kwargs): total = x for arg, value in kwargs.items(): print(\"adding %s=%s\" % (arg,value)) total += value return total # 使用方法如下： def foo(*args, **kwargs): print(args, kwargs) add(1, 2, 3, 4) foo(2, 3, x='bar', z=10) map 方法生成序列，map(aFun, aSeq)，函数 aFun 应用到序列 aSeq 上的每一个元素上，返回一个列表，不管这个序列原来是什么类型。事实上，根据函数参数的多少，map 可以接受多组序列，将其对应的元素作为参数传入函数。 def square(a, b, c): return a**2 + b + c a = [1,2,3] b = (4, 5, 6) print(list(map(square, a, b, b))) ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:1:2","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"文件读写\rpython 提供安全的 with 来进行文件读写，当 with 块的内容结束后，Python 会自动调用它的 close 方法，确保读写的安全。 模式 描述 r 只读。该文件必须已存在。 r+ 可读可写。该文件必须已存在，写为追加在文件内容末尾。 rb 表示以二进制方式读取文件。该文件必须已存在。 w 只写。打开即默认创建一个新文件，如果文件已存在，则覆盖写（即文件内原始数据会被新写入的数据清空覆盖）。 w+ 写读。打开创建新文件并写入数据，如果文件已存在，则覆盖写。 wb 表示以二进制写方式打开，只能写文件， 如果文件不存在，创建该文件；如果文件已存在，则覆盖写。 a 追加写。若打开的是已有文件则直接对已有文件操作，若打开文件不存在则创建新文件，只能执行写（追加在后面），不能读。 a+ 追加读写。打开文件方式与写入方式和a一样，但是可以读。需注意的是你若刚用a+打开一个文件，一般不能直接读取，因为此时光标已经是文件末尾，除非你把光标移动到初始位置或任意非末尾的位置。 import os os.remove('newfile.txt') with open('newfile.txt','w+') as f: for i in range(30): x = 1.0 / (i - 10) f.write('hello world: ' + str(i) + '\\n') ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:1:3","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"其他\r通过 split 对 “,” 进行分割，使得一行可以输入多个值。 a, b = input().split(\",\") print(f\"a = {a}, b = {b}\") print 操作，默认每次输入后会换行，控制结尾的参数是 end，设置 end 把 “\\n” 替换成了 “//\"。同时它一次也可以输出多个内容，默认以空格分隔，这里控制分割的参数就是 sep，修改之后空格变成 “//\"。 print(\"data\", end=\"//\") print(\"Data\", \"whale\", sep=\"//\") ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:1:4","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"数据转换\r这里强制自己使用byte类型，这样可以统一python的不同数据类型 ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:2:0","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"AllToBytes\r字符串转化为 bytes，也可以直接在前面加 'b' 来转换 string = \"Hello World\" str_byte = bytes(string, 'utf-8') # -\u003e b'Hello World' 二进制字符串转化为 bytes hex_string = \"68 656c6c6f20776f726c64\" # 这里空格不会影响结果，但是需要是两个字符(68中间不能加空格)一组 hex_byte = bytes.fromhex(hex_string) # -\u003e b'hello world' # list(hex_byte) -\u003e [104, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100] 长整型转换为 bytes，小端序方式 long_i = 6788912312 # 下面就是计算转化为16进制的字节数 int.to_bytes(long_i, (long_i.bit_length() + 7) // 8, byteorder=\"little\") # -\u003e b'\\xb8\\x94\\xa6\\x94\\x01' 十六进制数转化为 bytes，小端序方式 hex_int = 0x12345678 int_byte = int.to_bytes(hex_int, 4, byteorder='little') # -\u003e b'xV4\\x12' 整型列表转化为 bytes list_num = [0x12, 0x34, 0x56, 0x78] list_byte = bytes(list_num) # -\u003e b'\\x124Vx' 字节列表转化为 bytes，先转化为字符串，再转化 str_list = ['1', 'C', 'E', 'B', 'E', '0', '8', '9', '7', '4', 'A', '9', '6', '1', 'C', '5'] # 先转str再转byte bytes(\"\".join(str_list), encoding=\"utf-8\") # -\u003e b'1CEBE08974A961C5' ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:2:1","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"AllToBytes\rbytes 转化为字符串 byte = b'Hello World' byte_str = str(byte, 'utf-8') # -\u003e 'Hello World' bytes 转化为十六进制字符串 byte = b'hello world' byte_hex = byte.hex() # -\u003e '68656c6c6f20776f726c64' bytes 转化为长整型，小端序 byte = b'\\xb8\\x94\\xa6\\x94\\x01' i = int.from_bytes(byte, byteorder='little') # -\u003e 6788912312 bytes 转化为十六进制整型 byte = b'xV4\\x12' int_num = int.from_bytes(byte, byteorder='little') # -\u003e 305419896 0x12345678 bytes 转化为整型列表 byte = b'\\x124Vx' list_num = list(byte) # -\u003e [18, 52, 86, 120] bytes 转化为字符串列表 byte = b'1CEBE08974A961C5' str_list = [str(byte[i:i + 2], 'utf-8') for i in range(0, len(byte), 2)] # -\u003e ['1C', 'EB', 'E0', '89', '74', 'A9', '61', 'C5'] ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:2:2","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"其余转换处理\r转化为字符串 chr(a) # 将 int 类型的 a 根据其 ascii 码转化为 str 字符 hex(a) # 将 int 类型的 a 转化为其十六进制 str 类型 str(a) # 将所有类型的 a 按照其本身转化为 str 类型 str = a.decode() # 将 bytes 类型的 a 转化为 str 类型 转化为整型 # a 为 k 进制数，使用 int 将 k 进制数的 a 转化为十进制数 # # int(a) 直接将字符 a 转化为 int 类型，此时 a 必须为数字字符，注意：不是转化 为ascii 码，而是转化为数字类型，即值不变，类型改变 int(a,k) # 将 str 类型的十六进制数 a 转化为 int 类型(这里十六进制需要加上0x) eval(a) # 将字符类型的 a 按其 ascii 码转化为 int 类型 ord(a) ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:2:3","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"数据处理\rstruct 模块可以解决 bytes 和其他二进制数据类型的转换。pack 函数把任意数据类型变成 bytes，unpack 把 bytes 变成相应的数据类型。这里的格式就是(format:str, v1, v2, …)，其中format对于后面的数据进行匹配，然后输出。 ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:3:0","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"pack\rpack 函数把任意数据类型变成 bytes struct.pack('\u003cII', 10240099, 1767863401) # -\u003e b'\\x00\\x9c@ci_ti' 如果符合ascii的标准，就直接转化为字符 ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:3:1","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"unpack\runpack 把 bytes 变成相应的数据类型 struct.unpack('\u003cI', b'it_i') # -\u003e (1767863401,) 这里只有一个符合 I 的规则，所以只有一个数据 ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:3:2","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"数据格式\rformat 参数就是上面使用的描述符，struct 利用它可以指定使用大端序还是小端序来解析或者生成数据 Character Byte order Size Alignment @ native native native，凑足4个字节 = native standard none \u003c little-endian standard none \u003e big-endian standard none ! network(=big-endian) standard none 数据格式，用于匹配当前字符的数据 Format C Type Python type Standard size x pad byte no value c char string of length 1 1 b signed char integer 1 B unsigned char integer 1 ? _Bool bool 1 h short integer 2 H unsigned short integer 2 i int integer 4 I unsigned int integer 4 l long integer 4 L unsigned long integer 4 q long long integer 8 Q unsigned long long integer 8 f float float 4 d double float 8 s char[] string 1 p char[] string 1 P void * integer 0 ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:3:3","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"ipython\r","date":"2024.10.31","objectID":"/blog/posts/programming/python/:4:0","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"特点\ripython 比原生的 python 解释器好用很多，它拥有高亮、补全、魔法函数等功能 Tab，可以自动补全，例如输入 imp 然后按 Tab 键，它会自动补齐 import 这个单词；如果再按 tab，提示所有可导入的模块，按方向键可以进行导航。 ?，在变量和函数后面添加 ? 会输出相关文档，?? 会打印源码（前提库是 python 写的） %hist 会显示用户输入命令的历史记录 %edit 会打开系统文本编辑器 %edit x-y 打开 Notepad 并写入指定范围内的命令 %history -n 会显示历史记录及对应的序号，然后通过 %edit x-y 命令对某一范围输入为脚本供后续使用 ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:4:1","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"使用相关\r对于 for 和 def 这些需要换行缩进的地方而言，换行会自动进行缩进处理。如果想删除这个缩进，直接使用 back 就可以了。如果需要保存或者运行，enter 之后不再输入内容，直接再按一次即可。 换行缩进使用\r","date":"2024.10.31","objectID":"/blog/posts/programming/python/:4:2","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":null,"content":"关于我\r在系统/软件安全领域学习的菜狗 有趣的事情总能吸引我，然后忘记正事 ","date":"2024.10.29","objectID":"/blog/about/:1:0","tags":null,"title":"About","uri":"/blog/about/"},{"categories":null,"content":"网址\rhttps://cztangt.github.io/blog/ https://github.com/czTangt ","date":"2024.10.29","objectID":"/blog/about/:2:0","tags":null,"title":"About","uri":"/blog/about/"},{"categories":null,"content":"联系方式\r渠道 信息 QQ Mjk3MzE3NDU5Mg== 微信 VDEzMjY0NzE4NjI5 邮箱 Y3ouVGFuZ3RAZ21haWwuY29t ","date":"2024.10.29","objectID":"/blog/about/:3:0","tags":null,"title":"About","uri":"/blog/about/"}]
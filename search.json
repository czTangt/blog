[{"categories":["programming"],"content":"记录一下 java 的学习。 ","date":"2024.12.20","objectID":"/blog/posts/programming/java/:0:0","tags":["programming"],"title":"Some about Java","uri":"/blog/posts/programming/java/"},{"categories":["programming"],"content":"基础知识\r相关基础知识可以从 cs61b 中进行学习，还可以直接通过 相关笔记1，相关笔记2 来快速学习。 ","date":"2024.12.20","objectID":"/blog/posts/programming/java/:1:0","tags":["programming"],"title":"Some about Java","uri":"/blog/posts/programming/java/"},{"categories":["programming"],"content":"List and Deque\r对于 java 的列表和队列不太了解，所以这里进行相关记录。 ","date":"2024.12.20","objectID":"/blog/posts/programming/java/:2:0","tags":["programming"],"title":"Some about Java","uri":"/blog/posts/programming/java/"},{"categories":["programming"],"content":"SLList\rSLList 就是 Singly Linked List，即单向链表，代码如下所示。可以看出： 内部类 Node：对于链表的单个结构进行封装的结果，其类型为 private，保证了封闭性。 哨兵 sentinel：用来维护下面 addFirst 和 addLast 的一致性。正是因为这个哨兵节点的存在，他们可以对所有节点保持一样的操作，而不必考虑一开始没有节点的情况。 列表大小 size：记录当前列表的大小，因为在每次操作都会记录，所以可以直接通过 size() 获取大小。这样添加一个变量定理，遏制了列表从头遍历获取长度的操作，使长度获取更快速。 同时由下可以看出，列表对于最后一个元素的添加和获取速度很慢，但是其可以动态分配内存、插入和删除效率高，无连续内存要求。 public class SLList\u003cItem\u003e { private class Node { public Item item; public Node next; public Node(Item i, Node n) { item = i; next = n; } } /* The first item (if it exists) is at sentinel.next. */ private Node sentinel; private int size; /** Creates an empty timingtest.SLList. */ public SLList() { sentinel = new Node(null, null); size = 0; } public SLList(Item x) { sentinel = new Node(null, null); sentinel.next = new Node(x, null); size = 1; } /** Adds x to the front of the list. */ public void addFirst(Item x) { sentinel.next = new Node(x, sentinel.next); size += 1; } /** Returns the first item in the list. */ public Item getFirst() { return sentinel.next.item; } /** Adds x to the end of the list. */ public void addLast(Item x) { size += 1; Node p = sentinel; /* Advance p to the end of the list. */ while (p.next != null) { p = p.next; } p.next = new Node(x, null); } /** returns last item in the list */ public Item getLast() { Node p = sentinel; /* Advance p to the end of the list. */ while (p.next != null) { p = p.next; } return p.item; } /** Returns the size of the list. */ public int size() { return size; } } ","date":"2024.12.20","objectID":"/blog/posts/programming/java/:2:1","tags":["programming"],"title":"Some about Java","uri":"/blog/posts/programming/java/"},{"categories":["programming"],"content":"AList\rAList 就是 Array List，即数组列表，代码如下所示。可以看出： 列表大小 size：记录当前列表的大小，因为在每次操作都会记录，所以可以直接通过 size() 获取大小。 扩容 resize：进行扩容的函数，当 addLast 时发现大小不够时，就通过该函数对数组大小进行扩容处理。但是该操作是创建一个新数组，然后将原本的内容进行复制处理，所以对于大量数据速度会很慢。 使用数组的列表结构，可以快速随机访问，能直接通过索引进行访问，并且简单直观。但是扩容成本高，内存一开始开辟，填不满浪费空间，同时也不适合平凡的插入和删除。 public class AList\u003cItem\u003e { private Item[] items; private int size; /** Creates an empty list. */ public AList() { items = (Item[]) new Object[100]; size = 0; } /** Resizes the underlying array to the target capacity. */ private void resize(int capacity) { Item[] a = (Item[]) new Object[capacity]; System.arraycopy(items, 0, a, 0, size); items = a; } /** Inserts X into the back of the list. */ public void addLast(Item x) { if (size == items.length) { resize(size * 2); } items[size] = x; size = size + 1; } /** Returns the item from the back of the list. */ public Item getLast() { return items[size - 1]; } /** Gets the ith item in the list (0 is the front). */ public Item get(int i) { return items[i]; } /** Returns the number of items in the list. */ public int size() { return size; } /** Deletes item from back of the list and * returns deleted item. */ public Item removeLast() { Item x = getLast(); items[size - 1] = null; size = size - 1; return x; } } ","date":"2024.12.20","objectID":"/blog/posts/programming/java/:2:2","tags":["programming"],"title":"Some about Java","uri":"/blog/posts/programming/java/"},{"categories":["programming"],"content":"LinkedListDeque\r下面的代码实现了双端队列，他就是基于上面 SLList 的基础上进行改进的。 哨兵 sentinel：这里的哨兵和上文的作用一样，但是这里采用了更为巧妙的方法。这里对于双端队列，只设置一个哨兵，这样通过哨兵关联头尾，形成了一个环，这样就能保证双端队列的添加一致性。 这里双端队列相比于上文的单向链表，对于尾端的插入迅速，不必再遍历整个链表。 import java.util.Iterator; public class LinkedListDeque\u003cT\u003e implements Iterable\u003cT\u003e { // define the basic struct private class Node { T item; Node prev; Node next; Node(T item, Node prev, Node next) { this.item = item; this.prev = prev; this.next = next; } } // the first item (if it exits) is at sentinel.next // and the last item is at sentinel.prev private Node sentinel; private int size; public LinkedListDeque() { sentinel = new Node(null, null, null); sentinel.next = sentinel; sentinel.prev = sentinel; size = 0; } @Override public void addFirst(T item) { Node tempItem = new Node(item, sentinel, sentinel.next); sentinel.next.prev = tempItem; sentinel.next = tempItem; size += 1; } @Override public void addLast(T item) { Node tempItem = new Node(item, sentinel.prev, sentinel); sentinel.prev.next = tempItem; sentinel.prev = tempItem; size += 1; } @Override public int size() { return size; } @Override public void printDeque() { Node p = sentinel; while (p.next != sentinel) { System.out.print(p.item + \" \"); p = p.next; } System.out.println(); } @Override public T removeFirst() { if (size == 0) { return null; } T value = sentinel.next.item; sentinel.next.next.prev = sentinel; sentinel.next = sentinel.next.next; size -= 1; return value; } @Override public T removeLast() { if (size == 0) { return null; } T value = sentinel.prev.item; sentinel.prev.prev.next = sentinel; sentinel.prev = sentinel.prev.prev; size -= 1; return value; } // get the item at the given index @Override public T get(int index) { if (index \u003c 0 || index \u003e= size) { return null; } Node p = sentinel.next; for (int i = 0; i \u003c index; i++) { p = p.next; } return p.item; } // same as get, but uses recursion public T getRecursive(int index) { if (index \u003c 0 || index \u003e= size) { return null; } return recursiveHelper(sentinel.next, index); } private T recursiveHelper(Node p, int index) { if (index == 0) { return p.item; } return recursiveHelper(p.next, index - 1); } // Implemente Iterator @Override public Iterator\u003cT\u003e iterator() { return new DLLListIterator(); } private class DLLListIterator implements Iterator\u003cT\u003e { private Node current; private DLLListIterator() { current = sentinel.next; } @Override public boolean hasNext() { return current != sentinel; } @Override public T next() { T returnItem = current.item; current = current.next; return returnItem; } } @Override public boolean equals(Object o) { if (this == o) { return true; } if (!(o instanceof Deque\u003c?\u003e)) { return false; } Deque\u003c?\u003e deque = (Deque\u003c?\u003e) o; if (size != deque.size()) { return false; } for (int i = 0; i \u003c size; i++) { if (!get(i).equals(deque.get(i))) { return false; } } return true; } } ","date":"2024.12.20","objectID":"/blog/posts/programming/java/:2:3","tags":["programming"],"title":"Some about Java","uri":"/blog/posts/programming/java/"},{"categories":["programming"],"content":"ArrayDeque\r下面的代码基于上述的 AList，使用数组来实现双向队列。 nextFirst：这个变量一直指向第一个节点的上一个位置。当添加第一个节点时，就是添加数据到这个变量指向位置的下一个地址，然后这个变量就会继续指向前面一格的位置。 nextLast：这个变量则是一直执行最后一个节点的后一个位置。添加最后一个节点就是添加到它指向位置的前面，然后它会往后移动。 size 是当前数组中存在的真实数据的个数，数组中空的元素不算在里面，而 item.length 就是整个数组一开始开辟的大小，它是一个固定的值。 checkExpand，checkEmptySpace 和 resize 就是进行队列扩容缩放的操作，前二者就是对于当前队列大小进行判断的函数，然后在插入前和删除后进行相关判断。他们调用的就是 resize，它通过创建一个新的数组，然后将原来的数据复制进行来实现扩容缩放。 import java.util.Iterator; public class ArrayDeque\u003cT\u003e implements Iterable\u003cT\u003e { // define the basic struct private T[] items; private int size; // the number of items in the array // items.length -\u003e the size of the position in the array, and it is the capacity private final int INIT_CAPACITY = 8; // init size private final int MAX_CAPACITY = 16; // max size // nextFirst points to the position before the first item. private int nextFirst; // nextLast points to the position after the last item. private int nextLast; public ArrayDeque() { items = createArray(INIT_CAPACITY); size = 0; nextFirst = INIT_CAPACITY - 1; nextLast = 0; } // update the index private int nextIndex(int index) { return (index + 1) % items.length; } private int prevIndex(int index) { return (index - 1 + items.length) % items.length; } // check if it needs expand. private void checkExpand() { if (size != items.length) { return; } resize(size * 2); } // check if empty space exists. private void checkEmptySpace() { if (items.length \u003e= MAX_CAPACITY \u0026\u0026 size \u003c 0.25 * items.length) { resize(items.length / 2); } } @SuppressWarnings(\"unchecked\") private T[] createArray(int capacity) { return (T[]) new Object[capacity]; } private void resize(int newCapacity) { T[] newItems = createArray(newCapacity); int first = nextIndex(nextFirst); // if it not is a circular if (first \u003c= prevIndex(nextLast)) { System.arraycopy(items, first, newItems, 0, size); } else { int firstPart = items.length - first; System.arraycopy(items, first, newItems, 0, firstPart); System.arraycopy(items, 0, newItems, firstPart, nextLast); } items = newItems; // since the copy happens within the range from 0 to size, // so the nextFirst points of the last position of the newCapacity. nextFirst = newCapacity - 1; // the nextLast points the position right the previous size. nextLast = size; } @Override public void addFirst(T item) { checkExpand(); items[nextFirst] = item; nextFirst = prevIndex(nextFirst); size += 1; } @Override public void addLast(T item) { checkExpand(); items[nextLast] = item; nextLast = nextIndex(nextLast); size += 1; } @Override public int size() { return size; } @Override public void printDeque() { int index = nextIndex(nextFirst); for (int i = 0; i \u003c size; i++) { System.out.print(items[index] + \" \"); index = nextIndex(index); } System.out.println(); } @Override public T removeFirst() { if (size == 0) { return null; } // nextIndex(nextFirst) points the first item int firstIndex = nextIndex(nextFirst); // cache calculation results T item = items[firstIndex]; items[firstIndex] = null; // the original position of first item becomes the position for the next addFirst insertion. nextFirst = firstIndex; size -= 1; checkEmptySpace(); return item; } @Override public T removeLast() { if (size == 0) { return null; } int lastIndex = prevIndex(nextLast); T item = items[lastIndex]; items[lastIndex] = null; nextLast = lastIndex; size -= 1; checkEmptySpace(); return item; } // get the item at the given index @Override public T get(int index) { if (index \u003c 0 || index \u003e= size) { return null; } int actualIndex = (nextFirst + 1 + index) % items.length; return items[actualIndex]; } @Override public Iterator\u003cT\u003e iterator() { return new ArrayDequeIterator(); } private class ArrayDequeIterator implements Iterator\u003cT\u003e { private int index; private ArrayDequeIterator() { index = nextIndex(nextFirst); } @Override public boolean hasNext() { return index != nextLast; } @Override public T next() { T returnItem = items[index]; index = nextIndex(index); return returnItem; } } @Override public boolean equals(Object o) { if (this","date":"2024.12.20","objectID":"/blog/posts/programming/java/:2:4","tags":["programming"],"title":"Some about Java","uri":"/blog/posts/programming/java/"},{"categories":["Static Analysis"],"content":"记录一下对于静态分析的理解。 前提说明\r由于笔者知识面受限，所以关于当前系列文章做出以下解释： 在计算机科学中，程序分析 是指自动分析一个程序的包括正确性、健壮性、安全性和活跃性等特征的过程。程序分析主要研究两大领域：程序的优化和程序的正确性。前者研究如何提升程序性能并且降低程序的资源占用，后者研究如何确保程序完成预期的任务。同时程序分析可以在不执行程序的情况下进行（静态程序分析），也可以在执行时进行（动态程序分析），或结合二者。这里都是来自 wiki 的介绍，而本文的相关术语也遵从上面的介绍，静态分析就是程序分析的一个方面，全称为静态程序分析。 在我的学习中，感觉静态分析的相关知识和编译器优化的内容存在很大程度上的重叠，所以就将 DCC888 的内容也补充进来。后来发现该课程主页的名称为 Static Program Analysis，拿过来记录也名正言顺。所以本系列文章就是基于 《软件分析》，《软件分析技术》，《DCC888》 三门课程与其余参考资料所写的笔记。 ","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:0:0","tags":["static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["Static Analysis"],"content":"静态分析概览\r注意事项\r下面的内容大部分来自于 沉浸式《程序分析》教材，但是在那篇文章中，对于程序分析的描述为本文一开始提到的静态程序分析。所以在这篇文章中，采用静态分析替代那篇文章中的程序分析。 ","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:1:0","tags":["static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["Static Analysis"],"content":"静态分析定义\r静态分析\r静态分析（Static Analysis） 是一种在实际运行程序 P 之前，通过分析静态程序 P 本身来推测程序的行为，并判断程序是否满足某些特定的 属性（Property） Q 的方法。 上述中静态程序指的就是不运行程序的状态，它也被称为 “静态” 或 “编译时”，它与程序的 “动态” 和 “运行时” 相对应。由此可以看出，静态分析就是对于给定的程序代码进行自动化扫描、分析，而不必运行程序。 ","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:1:1","tags":["static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["Static Analysis"],"content":"静态分析用途\r静态分析的用处有很多，主要可以分为下面的内容： 程序可靠性（Program Reliability）：空指针异常而导致的程序崩溃会影响程序的可靠性，诸如这样的 bug 还存在很多，但是他们中很多都可以在没有运行的状态下被静态分析检测出来。同时导致程序不响应的程序缺陷，例如内存泄漏，也会被静态分析检测出来。 程序安全性（Program Security）：对于程序中的可能引起注入攻击等的缺陷代码，静态分析也可以进行识别。 编译优化（Compiler Optimization）：在将源码编译为目标平台程序的过程中，静态分析可以在中间环节对中间代码进行优化。其中 Dead code elimination 可以避免永远执行不到的代码最终编译到目标平台程序中；Code motion 可以将循环中的某些计算不变式语句提取到循环外部，进行避免冗余计算，提高程序运行速度。 程序理解（Program Understanding）：IDE 提供的不止有代码编辑功能，还有程序理解功能。比如 IDE 可以提示代码的调用关系、继承关系、声明类型等信息，这些关于程序的诸多信息的提取很多都是通过静态分析技术来完成的。 ","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:1:2","tags":["static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["Static Analysis"],"content":"静态分析定位\r静态分析属于程序设计语言的一部分，而程序设计语言主要分为三类研究内容： 理论：设计一款程序设计语言一般是从其语法、语义的设计开始，也包括选择什么类型系统，支持什么语言特性等问题。一般情况下，这类理论研究一般可以自证，即可以将语言的语法、语义、类型系统等形式化，然后在其形式化基础上用理论方法证明该语言的诸多属性，这也就是为什么很多 PL 的论文并没有实现实验部分。 环境：程序设计语言有了理论设计，在实际中想要运行的起来，必须要有支撑它的环境系统，这主要包括编译系统和运行时系统两个部分。编译系统强调语法的解析（如果是静态语言还会有类型检查等），运行时系统强调语义的解释执行（比解释器更复杂的运行时系统也会负责垃圾回收等内存问题）。PL 的环境系统往往避免不了在实现细节上做很多脏活累活，使得语言在实际中真能好用起来。 应用：有了理论与环境的支撑，语言就能跑起来了。然而，一个工业级的程序设计语言通常是一个非常复杂的系统，如何保障该复杂系统的可靠性、安全性、高性能等需求，是需要一系列方法来支撑的，这些方法（如静态分析、程序验证、程序合成等）通常要以语言的理论部分为基础（如语法、语义），结合不同的数学理论来完成各自应用的目标。在 PL 应用中，最具代表性的技术就是静态分析。 虽然程序设计语言数量繁多，但是无非属于以下三大类（称为程序设计语言范式，Programming Paradigm）： 命令式程序设计语言（Imperative Programming Languages，IP）：在 IP 中，指令一个一个给出，用条件、循环等来控制逻辑（指令执行的顺序），同时这些逻辑通过程序变量不断修改程序状态，最终计算出结果。尽管 IP 现在都是高级语言了，但是本质上并没有脱离那种 “类似汇编的，通过读取、写入等指令操作内存数据” 的编程方式。国内高等教育中接触的绝大多数编程语言都是 IP 的，比如 Java、C、C++ 等。 函数式程序设计语言（Functional Programming Language，FP）：在 FP 中，逻辑（用函数来表达）可以像数据一样抽象起来，复杂的逻辑（高阶函数）可以通过操纵（传递、调用、返回）简单的逻辑（低阶函数）和数据来表达，没有了时序与状态，隐藏了计算的很多细节。不同的逻辑因为没有被时序和状态耦合在一起，程序本身模块化更强，也更利于不同逻辑被并行的处理，同时避免因并行或并发处理可能带来的程序故障隐患，这也说明了为什么 FP 语言如 Haskell 在金融等领域（高并发且需要避免程序并发错误）受到瞩目。 逻辑式程序设计语言（Logic Programming Language，LP）：LP 抽象的能力就更强了，计算细节干脆不见了，把想表达的逻辑直观表达出来就好了。如今，在数据驱动计算日益增加的背景下，LP 中的声明式语言，如 Datalog 作为代表开始崭露头角，在诸多专家领域开拓应用市场。 ","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:1:3","tags":["static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["Static Analysis"],"content":"不完备性\r由上文静态分析的定义可知，静态分析是通过分析程序的代码而推理出程序在动态运行时可能的行为，然后判断程序是否满足关注的一些属性的一种方法。这里关注的信息可能是： 该程序是否会泄漏私有信息？ 该程序是否会引用空指针？ 该程序中所有 cast 操作都是安全的吗？ 该程序的这块代码是否是死代码？ …… 可以看出，静态分析可以判断的属性有很多，而且有些至关重要。所以如果静态分析可以准确无误地判断上述程序的所有属性，那么程序就不愁还会存在可靠性和安全性的问题了，只需要关注于静态分析的优化即可。但是显示情况却不是这样的，这就需要下面一系列理论的支持了。 ","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:2:0","tags":["static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["Static Analysis"],"content":"不可判定\r可判定问题是指：对于回答是或否的问题，如果存在一个算法，使得对于该问题的每一个实例都能给出 是/否 的答案，那么这个问题就是可判定问题。而将这个问题转移到程序上面，就是说对于一个程序或者代码而言，只看其初始状态，而不运行这个程序，那么是否可以判断其是否会停机？答案就是它是不可判定的。 而要知道它为什么是不可判定问题，就需要知道哥德尔不完备定理和图灵停机问题的相关知识，因此可以从 停机悖论三句话就能证明不完备性定理？ 来进行了解。在观看之后就可以明白一个概念，不存在一个算法能够回答停机问题，它是不可判定的。 ","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:2:1","tags":["static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["Static Analysis"],"content":"莱斯定理\r现在关注静态分析是否可以准确无误地判断上述程序的所有属性问题，那么就需要引入莱斯定理。 Rice 定理\r对于使用 递归可枚举（Recursively Enumerable） 的语言描述的程序，其任何 非平凡（Non-trivial） 的属性都是不可判定的。 这里的递归可枚举就可以理解为图灵完备语言；而对于非平凡属性，定义一个属性是平凡的，那么这个属性要么对任何一个递归可枚举语言编写的所有程序为真，要么为假，否则它就是非平凡的。由此可以把这里的非平凡属性理解为和程序运行时行为相关的属性，它体现的是一种语义相关而不是语法相关的属性。例如，一个程序是否存在 while 循环、是否存在左右括号等类似的就是和语法相关的属性，而这里讨论的是否会泄漏私有信息等就是和语义相关的属性。因此可以进一步将莱斯定理理解为下面的表述： Rice 定理\r一个程序的任何语义（运行时行为）相关的属性都是不可判定的。 ","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:2:2","tags":["static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["Static Analysis"],"content":"莱斯定理验证\r既然成功理解了莱斯定理，知道其含义，那么就需要知道它为什么是正确的，这样就涉及到上面提起的不可判定了。这里的证明思路需要和图灵机停机进行联系，也就是将证明这个问题（非平凡属性）是否可判定规约到是否可以判定图灵机停机问题上。如此一来，如果该问题可判定，那么就可以得到图灵停机问题也可以判定的结果，继而根据已知事情反证出来该问题不可判定。下面就是使用 python 来定义一个 Halt 函数： def Halt(p, i): def trick(k): p(i) return k * k * k return is_cube(trick) 这里 Halt 函数用来判定在给定程序 p 和输入 i 的条件下，p 是否会停机。之后再内部定义一个函数 trick，它的输入是 k，首先执行输入为 i 的程序 p，之后返回输入 k 的立方。如果 p(i) 不停机，也就是一直处于运行状态，那么这个 trick 函数就不会进行返回操作；而如果 p(i) 能够停机，那么这个函数就会返回给定参数的立方值。 现在假设 Halt 函数中的 is_cube(trick) 是可以确切无误地判断给定函数 trick 是否可以计算立方值问题的函数（这里可以把计算立方值替换为任何非平凡的属性），那么就可以得到下面的两种情况： p(i) 会停机，之后 trick 就会返回立方值，又因为 is_cube(trick) 可以确切判断出 trick 可以计算立方值，因此 is_cube(trick) = Halt(p, i) = true，也就是判定了程序可以停止。 p(i) 不会停机，之后 trick 不会返回立方值，而此时 is_cube(trick) 可以确切判断出 trick 不可以计算立方值，因此 is_cube(trick) = Halt(p, i) = false，也就是判定了程序不可以停机。 从上述可以知道，如果真存在一个可判定非平凡属性是否为真的算法（即这里的 is_cube），那么就可以得到一个可判断图灵提及的算法（即这里的 Halt），即可以通过调用 is_cube(trick) 的结果准确的判断程序 p 是否会停机。但是又因为图灵停机问题是不可判定的，因此就不存在一个可判定非平凡属性的算法，那么莱斯定理就成立了。 ","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:2:3","tags":["static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["Static Analysis"],"content":"静态分析类型\r","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:3:0","tags":["static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["Static Analysis"],"content":"完美的静态分析\r完美的静态分析\r如果一个静态分析 S 能够对于程序的某个非平凡性质 Q 给出确切的答案，就称 S 是 P 关于 Q 的 完美静态分析（Perfect Static Analysis）。定义程序 P 关于 Q 的真实性为 真相（Truth），那么完美静态分析有两层含义： 完全性（soundness）：真相一定包含在 S 给出的答案中； 正确性（completeness）：S 给出的答案一定包含在真相中； 那么记这个静态分析程序给出的答案集合 A，真相集合为 T，则完美的静态分析满足： $$ T ⊆ A ∧ A ⊆ T ⇔ A = T $$ 其中，$T⊆A$ 体现了 soundness，$A⊆T$ 体现了 completeness。 根据上述的定义可知，一个完美的静态分析得到的结果是正确的，也是全面的，但是由上文的莱斯定理可以知道并不存在一个完美的方法可以准确判断任意程序的非平凡属性是否为真，也就是说不存在一个既能 Sound 又能 Complete 的静态分析方法。那么这里的静态分析是否就没用了呢？其实并不是，sound 和 complete 之间就是进行探索的领域。 ","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:3:1","tags":["static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["Static Analysis"],"content":"妥协的静态分析\rsoundness \u0026 completeness\r因为完美的静态分析并不存在，所以通常需要做一些妥协，也就是在 $T⊆A$ 和 $A⊆T$ 中只尽力满足其中一个条件，妥协另一个条件。于是，就得到了两种妥协后的静态分析类型。 过近似\r记程序 P 关于性质 Q 的静态分析 S 为 Sound 的静态分析，当且仅当 S 给出的答案集合 A 和 P 关于 Q 的真相集合 T 之间满足： $$ T⊆A $$ 这种分析策略也成为 过近似（Over-approximation）。 这里 Sound 的静态分析保证了 soundness，妥协了 completeness，会 过近似（Overapproximate） 程序的行为，因此会出现 假阳性（False Positive） 的现象，即判定为阳性，但实际是阴性的。反映在现实场景中即为 误报问题。比如真实的行为（Truth）给定程序存在 5 处空指针引用，那么一个 Sound 的结果就是它至少包含这 5 处空指针引用，即不存在漏报。但是它可能报出 9 处空指针引用，多余的这 4 处空指针引用就是误报，也就是假阳性的情况。但是这样的妥协理论上不但可以帮助找出所有的程序缺陷漏洞，还可以使得静态分析可以用于编译优化和程序验证等应用。这里对于编译优化而言，静态分析就是在判断该优化是否是正确的，所以需要 Sound 的分析来对所有情况进行考虑。 False Positive\r欠近似\r记程序 P 关于性质 Q 的静态分析 S 为 Complete 的静态分析，当且仅当 S 给出的答案集合 A 和 P 关于 Q 的真相集合 T 之前满足： $$ A⊆T $$ 这种分析策略也成为 欠近似（Under-approximation）。 这里 Complete 的静态分析保证了 completeness，妥协了 soundness，会 欠近似（Underapproximate） 程序的行为，因此会出现 假阴性（False Negative） 现象，即判定为阴性，但实际是阳性。反映在现实场景中即为 漏报问题。比如真实的行为（Truth）给定程序存在 5 处空指针引用，那么一个 Complete 的结果就是它最多包含这 5 处空指针引用，即不存在误报。但是它可能报出 3 处空指针引用，缺少的 2 处空指针引用就是漏报，也就是假阴性的情况。而这样的妥协不影响分析应用的有效性，例如利用静态分析查找程序缺陷和安全漏洞，虽然因为漏报没有找到所有的 bug，但是找到一个 bug 都是有益的。 False Negative\r","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:3:2","tags":["static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["Static Analysis"],"content":"现实的静态分析\r而现在，无论是怎样的分析应用，静态分析的设计都是在努力追求更好的 soundness。因为这样的分析会覆盖到更多的程序行为，对于像编译优化和程序验证这种应用，静态分析必须是 Sound 的，否则它会影响优化和验证的正确性。对于 Sound 可以通过下面的例子进一步理解： if input then x = 1; else x = 0; output x; 对于上面的代码，存在两种 Sound 的静态分析： 当 input 为 true，x 是 1，当 input 为 false， x 是 0 ； x 是 0 或 1 这两种都保证了 soundness，不过前者更精确，代价也更高，分析速度慢；后者不那么精确，但相应代价也会更低一点，分析速度快。前者精确，但是需要维护条件分支的信息，需要额外的开销，如果针对一定规模的程序，这个开销将占据非常多的资源，很大程度上会拖累分析的速度；相比之下，后者不那么精准，但是因为不用维护额外的信息，分析速度会很快。由此可以对现实世界中的静态分析进行总结： 现实中的静态分析\r现实中的静态分析需要在确保（尽可能接近）soundness 的前提下，在速度和精度之间做一个合适的权衡。 上述中尽可能接近 soundness，是因为在不少实际应用场景中，取得完全的 soundness 是困难的。例如分析 java 程序，那么 java 语言的反射特性、动态类加载特性以及 native 代码调用，都会在很大程度上影响分析的 soundness。在这种情况下，就是需要分析尽可能地接近 soundness 了。当下鉴于 soundness 对普遍应用的重要性，以及对部分应用的必要性，为方便理解，如无特殊说明，静态分析都应做 Overapproximate 以获取 soundness。 ","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:3:3","tags":["static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["Static Analysis"],"content":"编译基础\r注意事项\r在最初的前提说明中，我提到自己认为静态分析与编译器优化（尤其是编译的中后端内容）之间存在较大的重叠。因此，我觉得有必要了解一些编译相关的知识，并记录了相关内容。以下内容主要参考了 （一）初始软件分析，对编译基础进行一个概括性的介绍。详细内容可以参见 compile 中的相关内容。 编译器（Compiler）是一种计算机程序，它会将用某种编程语言写成的源代码（原始语言），转换成另一种编程语言（目标语言）。一般来说编译器的内部包含了如下的工作步骤： 词法分析； 语法分析； 语义分析； 生成中间表示（intermediate representation，IR）； 优化； 代码生成； 编译器工作步骤\r在这里，编译器的前端对接各种编程语言，对编程语言本身进行语法和语义分析，中端则负责代码优化，后端对接各种硬件架构，负责生成对应硬件下的可执行文件。而对于静态分析而言，关注的就是中间代码上的优化部分。 ","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:4:0","tags":["static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["Static Analysis"],"content":"词法分析\r词法分析（lexer）的主要工作是将源代码的字符流转换成 Token（词法单元） 流，在这里，词法分析器会根据给定的规则把输入的源代码构建成 Token。例如对于 int a = 0;，就会产生 $int, \\ a, \\ =, \\ 0, \\ ;$ 这几个 Token。具体而言，Token 分为种别码和属性值，种别码是一个标识符，用于区分不同类型的 token，编译器就是通过它来识别和分类 token 的关键信息；而属性值就是 token 的具体信息了，它会在后续的语法分析和语义分析阶段被用于构建语法树和进一步的处理。下面就是种别码的不同类型，可以看出它是程序的关键字部分。 种别码类型\r下面就是一个简单的词法分析过程，输出的内容就是输入的字符流进行转化的结果。第一列就是字符，后面使用 \u003c \u003e 包围的就是转换后的 Token 了。 词法分析\r词法分析器可以读入字符流，然后转化为 Token，但是词法分析器的产生过程是不容易的。下图就展示了词法分析器代码产生的过程。 词法分析流程\r词法分析器的产生始于对语言模式的定义，即需要知道对于某个字符，应该进行怎样的处理。而正则表达式（RE）正是描述语言词法规则的一种简洁而有效的工具。例如，正则表达式 [a-zA-Z_][a-zA-Z0-9_]* 可以定义标识符的格式，而 [0-9]+ 则可以描述整数常量。然而，正则表达式只是对模式的抽象描述，并不能直接用于字符流的解析。为了将正则表达式转化为实际可执行的结构，首先需要构造非确定性有限自动机（NFA）。NFA 是正则表达式的一种等价形式，它通过状态和状态间的转移来表示语言的匹配过程。NFA 的一个显著特点是它允许非确定性迁移，即在某个状态下，读取一个字符可以有多个可能的转移，这为复杂的模式解析提供了灵活性。NFA 的构造通常采用 Thompson 构造法，将简单的正则表达式片段逐步拼接为完整的自动机结构。 如下图就是 RE 向 NFA 的转化过程，上面的公式就是正则表达式的匹配公式。可以看出，随着对于正则表达式的不断解析，NFA 的构建也逐渐完善。这里的圆圈就是状态，随着中间箭头上字符的输入，状态进行不同的转移，从而匹配相应的正则表达式规则，即语法规则。 NFA 结构\r然而，NFA 的非确定性也导致了解析效率的下降，因为在解析时可能需要同时跟踪多个状态，例如下图中 NFA 的 1 状态到 2、4 状态。为了解决这个问题，需要将 NFA 转换为确定性有限自动机（DFA）。DFA 通过子集构造法将 NFA 的多个状态集合映射为一个确定的状态，从而消除了非确定性。DFA 的每个状态都可以看作是 NFA 的一个状态集合，因此保留了与 NFA 等价的语言匹配能力，但解析效率得到了显著提高，因为在 DFA 中，每次读取一个字符只会有唯一的状态迁移。 DFA 结构\r在得到 DFA 后，接下来的任务是将其转化为实际的词法分析器代码。DFA 本质上是一个状态迁移表，可以直接映射到代码实现中。词法分析器通过模拟 DFA 的运行过程，从字符流中逐个读取字符，根据 DFA 的状态迁移规则移动到下一个状态。当到达终止状态时，词法分析器便生成对应的 Token，并继续解析后续的字符。如果某个字符无法匹配任何状态迁移，则报告词法错误。通过这种方式，词法分析器实现了从正则表达式到自动机、再到代码的完整转换流程，从而能够高效地将源代码的字符流解析为词法单元，为后续的语法分析和语义分析奠定基础。 ","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:4:1","tags":["static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["Static Analysis"],"content":"语法分析\r语法分析（parsing）是根据给定的 形式文法 对单词序列（如英语单词序列）构成的输入文本进行分析并确定其语法结构的一个过程。简单来说，上述词法分析根据字符生成 Token 的过程类似于将字母组成单词。而语法分析将 Token 按特定的规则构成语法树的过程类似于把单词组合成语句。 语法分析过程\r而语法分析器（parser）通常作为编译器或解释器的组件出现，它的作用是进行语法检查，构造由输入的单词组成的数据结构（一般是抽象语法树等层次化的数据结构）。下面就是将辗转相除法代码转化为的抽象语法树。 while b != 0: if a \u003e b: a := a - b else: b := b - a return a 抽象语法树\r","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:4:2","tags":["static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["Static Analysis"],"content":"其余参考资料\r参考\r（一）初始软件分析 沉浸式《程序分析》教材 程序分析与优化 - 1 导论 静态分析基础教程 程序分析研究进展 ","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:5:0","tags":["static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["compile"],"content":"这里记录 riscv、isel、ra 的相关知识。 ","date":"2024.12.7","objectID":"/blog/posts/compile/codegen-riscv-isel-ra/:0:0","tags":["compile"],"title":"05 Codegen Riscv Isel Ra","uri":"/blog/posts/compile/codegen-riscv-isel-ra/"},{"categories":["compile"],"content":"riscv\r这里主要就是讲述了 riscv 的汇编语法，通过写汇编语言并执行来加强对于 riscv 的熟悉。因此这里没什么笔记，需要的时候再去查找 riscv 的相关汇编语法。 贴一下 相关手册。 ","date":"2024.12.7","objectID":"/blog/posts/compile/codegen-riscv-isel-ra/:1:0","tags":["compile"],"title":"05 Codegen Riscv Isel Ra","uri":"/blog/posts/compile/codegen-riscv-isel-ra/"},{"categories":["compile"],"content":"代码转换\r下面就是从中间语言到目标平台代码的翻译过程，其中 MC 指 Machine Code。 转换流程\r下图上面部分就是在转换为目标代码过程中的各个中间产物，而下面就是具体流程。白色块就是 pass，主要是进行优化，因此我们的关注点就是黑色的转换块。 这里首先把 LLVM IR 转化为 DAG（有向无环图） 形式，然后在这个形势下做指令选择。之后 Instruction scheduling 就是对于前面的无环图进行排序，转换为线性结构，这样才能给后面进行处理。然后进行 Register allocation，把之前使用 SSA 的 IR 转换为有限寄存器的结构。 LLVM 转换\r","date":"2024.12.7","objectID":"/blog/posts/compile/codegen-riscv-isel-ra/:2:0","tags":["compile"],"title":"05 Codegen Riscv Isel Ra","uri":"/blog/posts/compile/codegen-riscv-isel-ra/"},{"categories":["compile"],"content":"指令选择\r","date":"2024.12.7","objectID":"/blog/posts/compile/codegen-riscv-isel-ra/:3:0","tags":["compile"],"title":"05 Codegen Riscv Isel Ra","uri":"/blog/posts/compile/codegen-riscv-isel-ra/"},{"categories":["compile"],"content":"介绍\r指令选择介绍\r指令选择的介绍如上图所示，下面就是可以采用的不同的算法。 指令选择算法\r下面就是 LLVM IR 生成的相关 DAG 图，之后我们需要做的就是对于这个 DAG 图进行优化，删除改进合并相关细节。 DAG 生成\r优化之后的 DAG 如下左图所示。之后我们就需要从 DAG 中找到和指令相关的元素，然后采用树结构来进行匹配，从而获取下图最终的结果。 选择指令\r结构转换\r","date":"2024.12.7","objectID":"/blog/posts/compile/codegen-riscv-isel-ra/:3:1","tags":["compile"],"title":"05 Codegen Riscv Isel Ra","uri":"/blog/posts/compile/codegen-riscv-isel-ra/"},{"categories":["compile"],"content":"树匹配\r定义\r上面就是我们需要进行匹配的定义，下面则是我们相关的匹配规则。1 匹配规则 1\r匹配规则 2\r由上述匹配规则，我们自底向上进行匹配，若是遇到更大的匹配规则，那么采用更大的覆盖小的，这样就可以得到右侧的相关指令。 匹配结果\r对于上述匹配是理解匹配，我们需要转换为相关算法，所以采用之前语法分析的流程。将树进行前缀表达，语法的推导也转换形式，这样就可以形成推导算法了。 匹配算法\r但是这也会存在二义性问题，所以面对归约/归约冲突，优先选择较长的归约；面对移入/归约冲突，优先选择移入动作。 ","date":"2024.12.7","objectID":"/blog/posts/compile/codegen-riscv-isel-ra/:3:2","tags":["compile"],"title":"05 Codegen Riscv Isel Ra","uri":"/blog/posts/compile/codegen-riscv-isel-ra/"},{"categories":["compile"],"content":"寄存器分配\r定义\r线性扫描分配算法就是根据活跃变量算法查看不同变量的活跃期间，然后进行寄存器的分配和回收；而对于溢出变量，就是使用 store/load 来存取内存。然后后面就没有声音了，但是有个 笔记 可以看看，包含编译原理的很多内容。 ","date":"2024.12.7","objectID":"/blog/posts/compile/codegen-riscv-isel-ra/:4:0","tags":["compile"],"title":"05 Codegen Riscv Isel Ra","uri":"/blog/posts/compile/codegen-riscv-isel-ra/"},{"categories":["config"],"content":"主要记录 Vim 的配置和使用。 ","date":"2024.12.4","objectID":"/blog/posts/config/vim/:0:0","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"基本模式\r","date":"2024.12.4","objectID":"/blog/posts/config/vim/:1:0","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"Normal 模式\r默认进入的模式，可以进行查看，粘贴，搜索等相关操作。 基本移动\r快捷键 含义 hjkl 左下上右 gg 跳到第一行（类似于 Home 键） G 跳到最后一行（类似于 End 键） \u003cCtrl-u\u003e 往上翻半页（类似 PageUp 键） \u003cCtrl-d\u003e 往下翻半页（类似 PageDown 键） {lineno}gg 跳到第 lineno 行 zz / zt / zb 光标行设置为 屏幕居中/屏幕第一行/屏幕最后一行 这里的 u，d 可以理解为 up，down。同时在 Vim 配置中放弃了 和 这两个翻一页的操作，反而改为 vscode 原本的操作。 基于单词移动\r快捷键 描述 w 代表 word，跳转到下一处单词的开头 b 代表 back，跳转到上一处单词的开头 e 代表 end，跳转到下一处单词的结尾 ge e 的反向版本，跳转到上一处单词的结尾 wbe 大写版本 WBE 对应的单词是连续的非空字符 大小写比对\r基于搜索的移动\r行内搜索： 快捷键 描述 f{char} / t{char} 跳转到本行下一个 char 字符出现处/出现前 ; / , 快速向后/向前重复 ft 查找 F{char} / T{char} 往前搜索而非往后 文件中搜索： 快捷键 描述 /{pattern} 跳转到本文件中下一个 pattern 出现的地方 ?{pattern} 跳转到本文件中上一个 pattern 出现的地方 pattern 可以是正则表达式 * 等价于 /{pattern}，pattern 是当前光标下的单词 n / N 快速重复 / 查找 这里查找之后按 enter 就会跳到查找的 pattern 出现的地方 基于标记的移动\r快捷键 描述 `` 上次跳转前的位置 `. 上次修改的位置 其它移动\r快捷键 描述 ^ / $ 跳转到本行的开始/结尾 % 跳到匹配的配对符（括号等）处 % 的作用比如就是在左花括号使用可以跳到右花括号处。同时三者的顺序为 shift + 456，可以理解为结束、匹配、开始。 ","date":"2024.12.4","objectID":"/blog/posts/config/vim/:1:1","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"Insert 模式\r插入模式，主要用于编辑文本内容。Normal 模式下通过特定命令进入 Insert 模式。ESC 返回 Normal 模式。 快捷键 描述 i 代表 insert，当前光标之前开始输入 a 代表 append，当前光标之后开始输入 o 下方插入新的一行，然后开始输入 s 删除当前光标的字符，然后开始输入 I 在本行的开头开始输入 A 在本行的末尾开始输入 O 上方插入新的一行，然后开始输入 S 删除当前行，然后开始输入 ⼤写字⺟和⼩写字⺟的操作存在关联，可以⼀起记忆 ","date":"2024.12.4","objectID":"/blog/posts/config/vim/:1:2","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"Command 模式\r命令模式，在底部输入命令，对文本进行保存，搜索等。Normal 模式下输入 : 进入 Command 模式。ESC 返回 Normal 模式。 快捷键 描述 :w 保存当前文件 :q 退出 :q! 放弃当前更改，然后退出 :wq 保存当前更改，然后退出 /{pattern} 搜索文本，按 enter 确认，之后使用 n 搜索下一个 这里的搜索会出现高亮，取消高亮就是在命令模式中输入 :noh 即可。这里需要注意，使用 : 进入命令模式高亮就会消失，但是不做任何操作，直接退出的话，高亮还是会在之后出现。 ","date":"2024.12.4","objectID":"/blog/posts/config/vim/:1:3","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"Visual 模式\r可视模式，对文本进行选择。ESC 回到 Normal 模式 Normal 模式下按 v 进入可视模式，之后可以用 Normal 模式下的移动命令选择文本 按 V 进入行可视模式，一次选中一整行，在需要选中多行时很方便。 可视模式下 x / y：剪切/复制；回到 Normal 模式下 p：粘贴 ","date":"2024.12.4","objectID":"/blog/posts/config/vim/:1:4","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"编辑命令\r","date":"2024.12.4","objectID":"/blog/posts/config/vim/:2:0","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"编辑动作\r{operator}{motion}：就是一次编辑动作，这里的 motion 就是对于光标的移动，也就是上面我们在 Normal 和 Visual 模式展示的这些，因此我们可以理解这里的编辑就是对于这次光标到移动后光标之间的内容进行编辑操作。常见的操作符如下： c：change，修改、删除内容并进入插入模式 d：delete，删除 y：yank，复制 v：visual，选中文本，进入可视模式 大部分操作符连续按两次（例如 cc/dd/yy）：将其作用在这一行上，比如 dd 就是删除这一行。 d{char}，说是删除，但是这个动作其实是剪切的行为，会把内容复制到剪切板上，之后就可以使用 p 会进行粘贴。 例子： dgg：删除到第一行 ye：复制到单词结尾 d$：删除到行尾 dt;：删除直到分号为止的内容 ","date":"2024.12.4","objectID":"/blog/posts/config/vim/:2:1","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"重复操作\r.：重复上一次修改，记住是修改，不能重复光标移动操作 u：撤销上一次修改 \u003cCtrl-r\u003e：重做上一次修改 . 命令适合需要多次重复某一个修改动作的场景 ","date":"2024.12.4","objectID":"/blog/posts/config/vim/:2:2","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"批量操作\r{count}{action}：重复 count 次 action 动作，动作可以是移动动作或是编辑动作。 4j：向下移动4行 3dw：删除3个单词 2yy：复制2行 4p：粘贴4次 数字 + 动作是一种重要的批量操作方式，命令直观，语义明确。这里 .命令可以直观地看到每一次地变化，在合适地时候停止，而数字 + 动作则需要预先知道动作的次数。 ","date":"2024.12.4","objectID":"/blog/posts/config/vim/:2:3","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"文本对象操作\r文本对象为文本赋予了结构化的含义，允许我们以一个语义对象作为操作单元。命令就是 [count]{operator}{textobjects}。这里的 {textobjects} 就是语义化的文本片段，格式为 i / a + 对象。常见的对象如下： w / W，s，p：单词、句子、段落 ( / )，[ / ]，{ / }，\u003c / \u003e，' / \"：配对符定义的对象 这里 i 代表 inner，内部；a 额外包括周围的空格或配对符。 图示举例\r例子： diw：删除一个单词 ci(：修改小括号内部 yi{：复制大括号内部 这里配合 . 或 [count] 可以简单完成多次对特定语义对象的操作 ","date":"2024.12.4","objectID":"/blog/posts/config/vim/:3:0","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"其余操作\rgd：跳转到函数定义的地方。 gh：查看函数的帮助信息。 ","date":"2024.12.4","objectID":"/blog/posts/config/vim/:4:0","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"相关配置及插件\r","date":"2024.12.4","objectID":"/blog/posts/config/vim/:5:0","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"Vim 配置\r由下面的 vim.handleKeys 可以看出为了vscode 和 vim 协调，调整了一些快捷键。 { // Vim \"vim.easymotion\": true, \"vim.incsearch\": true, \"vim.useSystemClipboard\": true, \"vim.useCtrlKeys\": true, \"vim.hlsearch\": true, \"vim.leader\": \"\u003cspace\u003e\", \"vim.smartRelativeLine\": true, // 相对行号 \"vim.handleKeys\": { // false 则由 vscode 进行处理 \"\u003cC-a\u003e\": false, // 全选 \"\u003cC-c\u003e\": false, \"\u003cC-x\u003e\": false, \"\u003cC-v\u003e\": false, \"\u003cC-p\u003e\": false, // 打开配置 \"\u003cC-w\u003e\": false, // 关闭当前窗口 \"\u003cC-q\u003e\": false, // 选择侧边栏 \"\u003cC-f\u003e\": false, // 查找 \"\u003cC-b\u003e\": false, // 关闭侧边栏 }, \"vim.insertModeKeyBindings\": [ { \"before\": [\"j\", \"j\"], \"after\": [\"\u003cEsc\u003e\"] } ], \"vim.normalModeKeyBindingsNonRecursive\": [ { \"before\": [\"\u003cleader\u003e\", \"d\"], \"after\": [\"d\", \"d\"] }, { \"before\": [\"\u003cC-n\u003e\"], \"commands\": [\":nohl\"] }, { \"before\": [\"K\"], \"commands\": [\"lineBreakInsert\"], \"silent\": true } ], // To improve performance \"extensions.experimental.affinity\": { \"vscodevim.vim\": 1 }, } ","date":"2024.12.4","objectID":"/blog/posts/config/vim/:5:1","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"easymotion\r这里就是使用 \u003cleader\u003e 来帮助进行操作。也就是采用 \u003cleader\u003e \u003cleader\u003e {char} 可以使操作作用于全局，将对应的位置高亮显示，并修改为字母，之后就可以点击相应字母达成光标移动 ","date":"2024.12.4","objectID":"/blog/posts/config/vim/:5:2","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"vim-surround\r对于上述文本对象操作而言，这里除了 i/a 之外可以再添加一个 s，它表示 a 中除了 i 的部分。下面就是使用说明： 具体使用\r","date":"2024.12.4","objectID":"/blog/posts/config/vim/:5:3","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"注意事项\r","date":"2024.12.4","objectID":"/blog/posts/config/vim/:6:0","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"解决中文输入法\r根据 知乎回复 的解决方案，配置了改进的 AutohotKey 方法。同时按照我的情况更改为如下的代码： ;限定在vscode 程序里面发挥作用 #IfWinActive ahk_exe Code.exe ;vscode 的exe 名字叫做Code.exe global MyVar := 0 ~Esc:: if (MyVar == 0) { sendinput, {Esc} sendinput, {Shift Down} SendInput, {Shift Up} MyVar = 1 } else { sendinput, {Shift Down} SendInput, {Shift Up} MyVar = 0 } return #If 但是仍然存在问题，第一次使用的时候和预期的一样，按下 ESC 就可以切换回 NORMAL 的同时切换回英文模式。但是在之后进行第二次切换时，就只会切换英文模式，而不会切换为 NORMAL 了，怀疑之后信息截断之后没有再发送到 vscode 了。所以现在使用的方案就是手动进行中英文的切换，多进行一步比搞混乱浪费的时间短。 ","date":"2024.12.4","objectID":"/blog/posts/config/vim/:6:1","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"参考\r参考的教程如下： Vim 使用教程 Vim 相关使用 Vscode Vim 快捷键配置 Vim 讲解及配置 ","date":"2024.12.4","objectID":"/blog/posts/config/vim/:7:0","tags":["config"],"title":"Vim 使用记录","uri":"/blog/posts/config/vim/"},{"categories":["config"],"content":"记录一下 vscode 及其相关插件的配置和使用。 ","date":"2024.12.3","objectID":"/blog/posts/config/vscode/:0:0","tags":["config"],"title":"VsCode 配置和使用","uri":"/blog/posts/config/vscode/"},{"categories":["config"],"content":"具体使用\r","date":"2024.12.3","objectID":"/blog/posts/config/vscode/:1:0","tags":["config"],"title":"VsCode 配置和使用","uri":"/blog/posts/config/vscode/"},{"categories":["config"],"content":"快捷方式\r这里只描述 vscode 本体的快捷方式或者后续添加的，与 Vim 相关的操作在具体描述 Vim 的文章中进行讲述。 多功能按键\r\u003cCtrl-Shift-p\u003e：这个按键就是调出设置框，如下图所示。通过这个设置框，我们可以在里面寻找 vscode 的任何操作说明，点击即可进行相关操作。 设置处理\r\u003cCtrl-p\u003e：和上面按键类似，但是这个是对于文件的处理，它可以寻找当前项目的文件，点击即可打开，同时聚焦于新文件。 文件处理\r界面聚焦\r这里的聚焦实际指当前光标的位置，因为 vscode 的区域可以分为侧边栏，编辑区，终端等区域，所以这里记录区域切换的方式。 \u003cCtrl-`\u003e：这个按键用于打开/隐藏终端，但是打开/隐藏的时候会伴随着光标的切换。也就是当打开终端时，会自动聚焦于终端上；隐藏终端时，会自动聚焦于编辑框。由此能把这个按键作为编辑框和终端的光标转换按键，需要终端时使其打开出现，不需要时也可以令其隐藏使光标处于编辑框中。 \u003cCtrl-Shift-E\u003e：这个是光标跳转到左侧边栏的 Explorer 的快捷键，使用它就可以使光标在左侧边栏和离侧边栏最近的编辑框进行跳转了，它类似于上面的 \u003cCtrl-`\u003e，不过这里只是光标的跳转，上面还可以打开/隐藏终端。 \u003cCtrl-count\u003e：count 指的就是数字键，这个组合是对于横向的窗口而言的。比如 \u003cCtrl-0\u003e 就会把光标放在左侧边栏中，这样对于文件栏而言可以使用 enter 进行打开；\u003cCtrl-1\u003e 则是当前编辑框；Ctrl-2 就是第二个编辑框，若是当前没有就会进行创建，然后我们就可以使用 \u003cCtrl-p\u003e 来打开文件了。后面的数字依次类推。 \u003cAlt-count\u003e：上面的 Ctrl 是对于不同窗口而言的，那么这里的 Alt 就是对于不同标签页而言的。使用这个按键组合就可以在当前窗口中切换相应标签页了。这里使用 \u003cCtrl+Tab\u003e 也是切换标签页，不过有一个切换界面。 页面操作\r\u003cCtrl-w\u003e：关闭当前标签页，\u003cCtrl-Shift-w\u003e就是关闭当前项目了。 \u003cCtrl-b\u003e：打开/关闭侧边栏。 侧边栏操作\r配置了下面的快捷方式，使得在侧边栏操作更为方便。 // -------------------------- 侧边栏操作 -------------------------- [ { // Rename file \"key\": \"r\", \"command\": \"renameFile\", \"when\": \"explorerViewletVisible \u0026\u0026 filesExplorerFocus \u0026\u0026 !explorerResourceIsRoot \u0026\u0026 !explorerResourceReadonly \u0026\u0026 !inputFocus\" }, { // New file \"key\": \"a\", \"command\": \"explorer.newFile\", \"when\": \"explorerViewletVisible \u0026\u0026 filesExplorerFocus \u0026\u0026 !explorerResourceIsRoot \u0026\u0026 !explorerResourceReadonly \u0026\u0026 !inputFocus\" }, { // New folder \"key\": \"shift+a\", \"command\": \"explorer.newFolder\", \"when\": \"explorerViewletVisible \u0026\u0026 filesExplorerFocus \u0026\u0026 !explorerResourceIsRoot \u0026\u0026 !explorerResourceReadonly \u0026\u0026 !inputFocus\" }, { // Delete file \"key\": \"d\", \"command\": \"deleteFile\", \"when\": \"explorerViewletVisible \u0026\u0026 filesExplorerFocus \u0026\u0026 !explorerResourceIsRoot \u0026\u0026 !explorerResourceReadonly \u0026\u0026 !inputFocus\" }, { // Copy \"key\": \"y\", \"command\": \"filesExplorer.copy\", \"when\": \"explorerViewletVisible \u0026\u0026 filesExplorerFocus \u0026\u0026 !explorerResourceIsRoot \u0026\u0026 !explorerResourceReadonly \u0026\u0026 !inputFocus\" }, { // Cut \"key\": \"x\", \"command\": \"filesExplorer.cut\", \"when\": \"explorerViewletVisible \u0026\u0026 filesExplorerFocus \u0026\u0026 !explorerResourceIsRoot \u0026\u0026 !explorerResourceReadonly \u0026\u0026 !inputFocus\" }, { // Paste \"key\": \"p\", \"command\": \"filesExplorer.paste\", \"when\": \"explorerViewletVisible \u0026\u0026 filesExplorerFocus \u0026\u0026 !explorerResourceIsRoot \u0026\u0026 !explorerResourceReadonly \u0026\u0026 !inputFocus\" } ] ","date":"2024.12.3","objectID":"/blog/posts/config/vscode/:1:1","tags":["config"],"title":"VsCode 配置和使用","uri":"/blog/posts/config/vscode/"},{"categories":["config"],"content":"配置辨析\r为了更改目录相关的配置，我们可以设置 settings.json 文件实现。在此过程中，我们选择使用 Workspace（工作区）配置，而非全局的 User 配置。这样 vscode 会在当前目录的根目录下生成 .vscode 文件夹，其含有 settings.json 文件，专门用于当前目录的配置。因此，每个独立的目录可以被视为一个单独的工作区。 对于工作区配置，其核心是通过一个专门的配置文件 .code-workspace 来管理多个子项目和工作区的 settings.json 文件。同时，每个子项目的目录下仍可以存在单独的 .vscode 文件夹，用于个性化配置。这种方案的优点是粒度更细，可以分别对工作区和子项目进行配置。但缺点也较为明显：如果需要按之前的配置打开相关项目，就必须通过工作区文件打开多个子项目。此外，工作区文件记录的是绝对路径，若项目地址发生变动，原配置文件就失效了。这对我当前随机分配项目的需求而言并不适用。 至于 Profiles 功能，它允许为不同目录设置独立的配置文件。然而，根据实际尝试，这种方式存在一个问题：每个配置文件需要单独下载插件，并无法共享，这对于插件依赖较多的场景来说非常不便，因此我放弃了这种方案。 最终，我选择将每个目录视为一个独立的工作区，并通过禁用不相关插件来优化体验。尽管目前大多数语言相关插件都支持按需加载（未使用时不加载），且加载后会显示加载时间，但我注意到部分插件在未使用时依然被加载。因此，为了针对不同目录提高效率，我仍倾向于手动禁用无关插件，以实现更精准的控制和优化。 ","date":"2024.12.3","objectID":"/blog/posts/config/vscode/:1:2","tags":["config"],"title":"VsCode 配置和使用","uri":"/blog/posts/config/vscode/"},{"categories":["config"],"content":"配置记录\r记录一下自己的 settings.json 配置。 { // ----------------------------- 编辑器配置 ----------------------------- // workbench 配置，用于设置工作台的外观和行为 \"workbench.editor.enablePreview\": false, \"workbench.startupEditor\": \"none\", \"workbench.colorTheme\": \"Learn with Sumit - Blue Velvet\", \"workbench.iconTheme\": \"material-icon-theme\", \"workbench.layoutControl.enabled\": false , // files 配置，用于设置文件相关的行为 \"files.autoSave\": \"onFocusChange\", \"files.autoGuessEncoding\": true, // editor 配置，用于设置编辑器的外观和行为 \"editor.wordWrap\": \"on\", // 软换行，没有横向滚动条 \"editor.formatOnPaste\": true, \"editor.fontSize\": 13, \"editor.fontFamily\": \"JetBrainsMono Nerd Font Propo\", \"editor.tabCompletion\": \"on\", \"editor.formatOnType\": true, \"editor.acceptSuggestionOnEnter\": \"off\", \"editor.detectIndentation\": false, \"editor.minimap.autohide\": true, \"editor.unicodeHighlight.invisibleCharacters\": false, // 不高亮显示不可见字符 // window 配置，用于设置窗口的行为 \"window.openFoldersInNewWindow\": \"on\", // ----------------------------- 终端配置 ----------------------------- // 配置 Windows 平台终端 \"terminal.integrated.profiles.windows\": { \"PowerShell\": { \"source\": \"PowerShell\", \"icon\": \"terminal-powershell\" }, \"Command Prompt\": { \"path\": [ \"${env:windir}\\\\Sysnative\\\\cmd.exe\", \"${env:windir}\\\\System32\\\\cmd.exe\" ], \"args\": [], \"icon\": \"terminal-cmd\" } }, // 终端通用配置 \"terminal.integrated.defaultProfile.windows\": \"PowerShell\", \"terminal.integrated.defaultProfile.linux\": \"zsh\", \"terminal.integrated.fontFamily\": \"JetBrainsMono Nerd Font Propo\", \"terminal.integrated.enablePersistentSessions\": false, // ----------------------------- Git 配置 ----------------------------- \"git.autofetch\": false, // 禁止自动获取远程仓库的更新 \"git.enableSmartCommit\": false, \"git.confirmSync\": true, // ----------------------------- 扩展配置 ----------------------------- \"extensions.autoUpdate\": false, // SSH \"remote.SSH.showLoginTerminal\": true, // GitHub Copilot \"github.copilot.editor.enableAutoCompletions\": true, \"github.copilot.enable\": { \"*\": true, \"plaintext\": false, \"markdown\": false, \"scminput\": false }, // Git History \"gitHistory.showEditorTitleMenuBarIcons\": true, // PicGo，这里根据自己的配置来设置 \"picgo.customOutputFormat\": \"![${uploadedName}](${url} \\\"${uploadedName}\\\")\", \"picgo.picBed.aliyun.accessKeyId\": \"\", \"picgo.picBed.aliyun.accessKeySecret\": \"\", \"picgo.picBed.aliyun.area\": \"\", \"picgo.picBed.aliyun.bucket\": \"\", \"picgo.picBed.aliyun.path\": \"\", \"picgo.picBed.current\": \"aliun\", \"picgo.dataPath\": \"\", // Vim \"vim.easymotion\": true, \"vim.incsearch\": true, \"vim.useSystemClipboard\": true, \"vim.useCtrlKeys\": true, \"vim.hlsearch\": true, \"vim.leader\": \"\u003cspace\u003e\", \"vim.smartRelativeLine\": true, // 相对行号 \"vim.handleKeys\": { // false 则由 vscode 进行处理 \"\u003cC-a\u003e\": false, // 全选 \"\u003cC-p\u003e\": false, // 打开配置 \"\u003cC-w\u003e\": false, // 关闭当前窗口 \"\u003cC-q\u003e\": false, // 选择侧边栏 \"\u003cC-f\u003e\": false, // 查找 \"\u003cC-b\u003e\": false, // 保存 }, \"vim.insertModeKeyBindings\": [ { \"before\": [\"j\", \"j\"], \"after\": [\"\u003cEsc\u003e\"] } ], \"vim.normalModeKeyBindingsNonRecursive\": [ { \"before\": [\"\u003cleader\u003e\", \"d\"], \"after\": [\"d\", \"d\"] }, { \"before\": [\"\u003cC-n\u003e\"], \"commands\": [\":nohl\"] }, { \"before\": [\"K\"], \"commands\": [\"lineBreakInsert\"], \"silent\": true } ], // To improve performance \"extensions.experimental.affinity\": { \"vscodevim.vim\": 1 }, // ----------------------------- 语言配置 ----------------------------- // Cpp \"C_Cpp.clang_format_style\": \"{ BasedOnStyle: Chromium, IndentWidth: 3, ColumnLimit: 0}\", \"C_Cpp.formatting\": \"vcFormat\", // Java \"[java]\": { \"editor.defaultFormatter\": \"redhat.java\" }, \"redhat.telemetry.enabled\": true, // Python \"python.condaPath\": \"\\\"E:\\\\source\\\\miniconda3\\\\envs\\\\re\\\\python.exe\\\"\", \"[python]\": { \"editor.defaultFormatter\": \"ms-python.black-formatter\" }, // JavaScript \"[javascript]\": { \"editor.defaultFormatter\": \"vscode.typescript-language-features\" }, // markdown \"[markdown]\": { \"editor.wordWrap\": \"on\", \"editor.defaultFormatter\": \"yzhang.markdown-all-in-one\" }, } ","date":"2024.12.3","objectID":"/blog/posts/config/vscode/:1:3","tags":["config"],"title":"VsCode 配置和使用","uri":"/blog/posts/config/vscode/"},{"categories":["config"],"content":"插件相关\r","date":"2024.12.3","objectID":"/blog/posts/config/vscode/:2:0","tags":["config"],"title":"VsCode 配置和使用","uri":"/blog/posts/config/vscode/"},{"categories":["config"],"content":"PicGo\r上传配置\r因为使用 vscode 来写 Markdown 语法，所以想着仿照之前 Typora + PicGo 配置的剪切板粘贴上传图片功能。同时因为之前在 PicGo 应用中配置过，所以这次就直接获取参数然后输入即可。 配置信息\r这里的配置信息直接从软件中抄过来，或者随便看看阿里云图床的配置文章就可以知道大致该怎么填写了。之后这里 Aliyun: Path 选择之前自己创建的目录，可以通过 OSS -\u003e Bucket -\u003e 文件列表 来查看。另外选择 Pic Bed: Current 为 aliyun，这样上面的配置才可以生效。同时还设置了快捷键，对于使用截图软件，把图片放在剪切板上的情况，使用快捷键 ctrl + alt + u，这样和普通粘贴分割开了，更加方便。 文件名设置\rCustom Output Format 就是文件在 vscode 中的展现形式，这里针对 Fixit 主题中 Image 的要求 进行了修改。这样后面的 title 可以直接生成，然后我们需要修改的就是前面的 alt 了。 layouts/partials/plugin/image.html 文件在之前进行修改了，所以图片下面的图标显示的就只有 alt 了，只有鼠标放在图片上面和放大图片显示的才是 title。 本地格式\rCustom Upload Format就是上传文件的格式，随便设置即可，因为不会有太多的格式要求，这里就是默认的配置。 上传格式\r保存路径\r这里有一个 Data Path，vscode 插件会把每次的提交形成 json 数据添加到这个文件中，所以可以设置存储路径，之后查看图片可以迅速找到相关信息。这里我也将路径设置为博客的仓库，使其作为附属信息上传到 github 上。 路径配置\r","date":"2024.12.3","objectID":"/blog/posts/config/vscode/:2:1","tags":["config"],"title":"VsCode 配置和使用","uri":"/blog/posts/config/vscode/"},{"categories":["config"],"content":"java 环境配置\r下载\r主要使用 wsl 来配置 java 环境来做实验，所以对于 java 的下载直接使用包安装工具来进行。 配置环境主要需要两个插件 Language Support for Java(TM) by Red Hat 和 Extension Pack for Java，然后它们会连续下载多个插件，一般这两个下载完了就配置了基础环境。 Language Support for Java(TM) by Red Hat\rExtension Pack for Java\r项目创建\r之后我们就可以在 Ctrl + P 打开的配置栏中创建 java 项目了。 项目添加\rjar 包添加\r如果我们想要添加外部下载的 jar 包，我们可以使用 Maven 来进行配置（之前插件也一起下载了）。但是我这里没有相关环境，所以采用手动导入的方式。因此可以在一个 java 项目中打开 java 文件，可以看见下面的 JAVA PROJECTS 标识，它可以进行相关配置。 我们可以直接点击 Referenced Libraries 右侧的 + 直接在文件系统中找自己下载的 jar 包。 添加 jar 包\r或者也可以直接如下图所示在配置界面进行添加。 添加 jar 包\r","date":"2024.12.3","objectID":"/blog/posts/config/vscode/:2:2","tags":["config"],"title":"VsCode 配置和使用","uri":"/blog/posts/config/vscode/"},{"categories":["config"],"content":"jupyter\r配置环境\r我是用的就是 miniconda 环境。下载并配置环境之后，在 vscode 中下载插件 python 和 jupyter。之后在 settings 中输入 python path ，然后输入 miniconda -\u003e envs -\u003e python.exe 的文件位置，这样之后就会直接使用默认的 python 解释器（我猜的，还没有经过验证）。 配置 python 路径\r介绍\r对我来说，Jupyter Notebook 在编程时具有语法高亮、缩进、tab补全的功能。并且可以在代码块下方展示运行结果。对代码编写说明文档或语句时，支持 Markdown 语法，支持使用 LaTeX 编写数学性说明。我主要想的就是可以通过划分不同的代码块来加强代码的理解，同时还可以使用 markdown 语法来进行讲解，这个比 python 需要最后再运行强很多，我需要的就是这种划分代码段分别运行，最后还能关联在一起的效果。这里之后根据 官方指南 进行 jupyter 的讲解。 运行细胞\r在这里，每一个代码块被称为一个 cell。要运行代码，可以在命令和编辑模式下使用键盘快捷键。要运行当前单元格，使用 Ctrl+Enter。要运行当前单元格并前进到下一个单元格，使用 Shift+Enter。之后也可以使用图形界面的选项来进行相关操作。 上文提到了命令模式和编辑模式，所以这里需要知道运行细胞存在三种个状态：未选中、命令模式和编辑模式。代码单元格和编辑器边框左侧的垂直条显示单元格的当前状态。 当没有可见的栏时，该单元格未被选中。选择单元格后，它可以处于命令模式或编辑模式 在命令模式下，单元格左侧将出现一个实心垂直条，该单元可以进行操作并接受键盘命令 在编辑模式下，单元格编辑器周围有一个实心垂直条由边框连接起来，单元格的内容可以修改 在键盘上，按 Enter 键可进入编辑模式，按 Esc 键可进入命令模式。 注意 有的主题不能呈现上述的颜色条变化，所以为了兼顾主题和 jupyter，我选择 Github Theme 中的 Complete Dark 主题，起码比较而言，它可以兼顾两者。后面发现这个主题是在别的插件共同渲染下才满足我的想法的，把别的插件禁用之后就不太好看了，所以又找了一个插件 Learn with Sumit Theme，选择 Blue Velvet 主题。 快捷键\r命令模式\r快捷键 备注 Enter 转入编辑模式 Shift/Alt+Enter 运行当前选定的单元格并在紧邻下方插入一个新单元格（焦点移至新单元格） Ctrl+Alt+Enter 运行当前选定的单元格 y 单元转入代码状态 m 单元转入markdown状态 up 选中上方单元 k 选中上方单元 down 选中下方单元 j 选中下方单元 a 在上方插入新单元 b 在下方插入新单元 dd 删除选中的单元 l 转换行号 Shift+Space 向上滚动 Space 向下滚动 编辑模式\r这里实际上就是 vscode 的内置快捷键，但是由于我下载了 IDEA 快捷键的插件和别的一些插件，所以目前 vscode 的快捷键很混乱，下main记录一下当前可以使用的快捷键操作。 快捷键 备注 Esc 转入命令模式 Shift/Alt+Enter 运行当前选定的单元格并在紧邻下方插入一个新单元格（焦点移至新单元格） Ctrl+Alt+Enter 运行当前选定的单元格 Ctrl + X 剪切/剪切行（空选定） Ctrl + C 复制/复制行（空选定） Delete / Backspace 删除光标右边、左边的字 Alt + ↑ / ↓ 向上/向下移动行 Ctrl + D 向下复制行（来自 IDEA 的快捷键） Ctrl + Y 删除行（来自 IDEA 的快捷键） Ctrl + Shift + \\ 跳到匹配的括号 Ctrl + ] / [ 缩进/突出行 Ctrl + ← / → 光标到字首/字尾 Ctrl + / 切换行注释 Shift + Alt + A 切换块注释 ","date":"2024.12.3","objectID":"/blog/posts/config/vscode/:2:3","tags":["config"],"title":"VsCode 配置和使用","uri":"/blog/posts/config/vscode/"},{"categories":["config"],"content":"Vim\r为了方便在所有的编辑器中都可以使用同一套快捷键，所以采用了 Vim 作为自己的编辑方式，这里记录的就是自己的配置。对于 vscode 而言就是下载相应的插件，这里就是在插件市场搜索 Vim 插件进行下载即可，如下面图片所示。 Vim 插件\r关于 Vim 的具体配置和使用在另外一篇文章中，方便之后直接抄配置。 ","date":"2024.12.3","objectID":"/blog/posts/config/vscode/:2:4","tags":["config"],"title":"VsCode 配置和使用","uri":"/blog/posts/config/vscode/"},{"categories":["config"],"content":"为了更好的使用电脑，这里记录一下关于 Windows 的相关配置。 ","date":"2024.12.3","objectID":"/blog/posts/config/windows/:0:0","tags":["config"],"title":"Windows 便捷使用","uri":"/blog/posts/config/windows/"},{"categories":["config"],"content":"电脑相关\r","date":"2024.12.3","objectID":"/blog/posts/config/windows/:1:0","tags":["config"],"title":"Windows 便捷使用","uri":"/blog/posts/config/windows/"},{"categories":["config"],"content":"屏幕鼠标切换\r目前使用的是双屏，虽然想的是手不离开键盘，但是屏幕切换的时候总要调整当前鼠标的位置，不然焦点就在另一个屏幕上了。所以发现了项目 MouseSwitcher，这里我设置通过快捷键 \u003cAlt-left/right\u003e 进行鼠标的切换。虽然实验下来发现不能解决聚焦的问题，但是能切换鼠标就是进步，聚焦可以通过别的程序快捷键来实现。这里贴一下 介绍，可以看这个来进行掌握。 后期发现可以在 控制面板 -\u003e 轻松使用设置中心 -\u003e 使鼠标更易于使用 中进行配置，选择这个 通过将鼠标悬停在窗口上来激活窗口 就可以了。这样当我们在不同屏幕切换鼠标的时候，我们就可以直接激活聚焦于当前窗口了，快捷方便。 鼠标设置\r后面发现其实使用 \u003cShift-Tab\u003e 切换标签页也能实现聚焦的切换，然后配合上面的设置，就可以进行达成一样的效果。所以后期如果熟练使用标签页的话，可以把这个工具舍弃了。再后来发现这个 是鼠标更易于使用 的作用不大，当我进行界面的切换的时候，虽然鼠标不在我切换后的界面中，但是控制权已经切换了。像一些快捷键，比如 PgUp/PgDn 也可以在转换后的界面进行使用，所以这个可以不进行设置。设置后的坏处就是一些暂时的窗口，如 utools，状态栏 就会一闪而过，很烦人。 ","date":"2024.12.3","objectID":"/blog/posts/config/windows/:2:0","tags":["config"],"title":"Windows 便捷使用","uri":"/blog/posts/config/windows/"},{"categories":["config"],"content":"Edge\r","date":"2024.12.3","objectID":"/blog/posts/config/windows/:3:0","tags":["config"],"title":"Windows 便捷使用","uri":"/blog/posts/config/windows/"},{"categories":["config"],"content":"标签页切换\r面对众多标签页，可以使用快捷键进行切换。其中从左到右是 \u003cShift-Tab\u003e，从右到左是 \u003cCtrl-Shift-Tab\u003e。而对于我的垂直页面，从上到下就是 \u003cShift-Tab\u003e，从下到上就是 \u003cCtrl-Shift-Tab\u003e。同时可以使用 \u003cCtrl-count\u003e 的方式来切换标签页，\u003cCtrl-9\u003e 就是最后一个，而其它的则是按顺序特定切换。 ","date":"2024.12.3","objectID":"/blog/posts/config/windows/:3:1","tags":["config"],"title":"Windows 便捷使用","uri":"/blog/posts/config/windows/"},{"categories":["config"],"content":"主页展示\r使用 \u003cCtrl-T\u003e 可以直接打开新的主页，同时这里配置了 青柠起始页 插件，使得主页直接聚焦于上方搜索栏中，这样就可以直接键盘输入内容进行搜索了。并且 \u003cCtrl-N\u003e 为打开新的 edge 浏览器，可以实现新开。 ","date":"2024.12.3","objectID":"/blog/posts/config/windows/:3:2","tags":["config"],"title":"Windows 便捷使用","uri":"/blog/posts/config/windows/"},{"categories":["config"],"content":"其余操作\r可以使用 PhUp 和 PgDn(空格) 替代鼠标的滚轮，实现上下页滑动的效果 \u003cCtrl-l\u003e 和 \u003cAlt-d\u003e 都是选择地址栏中的 URL 以进行编辑 \u003cCtrl-r\u003e 和 F5 作用一样，重新加载当前页，不过有缓存内容，加上 Shift 可以忽略缓存内容 \u003cCtrl-w\u003e 关闭当前标签页，加上 Shift 就是关闭当前窗口了 \u003cAlt-left/right\u003e 是返回/前进，但是我们在上面屏幕的切换中占用了这个快捷键，所以不能使用了 ","date":"2024.12.3","objectID":"/blog/posts/config/windows/:3:3","tags":["config"],"title":"Windows 便捷使用","uri":"/blog/posts/config/windows/"},{"categories":["config"],"content":"Vscode\r具体就是看 VsCode 配置和使用那篇文章，里面包含快捷键的使用。 ","date":"2024.12.3","objectID":"/blog/posts/config/windows/:4:0","tags":["config"],"title":"Windows 便捷使用","uri":"/blog/posts/config/windows/"},{"categories":["android"],"content":"记录一下 Unidbg 的使用。 具体的介绍就不讲了，使用就是直接从 官网 拉取代码，然后在 IDEA 中进行配置即可。基础操作可以看 博客。 ","date":"2024.11.30","objectID":"/blog/posts/android/unidbg/:0:0","tags":["android"],"title":"Unidbg 记录","uri":"/blog/posts/android/unidbg/"},{"categories":["android"],"content":"基础板子\r下面展示的就是基础使用的板子，每次对于 so 文件的分析都需要先设置这个板子，然后再在板子上进行自己需要的配置。 package com.ctf.wmctf; import com.github.unidbg.AndroidEmulator; import com.github.unidbg.Module; import com.github.unidbg.linux.android.AndroidEmulatorBuilder; import com.github.unidbg.linux.android.AndroidResolver; import com.github.unidbg.linux.android.dvm.DalvikModule; import com.github.unidbg.linux.android.dvm.VM; import com.github.unidbg.memory.Memory; import java.io.File; public class easyAndroid { private final AndroidEmulator emulator; private final VM vm; private final Module module; private final boolean logging; easyAndroid(boolean logging) { this.logging = logging; emulator = AndroidEmulatorBuilder.for64Bit() .setProcessName(\"com.s0rry.easyandroid\") .build(); // 创建模拟器实例，进程名建议依照实际进程名填写，可以规避针对进程名的校验 final Memory memory = emulator.getMemory(); // 模拟器的内存操作接口 memory.setLibraryResolver(new AndroidResolver(23)); // 设置系统类库解析 // 创建 Android 虚拟机并传入 APK（可不传，感觉无所谓），Unidbg 可以替我们做部分签名校验的工作 vm = emulator.createDalvikVM(new File(\"unidbg-android\\\\unidbg-android\\\\src\\\\test\\\\resources\\\\ctf\\\\wmctf\\\\easyAndroid.apk\")); vm.setVerbose(logging); // 设置是否打印Jni调用细节 // 加载目标 so 文件到 unicorn 虚拟内存，加载成功以后会默认调用 init_array 等函数 DalvikModule dm = vm.loadLibrary(new File(\"unidbg-android\\\\src\\\\test\\\\resources\\\\ctf\\\\wmctf\\\\libeasyandroid.so\"), true); dm.callJNI_OnLoad(emulator); // 手动执行JNI_OnLoad函数 module = dm.getModule(); // 获取本 so 模块的句柄 } public static void main(String[] args) { easyAndroid easyandroid = new easyAndroid(true); } } ","date":"2024.11.30","objectID":"/blog/posts/android/unidbg/:1:0","tags":["android"],"title":"Unidbg 记录","uri":"/blog/posts/android/unidbg/"},{"categories":["android"],"content":"Hook\rhook 在 Unidbg 感觉是最为重要的东西。有了它的存在，我们才能在调试中获取更多的信息，及其推荐一篇 文章，这个写的极好，感觉把我自己能想到的需要 hook 的场景方法都讲了一遍。 ","date":"2024.11.30","objectID":"/blog/posts/android/unidbg/:2:0","tags":["android"],"title":"Unidbg 记录","uri":"/blog/posts/android/unidbg/"},{"categories":["android"],"content":"hook 时机过晚\r我们正常的 hook 都是位于 so 加载之后，执行 JNI_OnLoad 之前，而我们的加载顺序为 init -\u003e init_array -\u003e JNI_OnLoad，所以如果 .init 段 和 .init_array 段存在代码逻辑，我们想要去 hook，那么使用之前的方法就太晚了，所以我们需要将 hook 的时机提前到 init 执行前。由此可以看上面文章的 讲述，存在三种应对方案，我这里只是为了快速回忆而做的笔记： 提前加载 libc：这个就需要我们想要 hook 的是目标函数中的 libc 函数。比如 .init 段存在 strcmp，我们想看看比对的数据，这个时候就可以首先 hook libc 来得到相关数据。但是如果目标函数不是这个，而是某个地址的寄存器信息等，那么就没有办法了。 固定地址下断点：我们都是通过 vm.loadLibrary 来加载第一个用户的 so 文件，基地址固定为 0x40000000。因此可以通过偏移和基地址计算出固定地址，之后通过 Console Debugger 来 Hook。 使用 Unidbg 提供的模块监听器：这是我认为最为合适的方案，就是添加一个监听器。之后要么用第三方 hook 框架，要么使用原生 unicornHook，这两个分情况使用，但是这个方案我觉得最为合适。具体的使用可以看看自己写的 WMCTF2024 easyAndroid 的反混淆 -\u003e notion。 ","date":"2024.11.30","objectID":"/blog/posts/android/unidbg/:2:1","tags":["android"],"title":"Unidbg 记录","uri":"/blog/posts/android/unidbg/"},{"categories":["android"],"content":"注意事项\r在 unidbg 的项目中不要进行 IDA 的分析，因为产生的分析文件是只读的，Maven 不能自动复制它们，这就会产生 build 的错误 ","date":"2024.11.30","objectID":"/blog/posts/android/unidbg/:3:0","tags":["android"],"title":"Unidbg 记录","uri":"/blog/posts/android/unidbg/"},{"categories":["compile"],"content":"这里记录 llvm、ir 相关知识。 ","date":"2024.11.28","objectID":"/blog/posts/compile/llvm-ir-control/:0:0","tags":["compile"],"title":"04 LLVM IR Control","uri":"/blog/posts/compile/llvm-ir-control/"},{"categories":["compile"],"content":"LLVM\r","date":"2024.11.28","objectID":"/blog/posts/compile/llvm-ir-control/:1:0","tags":["compile"],"title":"04 LLVM IR Control","uri":"/blog/posts/compile/llvm-ir-control/"},{"categories":["compile"],"content":"介绍\r注意 The LLVM Project is a collection of modular and reusable compiler and tool-chain technologies. Despite its name, LLVM has little to do with traditional virtual machines. The name “LLVM” itself is not an acronym; it is the full name of the project. LLVM IR\r","date":"2024.11.28","objectID":"/blog/posts/compile/llvm-ir-control/:1:1","tags":["compile"],"title":"04 LLVM IR Control","uri":"/blog/posts/compile/llvm-ir-control/"},{"categories":["compile"],"content":"IR\rIR\rIR 生成\r使用 clang -S -emit-llvm -fno-discard-value-names xxx.c -o xxx.ll -O1 -g0 将 c 代码转化为 IR 的形式。 -S：生成汇编代码（IR）作为输出，而不是直接生成二进制文件或可执行文件 -emit-llvm：生成 LLVM 中间表示（IR），而不是目标平台的汇编代码。-S 都是和它一起进行使用 -fno-discard-value-names：在生成的 IR 中不丢弃值的名称（如变量名和函数名），保留符号信息，便于调式或分析 -o xxx.ll：指定生成人类可读的 .ll 形式文件，而不是 bitcode 形式的 .bc 形式文件 -O1：优化级别设置，-O1 表示中等优化级别 -g0：控制调试信息的级别，它表示不包含调试信息 之后会形成下面形式的代码。它是强类型，同时为三地址码和静态单赋值形式。 .ll文件\r这里静态单赋值就是每个寄存器只被定义一次，也就是它只在左侧出现一遍，右侧没有限制。这样在软件上就可以实现无限制个数的寄存器了，同时对于变量定义的寻找也更为简便。下面就是 SSA 的转换，要使控制流满足 SSA，那么需要使用 $\\phi$ 函数来根据控制流决定选择 y1 还是 y2。 SSA转换\r不同优化等级的控制流\r都是对于下面的代码通过上述命令生成不同优化等级的 IR 代码。 int factorial(int val){ if(val == 0){ return 1; } return val * factorial(val - 1); } 下面就是没有优化的 CFG 图，可以看出它有一个开辟空间的操作，同时左右分支都把结果传到了 %2 这个寄存器之中，然后返回基本块姐可以直接使用这个进行返回。 无优化 CFG\r而下面就是 o1 优化的 CFG 图，它使用了 $\\phi$ 函数来对分支进行处理，若是从 %3 基本块跳转来的，那么返回值使用 %6；若是从 %1 基本块跳转来的，返回值使用 1。 o1 优化 CFG\r然后对于下面的代码，不同优化等级的 IR 代码列举如下。 int factorial(int val){ int temp = 1; for (int i = 2; i \u003c= val; i ++){ temp *= i; } return temp; } 这里没有优化的话，就会出现开辟空间的操作（下面的 alloca），然后因此涉及 load 和 store 操作。 无优化版本\r而若是采用了 o1 优化，那么上述开辟空间和加载等就没有了，整个代码都很简洁，多出了 $\\phi$ 函数的操作。 o1 优化版本\r","date":"2024.11.28","objectID":"/blog/posts/compile/llvm-ir-control/:1:2","tags":["compile"],"title":"04 LLVM IR Control","uri":"/blog/posts/compile/llvm-ir-control/"},{"categories":["compile"],"content":"中间代码生成\r","date":"2024.11.28","objectID":"/blog/posts/compile/llvm-ir-control/:2:0","tags":["compile"],"title":"04 LLVM IR Control","uri":"/blog/posts/compile/llvm-ir-control/"},{"categories":["compile"],"content":"表达式翻译\r非布尔表达式翻译\r这里如图所示，E.code 表示翻译后的中间代码，E.addr 表示原本的变量和生成的中间变量。下面的流程就是通过构建语法树，然后自底向上匹配规则，逐一生成中间变量，同时也就生成了中间代码。 表达式翻译\r数组引用翻译\r下面就是数组引用的中间代码翻译流程，我们首先就是需要对声明进行解析，这样我们才能得到数组的宽度。之后才会对于 i，j 进行解析，运用公式得到最后的地址。 数组引用翻译\r对于数组声明就采用之前的翻译制导方案，通过继承属性和综合属性来传递相关信息，最后形成数组类型。 语法制导翻译\r翻译规则\r翻译语法树\r这里主要关注 getelementptr，它对于数组元素进行解包获取内部信息。对于这里的参数 [2 x [3 x i32]] 是 base type，[2 x [3 x i32]]* %2 是数组的首地址，同时返回一个指向元素的指针，所以后面需要进行 load 操作。 翻译后中间代码\r","date":"2024.11.28","objectID":"/blog/posts/compile/llvm-ir-control/:2:1","tags":["compile"],"title":"04 LLVM IR Control","uri":"/blog/posts/compile/llvm-ir-control/"},{"categories":["compile"],"content":"控制流翻译（easy）\r这里就是对于下面的产生式进行翻译，转化为中间代码的形式。同时使用的是 Visitor 方式，因为我们这里需要及时输出生成的中间代码，避免频繁的字符串拼接操作，而使用 Listener 模式会有上面的问题，直接进行 Attributed Grammar 方式则会很麻烦。 同时这里为简单模式的翻译，它只需要使用综合属性，各个非终结符的分工、合作明确。所以产生的代码也相对冗杂。 产生式翻译\r翻译规则\rif 条件语句\r下面就是对于 if 条件语句的翻译规则。总结起来就是我们首先需要标记两个标签 true 和 false，然后看 if 中的 cond 来分配这两个标签到 if 中的语句块和 if 结尾，这样我们就实现了对于 if 语句的翻译。 最终生成的 IR 也是如下面的类型： # 源代码 if (true) { a = b; b = c; } # 翻译代码 br true b.true1 b.false2 b.true1: a = b c = c b.false2: if else 语句\r而对于 if else 形式的，需要在上面的基础上添加一个 end 的标签，这样比如在 true 的语句执行完之后，直接到 if 之后的语句，而不是 else 语句。 最终生成的 IR 也是如下面的类型： # 源代码 if (true) { a = b; if (true) { c = d; } else { e = g; } } else { d = f; } # 翻译代码 br true b.true1 b.false2 b.true1: a = b br true b.true4 b.false5 b.true4: c = d br end.6 b.false5: e = g b.end6: br b.end3 b.false2: d = f b.end3: while 循环语句\r对于 while 循环，我们需要设置一个 begin 的标签，这样我们才可以在满足循环条件的前提下从头开始执行代码。 # 源代码 while (true) { a = b; if (true) { c = d; } else { e = f; } } a = c; # 翻译代码 begin1: br true b.true2 b.false3 b.true2: a = b br true b.true4 b.false5 b.true4: c = d br b.end6 b.false5: e = f b.end6: br begin1 b.false3: a = c break 语句\r这里 break 语句的翻译难点就在于它只会跳出离他最近的一层循环，所以我们需要追踪它会跳到哪一个标签处。面对这种情况，我们采用栈结构来存储相关标签。如下图所示，我们在内外层 while 处分别压入相关标签，面对 break 时就跳到栈顶的标签处，这样就实现了只跳出离它最近一层的功能。 break 栈展示\r# 源代码 while (true) { while (false) { if (true) { break; # 这里的 break 只会跳出 while } a = b; } a = c; break; a = d; } a = e; # 翻译代码 begin1: br true b.true2 b.false3 b.true2: begin4: br false b.true5 b.false6 b.true5: br true b.true7 b.false8 b.true7: br b.false6 b.false8: a = b br begin4 b.false6: a = c br b.flase3 a = d br begin1 b.false3: a = e 短路求值\r短路求值和 if else 语句很像，例如 ||，前面的正确后，要标记正确并跳转到最后，前面失败，那么就看后面的正误来跳转。 # 源代码 while (true || false) { a = b; } a = c; # 翻译代码 begin1: br true or.true2 or.false3 or.false3: t1 = false br or.end4 or.true2: t1 = true or.end4: br t1 b.true5 b.false6 b.true5: a = b br begin1 b.false6: a = c ","date":"2024.11.28","objectID":"/blog/posts/compile/llvm-ir-control/:2:2","tags":["compile"],"title":"04 LLVM IR Control","uri":"/blog/posts/compile/llvm-ir-control/"},{"categories":["compile"],"content":"控制流翻译（hard）\r这里为困难模式，和简单模式相比，它直接用布尔表达式改变控制流，无需计算最终逻辑值，即将不同非终结符的作用混杂在一起。因此它需要从父节点获取更具体的跳转目标，缩短跳转路径。为此父节点要为子节点准备跳转指令的目标标签，子节点就通过继承属性确定跳转目标。 if 语句\r如下图所示，在困难模式下 $B.false = S_{1}.next = S.next$，这样通过将不同非终结符设置的标签根据位置组合成一个的做法简化了生成的代码。 相关操作\rif 语句\rif else 语句\r相关操作\rif else 语句\rwhile 循环语句\r相关操作\rwhile 循环语句\r布尔表达式\r布尔表达式\r具体例子\r","date":"2024.11.28","objectID":"/blog/posts/compile/llvm-ir-control/:2:3","tags":["compile"],"title":"04 LLVM IR Control","uri":"/blog/posts/compile/llvm-ir-control/"},{"categories":["compile"],"content":"backpatch\r技术介绍\r根据以下的规则，综合属性 $B.truelist$ 保存需要跳转到 $B.true$ 标签的指令，综合属性 $B.falselist$ 保存需要跳转到 $B.false$ 标签的指令，综合属性 $S/L.nextlist$ 保存需要跳转到 $S/L.next$ 标签的指令。 之后就是为左部非终结符 $B$ 计算综合属性 $B.truelist$ 与 $B.falselist$，为左部非终结符 $S/L$ 计算综合属性 $S/L.nextlist$，并考虑每个综合属性，为已能确定目标地址的跳转指令进行回填。下面只有 (3) 与 (7) 的 gen 生成了新的代码，控制流语句主要目的就是 控制 流。 相关规则\r由上面的做法，需要为回填操作添加多的属性来获取信息，由此就有了 M 属性和 N 属性。 M 属性\rM 属性就是获取下一个 code 的第一条语句的位置，这样我们就可以得到相关的位置信息了，之后我们就可以根据这个信息来进行回填。 M 属性示例\rN 属性\rN 属性就是添加一条 goto 语句，一开始就是为了解决 if else 的跳转到最后的情况。 N 相关规则\r","date":"2024.11.28","objectID":"/blog/posts/compile/llvm-ir-control/:2:4","tags":["compile"],"title":"04 LLVM IR Control","uri":"/blog/posts/compile/llvm-ir-control/"},{"categories":["compile"],"content":"目标代码生成\r","date":"2024.11.28","objectID":"/blog/posts/compile/llvm-ir-control/:3:0","tags":["compile"],"title":"04 LLVM IR Control","uri":"/blog/posts/compile/llvm-ir-control/"},{"categories":["reverse"],"content":"记录一下在逆向过程中常使用的算法，记录一下 python 脚本。 ","date":"2024.11.27","objectID":"/blog/posts/reverse/algorithm/:0:0","tags":["reverse","algorithm"],"title":"逆向中的算法","uri":"/blog/posts/reverse/algorithm/"},{"categories":["reverse"],"content":"base64\rfrom Crypto.Util.number import * # Base64 字符表 table = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\" def encode(data): n = bytes_to_long(data) # 转换为整数 pad = (3 - (len(data) % 3)) % 3 # 计算需要填充的字节数 n \u003c\u003c= 8 * pad # 左移填充 indices = [] # 存储 Base64 索引 while n: # 逐步取模 indices.append(n % 64) n //= 64 indices = indices[::-1] # 反转顺序 result = \"\".join([table[i] for i in indices]) # 索引映射到字符表 result += \"=\" * pad # 添加填充字符 print(result) encode(b\"flag{wecome_to_try_base64}\") 直接使用库来进行加解密 import base64 # Python3 中字符都是 unicode 编码，而 b64encode函数的参数为 byte 类型，所以必须先转码 enc = base64.b64encode(\"AlwaysBeta\".encode(\"utf-8\")) dec = base64.b64decode(enc) # 换表解密 new_table = \"ABCDEFQRSTUVWXYPGHIJKLMNOZabcdefghijklmnopqrstuvwxyz0123456789+/\" old_table = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\" cipher = \"zMXHz3TIgnxLxJhFAdtZn2fFk3lYCrtPC2l9\".swapcase() # swapcase 是大小写转化，大写转小写等 print(base64.b64decode(cipher.translate(str.maketrans(new_table, old_table)))) ","date":"2024.11.27","objectID":"/blog/posts/reverse/algorithm/:1:0","tags":["reverse","algorithm"],"title":"逆向中的算法","uri":"/blog/posts/reverse/algorithm/"},{"categories":["reverse"],"content":"RC4\rdef RC4(input, key): sbox = list(range(256)) j = 0 for i in range(256): j = (j + sbox[i] + key[i % len(key)]) % 256 sbox[i], sbox[j] = sbox[j], sbox[i] i, j = 0, 0 output = [] keystream = [] for k in range(len(input)): i = (i + 1) % 256 j = (j + sbox[i]) % 256 sbox[i], sbox[j] = sbox[j], sbox[i] keystream.append(sbox[(sbox[i] + sbox[j]) % 256]) output.append(input[k] ^ keystream[k]) return bytes(output), keystream key = b\"fun@eZ\" out = RC4(b\"Hello, world!\", key)[0] print(out) inp = RC4(out, key)[0] print(inp) ","date":"2024.11.27","objectID":"/blog/posts/reverse/algorithm/:2:0","tags":["reverse","algorithm"],"title":"逆向中的算法","uri":"/blog/posts/reverse/algorithm/"},{"categories":["reverse"],"content":"Tea 系列\r","date":"2024.11.27","objectID":"/blog/posts/reverse/algorithm/:3:0","tags":["reverse","algorithm"],"title":"逆向中的算法","uri":"/blog/posts/reverse/algorithm/"},{"categories":["reverse"],"content":"tea\rfrom ctypes import * def encrypt(rounds, v, k): v0, v1 = c_uint32(v[0]), c_uint32(v[1]) delta = 0x9E3779B9 sum = c_uint32(0) k0, k1, k2, k3 = c_uint32(k[0]), c_uint32(k[1]), c_uint32(k[2]), c_uint32(k[3]) for i in range(rounds): sum.value += delta v0.value += ((v1.value \u003c\u003c 4) + k0.value) ^ (v1.value + sum.value) ^ ((v1.value \u003e\u003e 5) + k1.value) v1.value += ((v0.value \u003c\u003c 4) + k2.value) ^ (v0.value + sum.value) ^ ((v0.value \u003e\u003e 5) + k3.value) return [v0.value, v1.value] def decrypt(rounds, v, k): v0, v1 = c_uint32(v[0]), c_uint32(v[1]) delta = 0x9E3779B9 sum = c_uint32(delta * rounds) k0, k1, k2, k3 = c_uint32(k[0]), c_uint32(k[1]), c_uint32(k[2]), c_uint32(k[3]) for i in range(rounds): v1.value -= (((v0.value \u003c\u003c 4) + k2.value) ^ (v0.value + sum.value) ^ ((v0.value \u003e\u003e 5) + k3.value)) v0.value -= (((v1.value \u003c\u003c 4) + k0.value) ^ (v1.value + sum.value) ^ ((v1.value \u003e\u003e 5) + k1.value)) sum.value -= delta return [v0.value, v1.value] v = [1, 2] k = [1, 2, 3, 4] enc = encrypt(32, v, k) print(\"%#x %#x\" % (enc[0], enc[1])) dec = decrypt(32, enc, k) print(\"%#x %#x\" % (dec[0], dec[1])) ","date":"2024.11.27","objectID":"/blog/posts/reverse/algorithm/:3:1","tags":["reverse","algorithm"],"title":"逆向中的算法","uri":"/blog/posts/reverse/algorithm/"},{"categories":["reverse"],"content":"xtea\rfrom ctypes import * def encrypt(rounds, v, k): v0, v1 = c_uint32(v[0]), c_uint32(v[1]) delta = 0x9E3779B9 sum = c_uint32(0) for i in range(rounds): v0.value += (((v1.value \u003c\u003c 4) ^ (v1.value \u003e\u003e 5)) + v1.value) ^ (sum.value + k[sum.value \u0026 3]) sum.value += delta v1.value += (((v0.value \u003c\u003c 4) ^ (v0.value \u003e\u003e 5)) + v0.value) ^ (sum.value + k[(sum.value \u003e\u003e 11) \u0026 3]) return [v0.value, v1.value] def decrypt(rounds, v, k): v0, v1 = c_uint32(v[0]), c_uint32(v[1]) delta = 0x9E3779B9 sum = c_uint32(delta * rounds) for i in range(rounds): v1.value -= (((v0.value \u003c\u003c 4) ^ (v0.value \u003e\u003e 5)) + v0.value) ^ (sum.value + k[(sum.value \u003e\u003e 11) \u0026 3]) sum.value -= delta v0.value -= (((v1.value \u003c\u003c 4) ^ (v1.value \u003e\u003e 5)) + v1.value) ^ (sum.value + k[sum.value \u0026 3]) return [v0.value, v1.value] v = [1, 2] k = [1, 2, 3, 4] enc = encrypt(32, v, k) print(\"%#x %#x\" % (enc[0], enc[1])) dec = decrypt(32, enc, k) print(\"%#x %#x\" % (dec[0], dec[1])) ","date":"2024.11.27","objectID":"/blog/posts/reverse/algorithm/:3:2","tags":["reverse","algorithm"],"title":"逆向中的算法","uri":"/blog/posts/reverse/algorithm/"},{"categories":["reverse"],"content":"xxtea\rfrom ctypes import * def MX(z, y, total, key, p, e): temp1 = (z.value \u003e\u003e 5 ^ y.value \u003c\u003c 2) + (y.value \u003e\u003e 3 ^ z.value \u003c\u003c 4) temp2 = (total.value ^ y.value) + (key[(p \u0026 3) ^ e.value] ^ z.value) return c_uint32(temp1 ^ temp2) def encrypt(n, v, key): delta = 0x9E3779B9 rounds = 6 + 52 // n total = c_uint32(0) z = c_uint32(v[n - 1]) e = c_uint32(0) while rounds \u003e 0: total.value += delta e.value = (total.value \u003e\u003e 2) \u0026 3 for p in range(n - 1): y = c_uint32(v[p + 1]) v[p] = c_uint32(v[p] + MX(z, y, total, key, p, e).value).value z.value = v[p] y = c_uint32(v[0]) v[n - 1] = c_uint32(v[n - 1] + MX(z, y, total, key, n - 1, e).value).value z.value = v[n - 1] rounds -= 1 return v def decrypt(n, v, key): delta = 0x9E3779B9 rounds = 6 + 52 // n total = c_uint32(rounds * delta) y = c_uint32(v[0]) e = c_uint32(0) while rounds \u003e 0: e.value = (total.value \u003e\u003e 2) \u0026 3 for p in range(n - 1, 0, -1): z = c_uint32(v[p - 1]) v[p] = c_uint32((v[p] - MX(z, y, total, key, p, e).value)).value y.value = v[p] z = c_uint32(v[n - 1]) v[0] = c_uint32(v[0] - MX(z, y, total, key, 0, e).value).value y.value = v[0] total.value -= delta rounds -= 1 return v v = [0x1, 0x2] k = [0x1, 0x2, 0x3, 0x4] n = 2 # 这里2为轮数，也就是 v 的个数 enc = encrypt(n, v, k) print(\"%#x %#x\" % (enc[0], enc[1])) dec = decrypt(n, enc, k) print(\"%#x %#x\" % (dec[0], dec[1])) ","date":"2024.11.27","objectID":"/blog/posts/reverse/algorithm/:3:3","tags":["reverse","algorithm"],"title":"逆向中的算法","uri":"/blog/posts/reverse/algorithm/"},{"categories":["reverse"],"content":"SM 系列\r","date":"2024.11.27","objectID":"/blog/posts/reverse/algorithm/:4:0","tags":["reverse","algorithm"],"title":"逆向中的算法","uri":"/blog/posts/reverse/algorithm/"},{"categories":["reverse"],"content":"SM4\rSM4 算法的原理参考这篇 文章。这里需要注意一下， SM4 是对称密码，它一次性加密 32 x 4 bit 的数据，也就是对 16 字节的数据进行加密。 # S盒，用于字节替换 S_BOX = [ 0xd6, 0x90, 0xe9, 0xfe, 0xcc, 0xe1, 0x3d, 0xb7, 0x16, 0xb6, 0x14, 0xc2, 0x28, 0xfb, 0x2c, 0x05, 0x2b, 0x67, 0x9a, 0x76, 0x2a, 0xbe, 0x04, 0xc3, 0xaa, 0x44, 0x13, 0x26, 0x49, 0x86, 0x06, 0x99, 0x9c, 0x42, 0x50, 0xf4, 0x91, 0xef, 0x98, 0x7a, 0x33, 0x54, 0x0b, 0x43, 0xed, 0xcf, 0xac, 0x62, 0xe4, 0xb3, 0x1c, 0xa9, 0xc9, 0x08, 0xe8, 0x95, 0x80, 0xdf, 0x94, 0xfa, 0x75, 0x8f, 0x3f, 0xa6, 0x47, 0x07, 0xa7, 0xfc, 0xf3, 0x73, 0x17, 0xba, 0x83, 0x59, 0x3c, 0x19, 0xe6, 0x85, 0x4f, 0xa8, 0x68, 0x6b, 0x81, 0xb2, 0x71, 0x64, 0xda, 0x8b, 0xf8, 0xeb, 0x0f, 0x4b, 0x70, 0x56, 0x9d, 0x35, 0x1e, 0x24, 0x0e, 0x5e, 0x63, 0x58, 0xd1, 0xa2, 0x25, 0x22, 0x7c, 0x3b, 0x01, 0x21, 0x78, 0x87, 0xd4, 0x00, 0x46, 0x57, 0x9f, 0xd3, 0x27, 0x52, 0x4c, 0x36, 0x02, 0xe7, 0xa0, 0xc4, 0xc8, 0x9e, 0xea, 0xbf, 0x8a, 0xd2, 0x40, 0xc7, 0x38, 0xb5, 0xa3, 0xf7, 0xf2, 0xce, 0xf9, 0x61, 0x15, 0xa1, 0xe0, 0xae, 0x5d, 0xa4, 0x9b, 0x34, 0x1a, 0x55, 0xad, 0x93, 0x32, 0x30, 0xf5, 0x8c, 0xb1, 0xe3, 0x1d, 0xf6, 0xe2, 0x2e, 0x82, 0x66, 0xca, 0x60, 0xc0, 0x29, 0x23, 0xab, 0x0d, 0x53, 0x4e, 0x6f, 0xd5, 0xdb, 0x37, 0x45, 0xde, 0xfd, 0x8e, 0x2f, 0x03, 0xff, 0x6a, 0x72, 0x6d, 0x6c, 0x5b, 0x51, 0x8d, 0x1b, 0xaf, 0x92, 0xbb, 0xdd, 0xbc, 0x7f, 0x11, 0xd9, 0x5c, 0x41, 0x1f, 0x10, 0x5a, 0xd8, 0x0a, 0xc1, 0x31, 0x88, 0xa5, 0xcd, 0x7b, 0xbd, 0x2d, 0x74, 0xd0, 0x12, 0xb8, 0xe5, 0xb4, 0xb0, 0x89, 0x69, 0x97, 0x4a, 0x0c, 0x96, 0x77, 0x7e, 0x65, 0xb9, 0xf1, 0x09, 0xc5, 0x6e, 0xc6, 0x84, 0x18, 0xf0, 0x7d, 0xec, 0x3a, 0xdc, 0x4d, 0x20, 0x79, 0xee, 0x5f, 0x3e, 0xd7, 0xcb, 0x39, 0x48 ] # 轮常数，用于密钥扩展 FK = [0xa3b1bac6, 0x56aa3350, 0x677d9197, 0xb27022dc] # 固定参数，用于轮密钥生成 CK = [ 0x00070e15, 0x1c232a31, 0x383f464d, 0x545b6269, 0x70777e85, 0x8c939aa1, 0xa8afb6bd, 0xc4cbd2d9, 0xe0e7eef5, 0xfc030a11, 0x181f262d, 0x343b4249, 0x50575e65, 0x6c737a81, 0x888f969d, 0xa4abb2b9, 0xc0c7ced5, 0xdce3eaf1, 0xf8ff060d, 0x141b2229, 0x30373e45, 0x4c535a61, 0x686f767d, 0x848b9299, 0xa0a7aeb5, 0xbcc3cad1, 0xd8dfe6ed, 0xf4fb0209, 0x10171e25, 0x2c333a41, 0x484f565d, 0x646b7279 ] def byte_sub(byte): \"\"\"S盒字节替换\"\"\" return S_BOX[byte] def l_transformation(b): \"\"\"线性变换\"\"\" return b ^ (b \u003c\u003c 2) ^ (b \u003c\u003c 10) ^ (b \u003c\u003c 18) ^ (b \u003c\u003c 24) def t_function(x): \"\"\"T函数，包括S盒替换和线性变换\"\"\" b = byte_sub((x \u003e\u003e 24) \u0026 0xFF) \u003c\u003c 24 | \\ byte_sub((x \u003e\u003e 16) \u0026 0xFF) \u003c\u003c 16 | \\ byte_sub((x \u003e\u003e 8) \u0026 0xFF) \u003c\u003c 8 | \\ byte_sub(x \u0026 0xFF) return l_transformation(b) def key_expansion(key): \"\"\"密钥扩展生成32轮密钥\"\"\" K = [key[i] ^ FK[i] for i in range(4)] rk = [] for i in range(32): temp = K[i] ^ t_function(K[i + 1] ^ K[i + 2] ^ K[i + 3] ^ CK[i]) rk.append(temp) K.append(temp) return rk def sm4_encrypt_block(plaintext, key): \"\"\"SM4单块加密\"\"\" rk = key_expansion(key) X = plaintext.copy() for i in range(32): temp = X[i] ^ t_function(X[i + 1] ^ X[i + 2] ^ X[i + 3] ^ rk[i]) X.append(temp) return X[35:31:-1] # 反序输出 def sm4_decrypt_block(ciphertext, key): \"\"\"SM4单块解密\"\"\" rk = key_expansion(key)[::-1] # 轮密钥反序 X = ciphertext.copy() for i in range(32): temp = X[i] ^ t_function(X[i + 1] ^ X[i + 2] ^ X[i + 3] ^ rk[i]) X.append(temp) return X[35:31:-1] # 反序输出 # 示例使用 plaintext = [0x01234567, 0x89abcdef, 0xfedcba98, 0x76543210] key = [0x01234567, 0x89abcdef, 0xfedcba98, 0x76543210] ciphertext = sm4_encrypt_block(plaintext, key) print(f\"encrypt: {ciphertext}\") decrypted_text = sm4_decrypt_block(ciphertext, key) print(f\"decrypt: {decrypted_text}\") ","date":"2024.11.27","objectID":"/blog/posts/reverse/algorithm/:4:1","tags":["reverse","algorithm"],"title":"逆向中的算法","uri":"/blog/posts/reverse/algorithm/"},{"categories":["config"],"content":"记录一下每次刷机和刷机之后需要的配置 ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:0:0","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"刷机\r这里记录一下刷机的流程，都是按照我的 pixel3 手机来的。 ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:1:0","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"解锁 OEM 和 BL\r首先是通过在设置 \u003e 系统 \u003e 关于手机多次点击版本号，知道提示进入开发者模式。之后在手机的设置 \u003e 系统 \u003e 开发者选项中找到 OEM 解锁，将其打开。 最后就是使用以下命令解锁 BL 锁，解锁之后，手机会重置。 adb devices # 先检查设备是否存在，存在则执行以下指令 adb reboot bootloader # 重启进入fastboot mode fastboot flashing unlock # 解锁 ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:1:1","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"驱动安装\rwindows 需要进行这一步，不然可能识别不了手机。从 官网 下载驱动安装，之后进入设备管理器 \u003e 其它设备下查看相应的设备，右键更新驱动程序，选择浏览我的电脑以查找驱动程序，将下载驱动解压缩路径选中，点击下一步，安装即可 ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:1:2","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"刷入官方镜像\r我使用的手机是 pixel3，所以直接从 google 镜像官网找 blueline 型号的镜像下载。解压压缩包之后进入目录，运行下面的命令，等待萨湖如官方镜像完成。 adb reboot bootloader # 先进入bootloader模式 ./flash-all.sh ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:1:3","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"使用 Magisk 进行 Root\r先从 官方 下载面具，之后使用 adb install xx.apk 来进行安装。之后从上面的官方镜像的 image-blueline-xxxxxx.zip 中得到 boot.img 文件，通过 adb push boot.img /sdcard/ 上传到手机之后，使用 Magisk，点击安装 \u003e 选择并修补一个文件对该文件进行修补，之后会得到 magisk_patched-xxx_xxx.img 文件。在把这个文件通过 adb pull /sdcard/Download/magisk_patched-xxx_xxx.img 下载到电脑，再次刷入即可 root。 adb reboot bootloader # 先进入fastboot mode fastboot flash boot magisk_patched-xxx_xxx.img 只需要在 adb shell 中执行 su 命令，Magisk 弹出确认，点击允许即可获取 root。 ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:1:4","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"软件下载\r","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:2:0","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"Magisk\r上面说了下载链接，这里就不展开述说了。面具的作用有很多，我觉得最主要的就是获取 root 权限，由此可以配合使用很多操作。 同时可以下载 zygisk，可以有更多修改能力，也可以下载 LSPosed，启动 Xposed Hook。 ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:2:1","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"CaptiveMgr\r去除 WiFi 受限无法连接叹号的问题，自己软件的下在链接忘了，贴一个别人存的地址，应该是一样的。相关博客。 ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:2:2","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"Termux\rTermux是一个适用于 Android 的终端模拟器，其环境类似于 Linux 环境。 无需Root或设置即可使用。 Termux 会自动进行最小安装 - 使用 APT 包管理器即可获得其他软件包。可以从 官方网址 进行下载。 Linux 中很多命令 Android 中都没有，下载又很麻烦，所以使用这个终端可以方便运行各项命令，因为可以直接使用包管理来进行软件下载。 ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:2:3","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"使用\r","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:3:0","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["config"],"content":"投屏\r因为存在需求要把安卓的屏幕投射到电脑上，所以下载了 晨钟酱 的 投屏控制器，虽然启动的慢，但是它可以进行黑屏启动，这样就不需要被手机的息屏给打断了。不过后续发现，过一段时间，这个也会和 QtScrcpy 一样黑屏不显示，所以还是推荐使用 QtScrcpy，毕竟它启动的快一些。 投屏控制器\r","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:3:1","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["android"],"content":"借鉴 《程序员的自我修养》，ELF视频 和 文字记录 做的笔记。主要想要探究一下 ELF 的链接和装载。 这里以 ARM-v8a 架构中的 ls 举例讲解 ELF 文件格式。 ","date":"2024.11.24","objectID":"/blog/posts/android/elf/:0:0","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"基础配置\r这里使用 /system/bin/ls 文件来进行分析，首先将其复制一份放在 /data/local/tmp 目录中，之后 pull 到本地使用 010 Editor 进行修改，然后再 push 上去运行验证。下面为了方便采用 bat 脚本执行。 adb push ls /data/local/tmp/ls adb shell \"chmod 777 /data/local/tmp/ls\" adb shell \"cd /data/local/tmp \u0026\u0026 ./ls\" 要提及一下 Toybox，它是一个小型、高效的命令工具集，为嵌入式系统和 Android 提供了常用命令的实现。同时它也是单一的可执行文件，集成了多个常用命令，如 ls、cp、mv、mkdir 等。我们使用的 ls 就是 Toybox 的软链接，它通过识别程序调用时的名称（即 argv[0]）决定执行的具体命令。所以我尝试把 ls 更改名称为 modify-ls，一开始能用，然后后面就报错 toybox: Unknown command modify-ls 了，所以还是使用原来的名称。 ","date":"2024.11.24","objectID":"/blog/posts/android/elf/:1:0","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"elf_header\relf_header\r上图就是 elf_header 的结构，它包含数个结构信息。下面主要展示真正起作用的部分和相关知识点，其余没有用处的部分一笔带过，这里有没有用处的评价标准是相对于在 Linux 中正常运行而言的，不影响运行就是没有作用的。 ","date":"2024.11.24","objectID":"/blog/posts/android/elf/:2:0","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"结构分析\re_ident\relf_header 下面有一个子结构体 e_ident，它里面其实只有第一个 file_identification 是有用的，并且是固定的，为 .ELF。 file_identification\r其余的属性，例如 ei_class_2_e，它是用来描述 elf 的位数的，32位和64位。但是实际上 linker 加载该 elf 文件的时候，根本不会在意这个值。如果把这个结构中除了 file_identification 全部更改为 EE（FF为 -1，可能存在作用），程序依然可以正常运行。 e_type\r这个的值虽然是一个枚举，但是是实际上无论是 exe 还是 so，它们的值都必须是 ET_DYN (3) ，如果是一个 exe 文件，将这个值改成 ET_EXEC (2)，它反而不能运行。 e_machine\r这个字段说明 CPU 平台，比如 x86，arm32，arm64 等。如果这个地方给错了，不能正常运行。 e_entry_START_ADDRESS\r这个是 elf 加载到内存时执行的初始地址，也就是程序加载后，加载器将控制权转移到的第一条指令地址，通常是 _start 函数的地址，之后这个函数会调用 libc 的启动函数 __libc_start_main，而 __libc_start_main 就会调用用户定义的 main 函数。这里它是一个虚拟地址，表示的相对偏移，真实的虚拟地址 = 加载的虚拟地址的基址 + 这个相对偏移。 PROGRAM_HEADER_OFFSET\r指 e_phoff_PROGRAM_HEADER_OFFSET_IN_FILE，它是 program_header_table 段的偏移。elf_header 后面就是 program_header_table，斯普哦它一般也是 elf_header 的大小。除非有人故意在这两者之间插入一些无用的数据。 SECTION_HEADER_OFFSET\r指 e_shoff_SECTION_HEADER_OFFSET_IN_FILE，它表示 section header table 段的偏移，但是没有什么用处，实际上跟 section 有关的都没啥用，因为 elf 加载的时候根本就不使用 section 相关的东西。上面是 Android 8 之前的版本，而 Android 8 及以后还是会读取 section header的，但不是所有的 section 都会读取。但是我使用 Android 9 进行实验，SDK 为 28，我发现按照之前的修改方式进行，程序还是可以运行。这里是 Android14 的 linker 代码，可以看到它存在 ReadSectionHeaders()、ReadDynamicSection() 函数来读取相关信息。 修改 section header table\r但是 IDA 是使用 section 来进行解析的。我们将 section header 都覆盖为 EE。之后可以正常运行，但是 IDA 解析一开始会报错，之后发现解析不了段信息。实际上加载一个 so 文件的时候，IDA 的 segment view 里面就是解析的 section header。如果我们破坏了甚至是弄一个假的 .text/.data section，那么 IDA 就没有办法正常解析了。 IDA 解析\r","date":"2024.11.24","objectID":"/blog/posts/android/elf/:2:1","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"其余信息\re_ehsize_ELF_HEADER_SIZE：没有用处，加载的时候根本不检查，它是根据位数的默认大小，所以改动 elf_header 的大小会有不可预料的后果 e_phentsize_PROGRAM_HEADER_ENTRY_SIZE_IN_FILE：program_header_table 是一个数组，这个表示数组中每个元素的大小 e_phnum_NUMBER_OF_PROGRAM_HEADER_ENTRIES：这个表示上面数组中元素的个数 ","date":"2024.11.24","objectID":"/blog/posts/android/elf/:2:2","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"总结\r所以最后可以把 elf_header 修改成下面的形式，它也是可以正常运行的。下面保留的相关结构就是 file_identification、e_type、e_machine、e_entry_START_ADDRESS、e_phoff_PROGRAM_HEADER_OFFSET_IN_FILE、e_phentsize_PROGRAM_HEADER_ENTRY_SIZE_IN_FILE、e_phnum_NUMBER_OF_PROGRAM_HEADER_ENTRIES。 修改后ELF\r","date":"2024.11.24","objectID":"/blog/posts/android/elf/:2:3","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"program_header_table\r这是一个数组，拥有数个元素结构体 program_table_element，元素个数和元素大小都在 elf_header 中展示出来了。这里是对单个元素结构进行分析，它每一个元素结构描述的都是内存和文件的对应关系。 program_header_table\r","date":"2024.11.24","objectID":"/blog/posts/android/elf/:3:0","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"结构分析\rp_type\r段类型，为 1 表示可加载段，然后根据读写权限可以分成代码段和数据段。这两个可加载段最为重要，其它段就是服务这两个段而存在的。 p_flags\r段属性。表示段为可读，可写，可执行等。对于加载段很重要，区分了代码段和数据段，其它段就基本没什么意义。 FROM_FILE_BEGIN\r指 p_offset_FROM_FILE_BEGIN，它表示段在文件中的偏移，可以直接在文件中根据偏移进行查看。 VIRTUAL_ADDRESS\r指 p_vaddr_VIRTUAL_ADDRESS，它表示段的虚拟地址。它表示的是一个相对偏移，因为段被加载到的虚拟地址是不确定的，所以真实的虚拟地址 = 加载的虚拟地址的基址 + 这个相对偏移 PHYSICAL_ADDRESS\r指 p_paddr_PHYSICAL_ADDRESS，它表示段的物理地址。因为都运行在用户态，没有物理地址的概念，所以所有段的这个都没有用。段只有虚拟地址才有意义。 SEGMENT_FILE_LENGTH\r指 p_filesz_SEGMENT_FILE_LENGTH，表示段在文件中的长度。 SEGMENT_RAM_LENGTH\r指 p_memsz_SEGMENT_RAM_LENGTH，表示段在内存中的长度。 p_align\r段的对齐方式。ELF 中的对齐都是内存对齐，不存在文件对齐，它都是密集排列的。它没有什么作用，加载器中写定了内存对齐都是 4K。 ","date":"2024.11.24","objectID":"/blog/posts/android/elf/:3:1","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"文件内存映射\rprogram_header_table 中的每个元素，描述的其实是将段加载到内存中时，elf文件中的段映射到了内存中。 p_offset_FROM_FILE_BEGIN 与 p_filesz_SEGMENT_FILE_LENGTH 表示了文件中的段。 p_vaddr_VIRTUAL_ADDRESS 与 p_memsz_SEGMENT_RAM_LENGTH 表示了内存中的段。 这两者构成一个映射关系，linker 在加载 elf 的时候采用的是 mmap。p_filesz_SEGMENT_FILE_LENGTH 与 p_memsz_SEGMENT_RAM_LENGTH 的大小不一定一样，因为为了节省 elf 文件大小，有些值为 0 的段，比如 .bss 就不占文件空间。但是加载到内存后，还是要分配空间的。 ","date":"2024.11.24","objectID":"/blog/posts/android/elf/:3:2","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"Program Header\r这个段里只有两块数据有用，其余都可以忽略。 Program Header\r文件偏移与虚拟地址，它们都是 0x40，而且这个值与 elf_header 必须是相等的。这个值某种意义上就是 elf_header 的大小。那为什么还需要在这里再储存一次呢？ 可以简单理解，linker 里面有一些指针指向的是 elf_header，而有些指针指向的是 program_header，互相转换的时候，会使用指针偏移来计算，偏移大小就是这里的 0x40，所以就在这里也记录了值，偏于指针计算。 p_data 就是整个 program_header_table 的内容。 p_type 不知道有没有用，没试过改这里，假定有用吧。 ","date":"2024.11.24","objectID":"/blog/posts/android/elf/:3:3","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"Interpreter Path\r这个段就是描述解析器（linker）路径的，它与上面的 Program Header 段必须要出现在可加载段前面。 Interpreter Path\r这个段需要关注的数据就是 p_data，可以发现它是一个字符串 /system/bin/linker64，那么 LENGTH 就都是指的容纳这个字符串的长度，在这里也就是最多 0x15 长度的字符串。ELF 的可加载段就是由这个路径文件来加载的，包括重定位操作等等。 我们可以根据这个路径获取系统的 linker，之后在入口点写入死循环，然后更改 ls 文件的解析器路径为我们修改的 linker 的路径。这里因为字符串的长度不能超过 0x15，同时需要以 00 字节结尾，所以更改 linker64 为 li64。 文件修改\r之后运行 ls 文件，发现卡死了，所以查看其 maps 信息。这里发现相比之前的死循环，这里少了很多东西，像是 libc 相关的东西也没有了。这是因为现在进程卡在了非常早的时机，连这个 ELF 文件自身的段的重定位都没有做，只是光将 ELF 文件中的东西放到内存里面了。 但是可以发现下图前面两行表示 ls 文件被加载了，这又是为什么？我们已经在 linker 的入口函数加了一个死循环，linker 根本不会执行加载逻辑才对。其实这是因为这两个可执行段不是由 ls 中指定的 linker 加载的，而是其他进程中的 linker 加载的，目前先简单的理解为是 init 进程干的吧（感觉需要更为细致的判断，这里的理解是猜测）。剩下的其他 ELF 依赖文件，比如 libc 等则将由路径中指定的 linker 来加载。 修改后 maps 信息\r我们可以使用 IDA 附加进程来更为细致的查看。在 Modules 中可以发现只有两个 so 被加载。 IDA Modules 信息\r之后还原 linker 的入口地址指令，让其继续执行，并且在 ls 的入口地址加上断点。按 F8 步过 linker_init 函数，发现此时 linker 加载了很多的 so。同时这里的 linker 存在一个特点，他没有 imports（导入表）。这是因为它不依赖其他 so，它也不能依赖其他 so。它运行的时候，其他 so 都没有加载。比如 open 函数，它就不能使用 libc 中的 open 函数，它必须自己实现 open 函数。所以它必须实现所有自己需要的函数。 IDA Modules 信息\r","date":"2024.11.24","objectID":"/blog/posts/android/elf/:3:4","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["android"],"content":"Android9 可加载段\r重要说明\r这里加载段和上面的内容都是对于我 Android9 的设备来看，与其它 Android 的版本存在差异。 这里最为重要的就是下面的两个可加载段了，根据其权限可以判断出，具有 R_X 属性的段为代码段，具有 RW_ 属性的段为数据段。 可加载段\r代码段\r之前根据 elf_header 的 e_entry_START_ADDRESS 值，我们可以知道代码的入口在虚拟地址 0xD760。对于程序在内存运行，段的加载就是根据它的虚拟地址和内存长度来进行排列的。这里代码段的虚拟地址为 0x0，可以判断它是排在第一个的。同时代码入口和段的真实虚拟地址都是 加载的虚拟地址的基址 + 相对偏移 得来的，它们的加载虚拟地址基址都是一样的，同时段的大小为 0x6041C，比 0xD760 大，所以代码的入口在代码段中。 代码段信息\r同时代码段的文件大小和内存大小相同，且段在文件中的偏移也是 0，所以可以判断它们为 1对1 映射。所以该入口地址在文件中也是在代码段中的（0x0 + 0xD760），我们可以直接查找 0xD760 来找到入口的代码。 修改前首地址\r之后修改为 00 00 00 14 ，它在 ARM64 中表示 b #0，是死循环代码，这样可以帮助我们查看内存中的段分布。 修改后首地址\r之后启动文件，通过 ps -a 查看进程信息，之后通过 proc/self/maps 查看内存中段信息。 内存段信息\r根据上图可以看到段在内存中的分布，这里第一个可读可执行的就是代码段，而后面三个一起就是数据段。这里代码段的起始位置 0x60a053e000 就是加载的虚拟地址的基址，因为代码段的相对偏移为 0。之后我们得到代码段的大小为 0x6041C，二者相加等于 0x60A059E41C，然后是 4K 对齐，结束地址为 0x60A059F000。同时我们用户的起始代码地址为 0x60a053e000 + 0xD760 = 0x60A054B760。在下图 IDA 的分析中，可以看到起始地址代码刚好为我们更改的结果。 IDA 中起始地址\r在 IDA 的分析中，这里的代码在名为 .text 的 segment 中，它是 IDA 根据 section 的信息分析的，在 section 中，.text的起始位置为 0xD740，刚好和这里的图片相对应。由此也可以验证 IDA 的分析是根据 section 来进行的，但是运行是根据 program 来进行的。 IDA 代码段信息\r数据段\r而后面三个一起为数据段，我们查看数据段信息，可以知道它的虚拟地址为 0x7CFC0，而基址为 0x60a053e000，二者相加为 0x60A05BAFC0。因为内存页都是 4K 对齐的，所以不能从这个地址开始给其赋予可读可写的权限，必须是给整个内存页赋予权限，所以这里就从 0x60a05ba000 开始赋予权限，但是真实的地址还是 0x60A05BAFC0。 同时数据段的大小为 0x89EE，0x60a05ba000 + 0x89EE = 0x60A05C29EE，根据 4kb 对齐就是 0x60A05C3000。这个地方应该和三部分的末尾相对应，但是我这里差了 1kb 的空间，每次都是这样，怀疑我这个系统往这个里面添加了什么数据，但是目前不知道。所以这里就当作它是刚好映射到结尾吧。 数据段信息\r这里从 IDA 的 Segments View 中可以看出，这个地址对应的 segment 就是 .preinit_array，也就是说这个数据段从这里往后进行放置。我们可以根据该段的文件偏移找到这个地方的代码，可以发现二者是相对应的。 IDA 数据段信息\r但是问题还是在这里，为什么这个数据段被分成了三部分？这是因为数据段中的一部分权限会被修改，它是被下面的 GNU Read-only After Relocation 段给修改的。这个段描述的就是，在重定位之后，将虚拟位置 0x7CFC0 且大小为 0x3040 字节的区域的权限改为只读。这里 0x7CFC0 就是数据段的起始位置，之后计算数据段的第一部分大小， 0x60a05be000 - 0x60a05ba000 = 0x4000，它刚好是 0x3040 4kb 对齐的结果，这说明第一部分就是这个段修改权限所产生的。 GNU Read-only After Relocation\r而剩余的两部分也都是数据段的内容，它们都是可读可写的，第一个后面存在文件路径，而后面那个没有。这是因为这个数据段的文件大小小于映射后的 RAM 大小，所以 RAM 超出文件的部分就没有文件映射了，也就没有文件路径了。 ","date":"2024.11.24","objectID":"/blog/posts/android/elf/:3:5","tags":["android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["compile"],"content":"这里记录符号表、语义属性相关知识。 ","date":"2024.11.21","objectID":"/blog/posts/compile/semantics-symboltable-ag/:0:0","tags":["compile"],"title":"03 Semantics SymbolTable Ag","uri":"/blog/posts/compile/semantics-symboltable-ag/"},{"categories":["compile"],"content":"Symbol Table\r符号主要指变量名、函数名、类型名、标签名。在语义分析中需要进行符号检查，即检查程序是否会出现符号乱用的情况，例如前一句将符号 symbol 定义为变量，之后又把它当作函数来进行函数调用了。而符号表就是用于保存各种符号相关信息的数据结构，它不仅在前端语法分析之后会发挥作用，还会在后端的生成中间代码的过程进行使用。下面就是一个符号表的示例。 符号表\r但是对于符号检查而言，最为困难的就是作用域了。“领域特定语言”（DSL），例如简单的键值对，它们通常只有单作用域（全局作用域），而对于我们真正要分析的“通用程序设计语言”（GPL），它通常就需要嵌套作用域了，这时就需要不同的哈希表来进行符号存储了，由此每个符号表代表了一个作用域，不同的作用域需要通过树结构来维护。 多作用域符号表\r下面就是每个作用域需要提供的接口： 作用域接口\r符号表相关的类层次结构设计如下，它是 Lab3 的一部分，表示了符号表的设计。 符号表类层次结构\r","date":"2024.11.21","objectID":"/blog/posts/compile/semantics-symboltable-ag/:1:0","tags":["compile"],"title":"03 Semantics SymbolTable Ag","uri":"/blog/posts/compile/semantics-symboltable-ag/"},{"categories":["compile"],"content":"语义分析\r这里讲述的就是属性文法，它指的就是为上下文无关文法赋予语义，分析的就是如何基于上下文无关文法做上下文相关分析。 因此得出在语法分析过程中实现属性文法，就是通过在推导过程中嵌入语义动作，例如 $B \\rightarrow X \\{ \\textcolor{red}{a} \\} Y$。语义动作嵌入的位置决定了何时执行该动作，基本思想就是一个动作在它左边的所有文法符号都处理过之后立刻执行。在 antlr4 中，使用参数的形式来表示继承属性，使用返回值来表示综合属性。 ","date":"2024.11.21","objectID":"/blog/posts/compile/semantics-symboltable-ag/:2:0","tags":["compile"],"title":"03 Semantics SymbolTable Ag","uri":"/blog/posts/compile/semantics-symboltable-ag/"},{"categories":["compile"],"content":"语法制导定义\rSDD（语法制导定义，Syntax-Directed Definition）是一个上下文无关文法的属性及规则的结合。 每个文法符号都可以关联多个属性 每个产生式都可以关联一组规则 SDD 唯一确定了语法分析树上每个非终结符节点的属性值，但它没有规定以什么方式、什么顺序计算这些属性值。顺序是根据不同的语法分析器的情况而言的，比如 antlr4 是深度优先遍历，那么它呃顺序也就是这个了。 antlr 遍历\rS 属性定义\r综合属性和 S 属性\r属性依赖关系\r由上图可以看出 S 属性的含义。本质而言，他就是父节点的信息需要依赖于子节点的传递，只有子节点首先处理完得到了结果，才能传递给父节点进行使用。 S 属性性质\rL 属性定义\r集成属性\r由上图，$T^{’}$ 有一个综合属性 syn 与一个继承属性 inh。这里继承属性 $T^{’}.inh$ 用于在表达式中从左向右传递中间计算结果。 L 属性\r上述的定义就是排除依赖右兄弟节点的情况，因为这种情况对于深度优先建立的语法分析树而言是不可能实现的。 例子\r属性文法计算后缀表达式\r后缀表示\r后缀表达 S 属性\r这里是子节点向父节点传递信息，所以使用综合属性。 数组类型文法举例\r综合信息的流向是从下向上传递信息，继承信息流向是从左向右、从上到下传递信息。所以为了把二者进行结合，那么就先通过继承属性从左向右、从上到下传递信息，再通过综合属性从下向上传递信息。 数组类型\r信息传递\r代码实现\r上图绿色为继承属性，把 int 从左往右，从上往下传递；红色为综合属性，把类型信息从下往上传递。 属性文法计算有符号二进制数\r有符号二进制数\rL 属性定义\r语法树传递信息\r","date":"2024.11.21","objectID":"/blog/posts/compile/semantics-symboltable-ag/:2:1","tags":["compile"],"title":"03 Semantics SymbolTable Ag","uri":"/blog/posts/compile/semantics-symboltable-ag/"},{"categories":["compile"],"content":"语法制导的翻译方案\rSDT\rSDD 只是一个理念，我们之后的例子都是进行 SDT 的操作，也就是真实实现。 ","date":"2024.11.21","objectID":"/blog/posts/compile/semantics-symboltable-ag/:2:2","tags":["compile"],"title":"03 Semantics SymbolTable Ag","uri":"/blog/posts/compile/semantics-symboltable-ag/"},{"categories":["config"],"content":"记录一下 IDA 的使用。 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:0:0","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"下载\r这里贴一个 IDA9.0rc1 的 来源，虽然不是从这里获取的资源，但是想来应该都差不多。之后就是使用评论区给出的 keygen2.py 文件进行 patch 和生成 License，也就是 idapro.hexlic 文件，这样就可以正常使用了。 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:1:0","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"配置\r","date":"2024.11.20","objectID":"/blog/posts/config/ida/:2:0","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"修改 python 版本\r想让 IDA 使用自己的 python，那么就需要进行相关配置，这里直接使用 idapyswitch.exe 进行切换即可，下面的命令就会更改 IDA 使用的 python 版本。我这里使用的是 miniconda 的虚拟环境，但是都是一样的，只要找到 python3.dll 就行。 .\\idapyswitch.exe --force-path E:\\xxxxx\\miniconda3\\envs\\re\\python3.dll ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:2:1","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"插件\rIDA 有很多好用的插件，但是按照之前 beta 的版本，有一些会产生冲突，所以这里记录目前可以使用或者被修改过的插件。 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:3:0","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"keypatch\r从 修改仓库 获取的，直接把 keypatch.py 放在 plugins 目录中就可以使用了。具体使用可以看链接的 README 文件 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:3:1","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"lazyida\r从 官方仓库 获取的，作者修改了错误的地方，配置方式和上面一样，具体使用也是看 README。 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:3:2","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"D810\r从 官方仓库 获取的，反正最开始的时候没有报错，当作可以正常使用 🐶。之后使用时选择适当的规则，然后点击 start，就可以按 F5 自动反编译，解决 OLLVM 混淆。如果已经存在 F5 缓存，可以将一段代码 nop 掉，之后撤销操作，再 F5 反编译即可 D810使用\r","date":"2024.11.20","objectID":"/blog/posts/config/ida/:3:3","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"findcrypt-yara\r从 官方仓库 获取之后，把 findcrypt3.py 和 findcrypt3.rules 放在 plugins 目录中。之后因为 yara-python 版本的问题，需要进行 修正，直接将下面的代码覆盖原来的即可。同时也可以给 rules 添加国密SM4算法的识别规则。 def yarasearch(self, memory, offsets, rules): print(\"\u003e\u003e\u003e start yara search\") values = list() matches = rules.match(data=memory) for match in matches: for stringR in match.strings: name = match.rule for string in stringR.instances: if name.endswith(\"_API\"): try: name = name + \"_\" + idc.GetString(self.toVirtualAddress(string.offset, offsets)) except: pass value = [ self.toVirtualAddress(string.offset, offsets), match.namespace, name + \"_\" + hex(self.toVirtualAddress(string.offset, offsets)).lstrip(\"0x\").rstrip(\"L\").upper(), stringR.identifier, repr(string.matched_data) ] idaapi.set_name(value[0], name + \"_\" + hex(self.toVirtualAddress(string.offset, offsets)).lstrip(\"0x\").rstrip(\"L\").upper() , 0) values.append(value) print(\"\u003c\u003c\u003c end yara search\") return values ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:3:4","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"ipyida\r可以在 IDA 中配置 ipython 来执行 python 代码。直接从 官方仓库 执行命令下载即可。然后使用 Shift + . 就可以打开进行使用了，注意 exit 的使用，它会直接退出 IDA，然后分析文件会遗留，但是是分散的格式。 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:3:5","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"bindiff\r直接去 官网 下载 bindiff，我这里下载的是 bindiff 8。然后在它的 Plugins 目录下存在 IDA 的插件，我这里是找到 IDA-9.0-rc1 的 适配 版本，直接放到 IDA 的 plugins 目录下，然后点击 File 就可以看到 bindiff 并使用了。 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:3:6","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"使用\r可以查看别人的 博客1、博客2、博客3 来学习具体的使用方法和小技巧。 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:4:0","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"日常使用\r这里补一下 IDA 官方快捷方式，这个更为全面。 主要操作\rctrl + e：找到main函数 Shift + f12：可以打开 string 窗口，一键找出所有的字符串，右击 setup，对窗口的属性进行设置。同时附加时使用可以显示 strings Shift + f7：可以查看 Segments 窗口。查看不同的段 空格：在 Text View 和 Group View 中来回切换 f5/Tab：一键反汇编，Tab 可以在汇编界面与伪代码界面来回切换 Ctrl + X：交叉引用 Alt + T：在汇编界面中搜索汇编语言 Shift + E：提取数据 Ctrl + Shift + W：保存快照，它会生成一个新的 ida 数据库文件，本质为另存为 插件操作\rCtrl + Alt + K：(Keypatch快捷键) 进行patch Shift + .：打开 ipyida 插件 类型更改\rD 转换为原始数据 C 转换为汇编代码 P 重新生成函数 a 将数据转换为字符串，主要可以应对小端序存储 N 更改变量的名称 Y 更改变量的类型，比如把 _int64 更正为 BYTE*（或者 char *） U undefine，取消定义函数、代码、数据的定义，转化为原始字节的形式 V 简化函数的格式，有时候函数没有 return 时可以使用，查看更方便 M 枚举所有相同的数据 ; 在反汇编后的界面中写下注释 / 在反编译后伪代码的界面中写下注释 \\ 在反编译后伪代码的界面中隐藏/显示变量和函数的类型描述 有时候变量特别多的时候隐藏掉类型描述看起来会轻松很多 右键点击 Hide casts 也可以隐藏类似 *(DWORD) 的类型描述 动态调试\r快捷键\rF2 增加断点 F7 单步步入，遇到函数，将进入函数代码内部 F8 单步步过，执行下一条指令，不进入函数代码内部 F4 运行到光标处（断点处） F9 继续运行 Ctrl + F2 终止一个正在运行的调试进程，重新开始调试 Ctrl + F7 自动步入，在所有的函数调用中一条一条地执行命令，断点或异常时，自动停止 Ctrl + F8 自动步过，一条一条的执行命令，程序到达断点，或者发生异常时，自动步过过程都会停止 附加\r应对一些强壳，可以先启动 .exe 程序，之后使用IDA的附加功能 (Debugger-\u003eattach)，附加进程，可以越过壳。之后可以使用 Shift + f12 和 Shift + f7 定位关键字符位置和段属性，将该程序的 Code 段使用 IDAPYTHON 转化为反汇编形式进行动调。 from ida_ua import * cur_addr = 0x401000 #起始地址 end_addr = 0x410000 #终止地址 def make_insn(start,end): adr = start out_ins = insn_t() while True: if(adr \u003e= end): break create_insn(adr) size = decode_insn(out_ins,adr) adr += size print(\"end!\") make_insn(cur_addr,end_addr) print(\"Done\") 可能 Code 段很大，编译很慢，可以结合手动按c反汇编结合查看 ELF 文件\r以下就是注意事项，具体流程直接上网查找即可。 Linux开启远程连接服务，在虚拟机中打开 IDA 在 Linux 中的调试工具 首先需要将文件提权，否则不能运行，也就不能调试了 IDA连接虚拟机，开始动调 Linux进行附加时，需要先打开 linux_server 服务，然后另起端口打开运行的程序，之后就可以附加了。这里需要先使用 sudo vim /etc/sysctl.d/10-ptrace.conf 更改最后一行 kernel.yama.ptrace_scope = 0，重启系统后，普通用户就可以使用 attach ID 连接程序调试了。 注意 wsl 的 Hosrname 可以设置为 127.0.0.1，有时候设置成 wsl 的 ip 不太起效果 为了方便 IDA 中的 application，可以使用 realpath ./file 直接获取文件的路径 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:4:1","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"idapython\ridapython 可以对相关数据进行操作，学习可以参照下面的文章。 IDA Python 使用总结 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:4:2","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["config"],"content":"相关技巧\r从IDA中获取数据时，如果在分析程序中发现数据的排列为 qword 等，建议不要以小端序转化，而是直接从 IDA 的 IDA View-RIP 界面复制，不用 Ctrl + e 提取数据。除此之外， qword 的转化可能会出现一些多余数据，记得识别 这里补充一点：若是在 IDA View-RIP 界面中的数据不是正规数据（这里指十六进制），则采用 Ctrl + e 进行十六进制提取，再分别以4个字节为一组，然后倒转称为小端序的顺序进行解密操作 总而言之 可以首先使用 Ctrl + e 进行提取，然后手动进行倒转转换 也可以使用 D 进行打乱，再分别使用 D 聚合成每4个字节为一组的形式 也可以使用插件 lazyida，在数据上 右键 -\u003e convert -\u003e Covern to …… DWORD list（这里注意看前面的标识进行相依字节长度的转化）就可以在下方output框看见正确的小端序数组 Patch 函数的时候，可以直接使用汇编。然后另存为文件即可跳过函数 mov eax,0x1 retn x ;这里的 x 需要根据函数末尾的返回来抄写，防止栈不平衡 遇到 (_BYTE *)\u0026qword_4058 之类的，若是知道这是表示的数组，那么可以再汇编界面按 D 变成数据，之后 F5 重新生成伪代码，则可以看到数组变成 byte_4058[] 之类的数组形式 若是函数格式中有 (_BYTE) 等干扰分析时，可以： 使用 Y 更改变量的类型，比如把 _int64 更正为 BYTE*或者 (char *) 使用 V 简化函数的格式，有时候函数没有 return 时可以使用，这样看更方便 IDA在识别花指令时，很可能在一个连续的函数中显示红色的 sub_3D9 endp ; sp-analysis failed 类似的信息，这个时候可以使用 Edit -\u003e Function -\u003e Delete function 删除函数定义，然后在正确的位置 retn 使用 Edit -\u003e Function -\u003e Set function end 设置函数结尾。之后 F5 反编译可以看到正常的函数 有时候 U + P 不能生成函数，可以先删除函数定义，选中函数块之后按 P 定义函数 ","date":"2024.11.20","objectID":"/blog/posts/config/ida/:4:3","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["compile"],"content":"这里记录上下文无关文法、LL、LR 算法相关知识。 ","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:0:0","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"CFG\r","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:1:0","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"语法\rDefinition(Context-Free Grammar, 上下文无关文法)，上下文无关文法 G 是一个四元组 G = (T, N, S, P)： T 是 终结符号（Terminal）集合，对应于词法分析器产生的词法单元 N 是 非终结符号（Non-terminal）集合 S 是 开始（Start）符号（$S \\in N $且唯一） P 是 产生式（Production）集合 $$ A \\in N \\rightarrow \\alpha \\in (T \\cup N)^* $$ 头部/左部（Head）A：单个非终结符 体部/右部（Body）$\\alpha$：终结符与非终结符构成的串，也可以是空串$\\epsilon$ ","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:1:1","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"语义\r上下文无关文法 G 定义了一个语言 L(G)。语言是串的集合，从文法得到串的过程就是推导（Derivation）。推导就是将某个产生式的左边替换成它的右边，每一步推导需要选择替换哪个非终结符号，以及使用哪个产生式。对于下面的推导式而言，E 就是非终结符，id 就是终结符，目的就是从左边推到为右边，得到只包含终结符的式子。 $$ E \\rightarrow E + E \\mid E * E \\mid (E) \\mid -E \\mid \\text{id} $$ 对于推导也存在区分，如果一直选择最左边的非终结符进行推导，就称为 Leftmost Derivation，如下所示： $$ E \\implies -E \\implies -(E) \\implies -(E + E) \\implies \\pmb{-(\\text{id} + E)} \\implies -(\\text{id} + \\text{id}) $$ 如果一直选择最右边的非终结符进行推导，就称为 Rightmost Derivation，如下所示 $$ E \\implies -E \\implies -(E) \\implies -(E + E) \\implies \\pmb{-(E + \\text{id})} \\implies -(\\text{id} + \\text{id}) $$ 由上述推导规则可以得到相关简单表示： $$ \\begin{align} E \u0026\\implies -E \\text{ : 经过一步推导得出} \\\\ E \u0026\\xRightarrow{\\text{+}} -(\\text{id} + E) \\text{ : 经过一步或多步推导得出} \\\\ E \u0026\\xRightarrow{\\text{*}} -(\\text{id} + E) \\text{ : 经过零步或多步推导得出} \\end{align} $$ 在推导的过程中，除了最左边的 program 和最后边的 文法写的程序，中间产物都被称为句型（Sentential Form），即 如果 $S \\xRightarrow{*} \\alpha$，且 $\\alpha \\in (T \\cup N)^*$，则称 $\\alpha$ 是文法 G 的一个句型。而最右边的结果被称为句子（Sentence），即 如果 $S \\xRightarrow{*} w$，且 $w \\in T^*$，则称 $w$ 是文法 G 的一个句子。 那么此时就可以定义文法 G 生成的语言 L(G) 了，即 文法 G 的语言 L(G) 是它能推导出的所有句子构成的集合 $L(G) = { w \\mid S \\xRightarrow{*} w }$。 ","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:1:2","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"LL(1) 语法分析算法\r自顶向下的、递归下降的、基于预测分析表的、适用于 LL(1) 文法的 LL(1) 语法分析器。 ","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:2:0","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"自顶向下\r这里指语法分析树从上往下进行构建，根节点是文法的起始符号 S，叶节点是词法单元流 w$，仅包含终结符号与特殊的文件结束符 $(EOF)，中间节点表示对某个非终结符应用某个产生式进行推导。那么这里的问题就是选择哪个非终结符，以及选择哪个产生式。这里对于 LL(1) 而言，第一个 L 就是表示从左向右读入词法单元；第二个 L 表示在推导的每一步，LL(1) 总是选择最左边的非终结符进行展开。即构建最左推导；1 表示只需向前看一个输入符号便可确定使用哪条产生式。 ","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:2:1","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"递归下降\r这里指实现方式，就是为每个非终结符写一个递归函数，内部按需调用其它非终结符对应的递归函数，下降一层。 递归下降的典型实现框架\r递归下降过程\r","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:2:2","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"基于预测分析表\r设计预测分析表就是源于上述递归下降过程的一个问题，在上图展开非终结符 S 的过程中，为什么前两次玄策了 $S \\implies (S + F)$，而第三次选择了 $S \\implies F$？这里就是因为它们面对的当前词法单元不同。由此根据不同的词法单元，形成了一张预测分析表，之后就可以使用预测分析表来确定产生式。 预测分析表\r这里指明了每个非终结符在面对不同的词法单元或文件结束符时，该选择哪个产生式（按编号进行索引）或者报错（空单元格）。下面就是递归下降、基于预测分析表的实现方法，这里根据预测分析表，从左往右逐个字符进行匹配。 实现方法\r那么如何得到这个预测分析表呢，就需要先知道两个概念。 FIRST 集合\r$FIRST(\\alpha)$ 是可从 $\\alpha$ 推导得到的句型的首终结符号的集合。即对于任意的（产生式的右部）$\\alpha \\in (N \\cup T)^*$： $$ \\text{FIRST}(\\alpha) = \\{ t \\in T \\cup \\{ \\epsilon \\} \\mid \\alpha \\overset{*}{\\Rightarrow} \\textcolor{red}{t} \\beta \\lor \\alpha \\overset{*}{\\Rightarrow} \\epsilon \\} $$ 因此对于这个集合而言，考虑非终结符 $A$ 的所有产生式 $A \\rightarrow \\alpha_1, \\quad A \\rightarrow \\alpha_2, \\quad \\ldots, \\quad A \\rightarrow \\alpha_m$，如果它们对应的 $FIRST(\\alpha)$ 集合互不相交，则只需查看当前输入词法单元，即可确定选择哪个产生式（或报错）。 符号 X 的 FIRST 集合计算\r符号串 $X\\beta$ 的 FIRST 集合计算\r具体可以看下面的例子： 后面跟的为终结符 ... A-\u003eaB|ε A-\u003ec ... First(A) = {a，ε，c} 后面跟的为非终结符 # 情况一 ... A-\u003eBa B-\u003eb ... First(A) = {b} # 情况二 ... A-\u003eBc B-\u003eb|ε ... First(A) = {b, c} # 情况三 ... A-\u003eBC B-\u003eb|ε C-\u003ec|ε ... First(A) = {b, c, ε} FOLLOW 集合\r$FOLLOW(A)$ 是可能在某些句型中紧跟在 $A$ 右边的终结符的集合。即对于任意的（产生式的左部）非终结符$A \\in N$： $$ \\text{FOLLOW}(A) = \\{ t \\in T \\cup \\{ \\text{\\$} \\} \\mid \\exists s.\\ S \\overset{*}{\\Rightarrow} s \\triangleq \\beta A \\textcolor{red}{t} \\gamma \\} $$ 这里的 $\\$$ 就是文法开始符，只在第一个字符的 $FOLLOW$ 集合中进行添加。考虑产生式 $A \\rightarrow \\alpha$，如果从 $\\alpha$ 可能推导出空串（$\\textcolor{red}{\\alpha \\overset{*}{\\Rightarrow} \\epsilon}$），则只有当当前词法单元 $t \\in FOLLOW(A)$，才可以选择该产生式。 符号 X 的 FOLLOW 集合计算\r符号串 $X\\beta$ 的 FOLLOW 集合计算\r构建预测分析表\r根据上述对于 FIRST集合 和 FOLLOW集合 的描述，可以计算给定文法 G 的预测分析表：对应每条产生式 $A \\rightarrow \\alpha$ 与终结符 $\\textcolor{blue}{t}$，如果 $$ t \\in \\text{FIRST}(\\alpha) \\\\ \\alpha^* \\Rightarrow \\epsilon \\land t \\in \\text{FOLLOW}(A) $$ 则在表格 $[\\textcolor{red}{A}, \\textcolor{blue}{t}]$ 中填入 $A \\rightarrow \\alpha$（编号）。 综合例子\r对于下面的例子，可以得到它们的 FIRST 和 FOLLOW 集合。 $$ X \\rightarrow Y \\\\ X \\rightarrow \\alpha \\\\ Y \\rightarrow \\epsilon \\\\ Y \\rightarrow c \\\\ Z \\rightarrow d \\\\ Z \\rightarrow XYZ $$ FIRST集合 FOLLOW集合 $FIRST(X) = \\{a, c, \\epsilon \\}$ $FIRST(Y) = \\{c, \\epsilon \\}$ $FOLLOW(X) = \\{a, c, d, \\$ \\}$ $FITST(Z) = \\{a, c, d \\}$ $FOLLOW(Y) = \\{a, c, d, \\$ \\}$ $FITST(XYZ) = \\{a, c, d \\}$ $FOLLOW(Z) = \\empty$ $FITST(YZ) = \\{a, c, d \\}$ 关于 FIRST 和 FOLLOW 的更多讲解和例子可以看 这篇文章。之后根据上面信息，可以构建相应的预测分析表。也可以看 这个视频 来学习两个集合的构造方法。 预测分析表\r","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:2:3","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"适用于 LL(1) 文法\r这里主要说明它的局限性。对于上面预测分析表的构建，需要定义 LL(1) 文法，即如果文法 G 的预测分析表是无冲突的，则 G 是 LL(1)文法。无冲突就是每个单元格里只有一个产生式（编号）即仅根据当前 token 即可递推 production。那么根据这个无冲突的预测分析表，对于当前选择的非终结符，仅根据输入中当前的词法单元（LL(1)）即可确定需要使用哪条产生式。这里根据 LL(1) 文法的定义就可以看到其局限性，它需要的就是预测分析表是无冲突的，其他情况就不适用这个文法了。 ","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:2:4","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"Adaptive LL(*) 语法分析算法\r看 视频 和 论文 理解吧。 记录一下别人的 博客1，博客2。第二篇是视频的笔记，虽然它只是截图保存🐶。 ","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:3:0","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"LR(0) 语法分析算法\r相关文法\r对于 LL(k) 而言，它的缺陷就是在仅看到右部的前 k 个词法单元时就必须预测要使用哪条产生式。那么相对应的，LR(k) 的优势就是看到某个产生式的整个右部对应的词法单元之后再做决定。 那么 LR 语法分析器的特点就是自底向上、不断归约、基于句柄识别自动机，适用于 LR 文法。 ","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:4:0","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"语法分析树\r这里的语法分析树是自底向上进行构建的，根节点是文法的起始符号 S；每个中间非终结符节点表示使用它的某条产生式进行归约；叶节点是词法单元流 $w$$，它仅包含终结符号与特殊的文本结束符 $$$。 ","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:4:1","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"推导与归约\r下图就是推导与归约的示例，我们首先进行自顶向下的最右推导，之后直接沿着反方向进行归约。因此这里的 LR 语法分析器中的 L 就是从左向右扫描输入；R 就是构建反向最右推导。 推导与归约1\r推导与归约2\r由上图可以看出，这里的最右推导就是指对于一个产生式，最先解析右侧的的非终结符，使其转化为终结符，然后再解析左侧的非终结符。因此反方向的归约从左到右进行识别，如果识别到产生式完整的右部，那么就转化为产生式的左部，这样持续进行，最终把终结符推导为最后的 E。 这里之所以采用最右推导是为了效率，若是最左推导，那么归约就是从右往左了。这样构造的话，非终结符必须全部输入完成才会进行解析，因为这里是从后往前。而采用最右推导，那么归约就是从前往后了，这样在读入输入的时候就可以进行归约构建，增强效率。 归约过程\r归约如下图所示。上边缘就是需要进行归约的部分，剩余的输入就是还没有读入的部分，这里就是一遍读入一遍进行归约。 归约概念\r下面就是归约的过程，通过栈结构将左侧的子树进行压栈，如果栈的栈顶部分满足产生式，可以推导出左半部分，那么就移除右半部分，将左半部分压栈。否则从左往右读入输入进行压栈。 归约过程\r那么现在的问题就是对于这个栈结构，什么时候进行归约，又是按哪条产生式进行归约？例如上面：为什么第二个 F 以 T * F 整体被归约为 T？那么回答就是，这与栈的当前状态 “T * F” 相关。 LR 分析表\r分析表解析\r这里需要注意，对于归约和 GOTO 语句而言，若是进行了归约，那么就存在着出栈的操作，此时对于 GOTO 语句的状态就不是当前的状态，而是上一次的状态，因为出栈引起了状态的变化。 移入与归约\rLR 分析表的构建\r这里展示了 LR(0) 句柄识别有穷状态自动机，我们之后要做的就是解释这个状态集怎么转化为分析表的。 句柄识别有穷状态自动机\r状态\r首先我们需要知道状态是什么，对于这个分析表，状态是语法分析树的上边缘，存储在栈中。由此我们可以的到下面的结论。 状态定义\r项集和项集族\r点的含义\r由上图，· 表示我们当前看的位置。一开始，栈为空，期望输入是 E 可以展开得到的一个句子并以 $ 结束。输入以 E 开始，意味着它可能以 E 的任何一个右部开始。 句柄\r根据下图我们可以知道句柄的概念，之后就需要知道句柄可能在哪里出现，有之前的操作我们可以看出，句柄在栈顶位置，所以这里就需要我们设计出一种满足“句柄总是出现在栈顶”性质的 LR 语法分析器。 句柄概念\r增广文法\r这里我们需要进行的就是添加一个文法帮助我们进行转换。 增广文法\r状态机转换\r由一开始的自动机就可以看出，这里通过 · 点的移动来进行状态的转换，根据产生式的内容进行转移。 $$ J = \\text{GOTO}(I, X) = \\text{CLOSURE}(\\{[A \\to \\alpha X \\cdot \\beta ] \\mid [A \\to \\alpha \\cdot X \\beta] \\}) $$ 接受状态： $$ F = \\{ I \\in C \\mid \\exists [A \\to \\alpha \\cdot] \\in I \\} $$ 此时，产生式 $ A \\ to \\alpha$ 的完整右部出现在栈顶 状态转移\r构建分析表\r分析表构造规则\r分析表构造规则\r分析表构造规则\r分析表构造规则\r","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:4:2","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"文法定义\r文法定义\r这里的无冲突，就是指每一个空位上只有一个规则，而上图可见是冲突的，它不是 LR(0) 文法。这里的 0 指的就是归约时无需向前看，· 移动到什么地方就进行归约判断。 自动机与栈\r","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:4:3","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["compile"],"content":"其余\r余下的 LSR(1)、LR(1)、LALR(1) 算法都是面对移入归约冲突、归越归约冲突的不同改进。具体可以看课程。 ","date":"2024.11.14","objectID":"/blog/posts/compile/parser-cfg-ll-lr/:4:4","tags":["compile"],"title":"02 Parser Cfg LL LR","uri":"/blog/posts/compile/parser-cfg-ll-lr/"},{"categories":["AI"],"content":"这里记录在学习人工智能，主要是大语言模型时的相关知识点，用以梳理逻辑。 ","date":"2024.11.12","objectID":"/blog/posts/ai/ai_knowledge/:0:0","tags":["AI"],"title":"AI Knowledge","uri":"/blog/posts/ai/ai_knowledge/"},{"categories":["AI"],"content":"人工智能相关\r","date":"2024.11.12","objectID":"/blog/posts/ai/ai_knowledge/:1:0","tags":["AI"],"title":"AI Knowledge","uri":"/blog/posts/ai/ai_knowledge/"},{"categories":["AI"],"content":"基础概念\r简单而言，人工智能是一个很宽泛的概念，只是一个广义上的称呼，这里主要还是区分机器学习、神经网络、深度学习的相关概念。 机器学习：这是人工智能的基础，通过提供大量样本数据来建立模型，以识别和预测新的事物。例如，通过输入一张图片并经过一系列的运算后，模型可以判断这张图片属于哪一类。机器学习的核心目的是从数据中发现模式和规律，并通过构建一个模型来处理数据，实现预测和决策。通过训练数学模型，机器学习能够根据已知的数据和结果的映射关系，在遇到新数据时准确预测输出结果。 神经网络：神经网络模仿动物大脑的结构和功能，本质上是用数学公式来构建模型。它是机器学习的一个分支。机器学习本身依赖数学公式进行计算，而神经网络的特别之处在于拥有大量“神经元”，即隐藏层。可以简单地理解为，机器学习是基于数学公式建模的总体概念，而神经网络和其他方法（如k-means聚类）则是不同的具体实现形式，主要差异体现在算法，即数学公式的不同。如下图，机器学习的每个类别对应一种算法。具体细节可参考这个视频，虽然标题涉及机器学习，但讲解的重点主要是神经网络的原理和概念。同时也可以观看这个视频，讲解更为细致全面。 深度学习：这是人工神经网络的一个特例，其复杂性远超一般神经网络。深度学习通过增加神经网络的隐藏层数量来实现更高难度的任务。与一般神经网络相比，深度学习网络结构更为深层和复杂。其他类型的神经网络是在不同方面进行了改进，因此产生了不同的类别，但它们都包含隐藏层这一特征。 关系图\r更为详细的解释可以看这篇文章，讲述了更为细节的内容。 ","date":"2024.11.12","objectID":"/blog/posts/ai/ai_knowledge/:1:1","tags":["AI"],"title":"AI Knowledge","uri":"/blog/posts/ai/ai_knowledge/"},{"categories":["AI"],"content":"大语言模型\r","date":"2024.11.12","objectID":"/blog/posts/ai/ai_knowledge/:2:0","tags":["AI"],"title":"AI Knowledge","uri":"/blog/posts/ai/ai_knowledge/"},{"categories":["AI"],"content":"自然语言处理阶段\r第一阶段：统计模型 + 数据（特征工程） 决策树、SVM、HMM、CRF、TF-IDF、BOW 第二阶段：神经网路 + 数据 Linear、CNN、RNN、GRU、LSTM、Transformer、Word2vec、Glove 第三阶段：神经网络 + 预训练模型 + （少量）数据 GPT、BERT、ROBERTa、ALBERT、BART、T5 第四阶段：神经网络 + 更大的预训练模型 + Prompt ChatGPT、Bloom、LLaMA、Alpaca、Vicuna、MOSS、文心一言、通义千问、星火 ","date":"2024.11.12","objectID":"/blog/posts/ai/ai_knowledge/:2:1","tags":["AI"],"title":"AI Knowledge","uri":"/blog/posts/ai/ai_knowledge/"},{"categories":["AI"],"content":"Transformer\r使用 GPT 进行举例，它的全称为 Generative Pre-trained Transformer。显而易见，Transformer 就是它技术的关键所在，这里可以通过这篇文章详细了解它们之间的联系，以及 Transformer 的核心 Self-Attention。然后这个视频更为细致的讲解其底层知识。 ","date":"2024.11.12","objectID":"/blog/posts/ai/ai_knowledge/:2:2","tags":["AI"],"title":"AI Knowledge","uri":"/blog/posts/ai/ai_knowledge/"},{"categories":["android"],"content":"RiskGuard app 的总览，介绍该项目的相关信息。 ","date":"2024.11.9","objectID":"/blog/posts/android/riskguard/:0:0","tags":["android"],"title":"RiskGuard","uri":"/blog/posts/android/riskguard/"},{"categories":["android"],"content":"UI 设计\r跟随 Project Manager 进行 UI 设计，采用 kotilin 进行了实现，延续该项目的配色风格，在此基础上添加自己的模块。这里补充一下状态栏的设计，在 res/values/themes.xml 中删除 style 标签下所有内容，转化为下面的内容，那么状态栏就会透明的，图标和文字为深色，这样 UI 会更适配。 配置状态栏\r","date":"2024.11.9","objectID":"/blog/posts/android/riskguard/:1:0","tags":["android"],"title":"RiskGuard","uri":"/blog/posts/android/riskguard/"},{"categories":["android"],"content":"展开二级列表\r一开始是想的实现珍惜大佬 hunter 的 UI 设计，所以一直寻找可折叠的 textview 项目，但是发现都不尽如人意。直到找到了 ExpandableRecyclerView 这个项目，所以就使用这个进行二级列表的设置。也因此改为 kotilin 作为 UI 界面的语言，这样便于直接进行代码移植。之后把之前的设备信息获取代码移植后，配置了列表的折叠和展开后，也添加了一个全部展开/折叠功能。 ","date":"2024.11.9","objectID":"/blog/posts/android/riskguard/:2:0","tags":["android"],"title":"RiskGuard","uri":"/blog/posts/android/riskguard/"},{"categories":["programming"],"content":"学习 C++ 的使用，主要区分 C++ 和 C 的区别。 ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:0:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"C++ 历史速览\r这里通过求和的案例来记录 C、C++98、C++11、C++17 的变化。 古代 C 语言，采用 malloc 和 free 来管理内存，同时数据需要自己进行定义，并通过 for 循环实现求和操作。同时打印采用 printf，需要声明打印数据的类型才可以正确打印。 #include \u003cstdlib.h\u003e #include \u003cstdio.h\u003e int main() { size_t nv = 4; int *v = (int *)malloc(nv * sizeof(int)); v[0] = 4; v[1] = 3; v[2] = 2; v[3] = 1; int sum = 0; for (size_t i = 0; i \u003c nv; i++) { sum += v[i]; } printf(\"%d\\n\", sum); free(v); return 0; } 近代 C++98 引入 STL 容器库，这样就不需要自己进行内存的释放了，离开了当前作用域会自己进行销毁。这里的创建和销毁实质上就是 STL 容器的构造函数和析构函数。同时引入了重载的 cout 函数，因此不需要指定变量类型，可以直接进行打印， #include \u003cvector\u003e #include \u003ciostream\u003e int main() { std::vector\u003cint\u003e v(4); v[0] = 4; v[1] = 3; v[2] = 2; v[3] = 1; int sum = 0; for (size_t i = 0; i \u003c v.size(); i++) { sum += v[i]; } std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } 近现代 C++11 引入了 {} 初始化表达式和 range-based for-loop 机制。这样可以通过花括号来进行赋值，并且支持通过迭代器来进行遍历，应用函数。 #include \u003cvector\u003e #include \u003ciostream\u003e #include \u003calgorithm\u003e int sum = 0; void func(int vi) { sum += vi; } int main() { std::vector\u003cint\u003e v = {4, 3, 2, 1}; // 在 \u003calgorithm\u003e 中进行实现 std::for_each(v.begin(), v.end(), func); std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } 同时近现代 C++11 还引入了 lambda 表达式。如下可以看出不需要定义全局变量 sum 了，可以对局部变量进行相关操作。 #include \u003cvector\u003e #include \u003ciostream\u003e #include \u003calgorithm\u003e int main() { std::vector\u003cint\u003e v = {4, 3, 2, 1}; int sum = 0; std::for_each(v.begin(), v.end(), [\u0026] (int vi) { sum += vi; }); std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } 现代 C++14 支持 lambda 用 auto 自动推断类型。 #include \u003cvector\u003e #include \u003ciostream\u003e #include \u003calgorithm\u003e int main() { std::vector\u003cint\u003e v = {4, 3, 2, 1}; int sum = 0; std::for_each(v.begin(), v.end(), [\u0026] (auto vi) { sum += vi; }); std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } 当代 C++17 拥有 CTAD（compile-time argument deduction），可以进行编译期参数推断，但是需要在 CMAKE 中添加 set(CMAKE_CXX_STANDARD 17)。同时还引入常用数值算法。 #include \u003cvector\u003e #include \u003ciostream\u003e #include \u003calgorithm\u003e int main() { std::vector v = {4, 3, 2, 1}; int sum = 0; std::for_each(v.begin(), v.end(), [\u0026] (auto vi) { sum += vi; }); std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } #include \u003cvector\u003e #include \u003ciostream\u003e #include \u003cnumeric\u003e int main() { std::vector v = { 4, 3, 2, 1 }; // 下面三者效果等同 //int sum = std::reduce(v.begin(), v.end(), 0, [](int x, int y) { // return x + y; //}); // 下面两种就是引入常用数值算法，主要实现在 \u003cnumeric\u003e 头文件中 //int sum = std::reduce(v.begin(), v.end()); int sum = std::reduce(v.begin(), v.end(), 0, std::plus{}); std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:1:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"头文件\rC++ 包含标准 C 语言头文件，对于原本 C 的头文件，C++ 有两种方式进行引用，一种是原有的方式（后面跟 .h），一种就是去掉 .h，在库前面添加一个 c 标识这是原本 C 的头文件。对于自己写的头文件还是原方式进行引用，即 \"\"。 #include \u003ciostream\u003e // 基本输入输出 #include \u003ccstdio\u003e // 在原来 C 语言的库前面加一个 c，去掉 .h #include \u003cstdio.h\u003e // 采用原有方式进行引用 #include \"myFile.h\" // 自己的文件，采用原有方式引用 ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:2:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"命名空间\r","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:3:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"基础知识\r命名空间增加了标识符的使用率，减少因为命名产生的冲突。对于命名空间而言，其中的变量和函数等都是属于自己这个空间的，需要通过标识空间名来指明数据的归属，这样可以使得不同命名空间可以存在同样名称的数据，它们之间不会产生冲突。 声明命名空间：namespace 空间名{}，命名空间的声明不能写在函数中 访问数据：空间名::空间中的成员名 省略前缀的方式：using namespace 空间名，表示从这个地方开始，后面都可以省略前缀。 #include \u003ciostream\u003e using namespace std; // 标准命名空间 namespace A{ int num = 1; void print(){ printf(\"A\\n\"); } } namespace B{ int num = 2; void print(){ printf(\"A\\n\"); } } namespace C{ namespace D{ int cd_num = 3; } } int g_num = 1001; int main(){ // 使用省略前缀的方式，可以直接使用其中的函数 cout \u003c\u003c \"命名空间\" \u003c\u003c endl; std::cout\u003c\u003c \"命名空间\" \u003c\u003c endl; // 不同命名空间访问数据 A::num = 2; B::print(); // 省略前缀方式访问数据 using namespace A; num = 3; // A 命名空间数据 using namespace B; B::num = 4; // B 命名空间数据，省略前缀需要注意二义性的问题，所以还需要标识命名空间 // 嵌套命名空间 C::D::cd_num = 5; using namespace C::D; cd_num = 5; // :: 为作用域分辨符，同时可以用于指明全局变量 int g_num = 11; printf(\"num %d\\n\", g_num); // 变量访问采用就近原则，这里就是访问上面的局部变量，返回 11 printf(\"num %d\\n\", ::g_num); // 使用作用域分辨符，指明访问全局变量，返回 1001 return 0; } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:3:1","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"内联命名空间\r对于嵌套命名空间，访问需要使用多层空间名，但是可以采用内联命名空间的方式直接进行访问。 #include \u003ciostream\u003e using namespace std; namespace Version{ inline namespace v2017{ void showVersion(){ cout \u003c\u003c \"v2017\" \u003c\u003c endl; } } namespace v2020{ void showVersion(){ cout \u003c\u003c \"v2020\" \u003c\u003c endl; } } } int main(){ // 上面采用内联命名空间，即添加了 inline，设置了默认的情况，使得下面的两个语句效果等价。 // Version::v2017::showVersion(); Version::showVersion(); } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:3:2","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"动态内存分配\rC 的动态内存采用函数 malloc calloc realloc free，具体可以从 堆基础 获取详细介绍。而 C++ 使用 new delete 操作符进行动态内存分配。但是当前这种分配方式还是容易产生一系列问题，所以引入了 RAII（Resource Acquisition Is Initialization）的思想，它认为资源获取就是初始化，反之，资源释放就是销毁，具体可以看下面 RAII 与智能指针 的部分，那么之后面对这样的情况，就应该使用智能指针，不再使用 new delete。 #include \u003ciostream\u003e using namespace std; void showArr(int* arr, int len){ for (int i = 0; i \u003c len; i ++){ cout \u003c\u003c arr[i] \u003c\u003c \" \"; } cout \u003c\u003c endl; } int main(){ // C 内存分配 int *p = (int*)calloc(5, sizeof(int)); showArr(p, 5); // calloc 会初始化为 0，所以可以直接打印 free(p); p = nullptr; // free 只是清除空间，还需要制空指针，不然就是一个野指针 // C++ 内存分配 int* page = new int; // 申请一个 int *page = 19; // 这里简单 new 不会初始化为 0，需要自行设置值 // int* page = new int(19); // 可以使用 c++ 的括号赋值直接进行赋值 cout \u003c\u003c *page \u003c\u003c endl; delete page; page = nullptr; page = new int[29]; // 申请一个数组，这里也不会初始化，所以可以采用下面的括号赋值，后面自动初始化为 0；或者使用 for 循环进行赋值 // page = new int[29]{1, 2, 3, 7, 12, 12}; showArr(page, 29); delete[] page; page = nullptr; return 0; } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:4:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"Lambda 表达式\rC++ 中 lambda 表达式语法为 [capture](parameters) -\u003e return_type { body }，相关描述如下： capture：变量捕获，定义了 lambda 如何捕获上下文中的变量 parameters：函数参数列表 return_type（可选）：定义返回类型（通常省略，由编译器推导） body：函数体 ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:5:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"Capture Clause\r这里定义的就是 lambda 是否可以捕获上下文的相关变量，直接写变量就是 按值捕获，加上 \u0026 就是按 引用捕获。 [] 表示不捕获上下文变量 [N, \u0026M] 表示 N 为按值捕获，不能修改原变量的值，M 为引用捕获，可以修改外围变量的值 [\u0026] 表示按照引用捕获，捕获所有封闭范围的变量，也就是所有在 lambda 外部作用域中定义的变量都通过引用传递给 lambda [=] 同上含义，但是表示所有的变量都按值捕获 [\u0026, =N] 表示 N 为按值捕获，其他变量都是按引用捕获 [this] 在某个 class 中使用匿名函数，可以通过这个方式捕获当前实例的指针 [*this] C++17，之后还可以按值捕获该实例 [N, \u0026M, K=5] C++14 之后，可以在捕获语句中定义新的变量并初始化，这样的变量 K 无需出现在匿名函数外围环境中 ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:5:1","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"Parameters\rC++ 14 之后，参数列表支持 auto 类型，例如 [](auto a, auto b) {return a + b;}，这个让匿名函数变的更通用更泛型。 ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:5:2","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"枚举类型\rC 和 C++ 都提供了枚举类型，两者有一定的区别。这里主要就是 C++ 的枚举类型，不涉及 C 的。 ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:6:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"enum 枚举类型\rC++ 中的 enum 就是枚举类型的标识符，它只允许赋值枚举值；同时枚举元素会暴露在外部作用域，两个不同枚举类型若是含有相同枚举元素，会产生冲突；不同的枚举可以直接进行比较 // 定义 enum WEEK {MON, TUE, WED, THI, FIR, SAT, SUN}; enum SHAPE {CIRCLE, RECT, POINT, LINE}; // 只允许赋值枚举值，前面的 enum 不进行添加就可以使用 WEEK today = 3; // 错误 error C2440：“初始化”：无法从“int”转换为“main::WEEK” today = CIRCLE; // 错误 error C2440：“=”：无法从“main::SHAPE”转换为“main::WEEK” // 枚举元素暴露在外部作用域 enumc OTHER {RECT}; // 错误 error C2365：“RECT”：重定义；以前的定义是“枚举数” Int RECT = 12; // 错误同上，但是可以通过枚举名访问指定的枚举属性 OTHER::RECT; // 正确 // 不同类型的枚举也可以直接比较 if (CIRCLE == MON){ cout \u003c\u003c \"yes\" \u003c\u003c endl; } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:6:1","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"enum class 强枚举类型\r这里强枚举类型不会将枚举元素暴露在外部作用域，必须通过枚举名去访问；同时不相关的两个枚举类型不能直接比较，编译报错 // 定义 enum class WEEK {MON, TUE, WED, THI, FIR, SAT, SUN}; enum class SHAPE {CIRCLE, RECT, POINT, LINE}; // 不暴露在外部作用域 cout \u003c\u003c SHAPCE::RECT \u003c\u003c endl; // 输出 1 // 不相关的两个枚举类型不能直接比较 if (SHAPCE::RECT == WEEK::MON){ // error c2676：二进制“==\"：“main::SHAPE\"不定义该运算符或到预定义运算符可接收的类型的转换 cout \u003c\u003c \"yes\" \u003c\u003c endl; } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:6:2","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"内联函数\r函数调用时，需要跳转到函数的地址去执行，执行完成后返回到被调用函数，比较费时，因此，C++中提供了一种操作方式，允许编译时直接把函数替换到调用处，即内联函数，它没有普通函数调用时的额外开销（压栈，跳转，返回）。在函数前面加上 inline 申明为内联函数。 内联函数声明时 inline 关键字必须和函数定义结合在一起，否则编译器会直接忽略内联请求。 C++ 编译器不一定准许函数的内联请求（只是对编译器的请求，因此编译器可以拒绝） 现代C++编译器能够进行编译优化，因此一些函数即使没有 inline 声明，也可能被编译器内联编译 #include \u003ciostream\u003e using namespace std; // 宏定义，会在编译的时候（预处理）进行替换，节省空间和时间，效率高，不会类型检查 #define MAX(a, b) a \u003e b ? a : b; // 内联函数，用来替换宏定义。inline 是关键字 /* 1. 不能存在任何形式的循环语句，不能存在过多的条件判断语句 2. 函数体不能过于庞大，不能对函数进行取址操作 3. 编译器对于内联函数的限制并不是绝对的，内联函数相对于普通函数的优势只是省去了函数调用时压栈，跳转和返回的开销。因此，当函数体的执行开销远大于压栈，跳转和返回所用的开销时，那么内联将无意义。 */ inline int mmax(int a, int b){ return a \u003e b ? a : b; } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:7:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"强制类型转化\rC 风格的强制类型转换很简单，据使用 Type b = (Type)a 形式进行转换。但是 C 风格的类型转换有不少缺点：万物皆可转，不容易区分，不容易查找代码。因此 C++ 提供了四种类型转换操作符来应对不同场合。 类型转换操作符 作用 static_cast 静态类型转换，编译器做类型检查，基本类型能转换，指针不能 reinterpret_cast 重新解释类型 const_cast 去const属性 dynamic_cast 动态类型转换，运行时检查类型安全（转换失败返回nullptr）如子类和父类之间的多态类型转换 #include \u003ciostream\u003e using namespace std; class Animal { public: virtual void cry() = 0; virtual ~Animal(){} }; class Dog:public Animal { public: void cry() override{ cout \u003c\u003c \"狗吠\" \u003c\u003c endl; } void seeHome(){ cout \u003c\u003c \"看家\" \u003c\u003c endl; } }; class Cat:public Animal { public: void cry() override{ cout \u003c\u003c \"猫叫\" \u003c\u003c endl; } void catchMouse(){ cout \u003c\u003c \"抓老鼠\" \u003c\u003c endl; } }; void obj(Animal* base){ base-\u003ecry(); // Dog：看家 // ((Dog*)base)-\u003eseeHome(); // 这种行为，不会根据传入参数的实际对象进行相应函数调用，而是只要转换就进行调用，也就是这样没有安全检查 Dog* dog = dynamic_cast\u003cDog*\u003e(base); // 这里运行时进行判断，如果转换成功返回子类所在地址，转换失败返回空指针 if (dog) { dog-\u003eseeHome(); } // Cat：抓老鼠 //((Cat*)base)-\u003ecatchMouse(); Cat* cat = dynamic_cast\u003cCat*\u003e(base); if (cat) { cat-\u003ecatchMouse(); } } int main(){ // 1. static_cast 类似 C 风格的强制转换，进行无条件转换，静态类型转换。 /* 基本数据类型转换，enum，struct，int，char，float 等。static_cast 不能进行无关类型（如非基类和子类）指针之间的转换。 可以用于 void* 和其他指针类型之间的转换（但是不能用于非 void 指针之间的转换） 不能用于两个不相关类型的转换，如 int 和 int* 之间的转换，虽然二者都是四个字节，但他们一个表示数据，一个表示地址，类型不相关，无法进行转换。 */ int age = 10; // double d = age; // 隐式类型转换 // double d = (double)age; // C 风格转换 double d = static_cast\u003cdouble\u003e(age); int* p = \u0026age; // double* pd = (double*)p; // 正确 // double* pd = static_cast\u003cdouble\u003e(p); // error C2440：“static cast”：无法从“int *”转换为“double *” void* pv = static_cast\u003cvoid*\u003e(p); // 正确 double* pdd = static_cast\u003cdouble*\u003e(pv); // 正确 // 2. reinterpret_cast 专门用来转换指针 double *pd = reinterpret_cast\u003cdouble*\u003e(p); // 正确 // 3. const_cast 去掉 const 属性 const int week = 7; // week = 5; // 错误，不能直接修改常量 int\u0026 rint = const_cast\u003cint\u0026\u003e(week); rint = 5; // 正确，可以去掉 const 属性，但是原先的值没有进行修改 // 4. dynamic_cast 把父类指针转为子类指针（判断父类指针指向的是哪个子类对象） Animal* pdog = new Dog; Animal* pcat = new Cat; obj(pdog); obj(pcat); } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:8:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"RAII 与智能指针\r","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:9:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"unique_ptr\r在没有智能指针的 C++ 中，我们只能手动去 new 和 delete 指针。这非常容易出错，一旦忘记释放指针，就会导致内存泄露等情况。因此 C++11 引入了 unique_ptr 容器，它的结构函数中会调用 delete p，因此不会造成忘记释放指针的情况，同时这里释放之后，就会把指针设置为 nullptr，防范了空悬指针的情况。 #include \u003ccstdio\u003e #include \u003cmemory\u003e struct C { C() { printf(\"分配内存!\\n\"); } ~C() { printf(\"释放内存!\\n\"); } }; int main() { std::unique_ptr\u003cC\u003e p = std::make_unique\u003cC\u003e(); if (1 + 1 == 2) { printf(\"出了点小状况……\\n\"); return 1; // 自动释放 p } return 0; // 自动释放 p } 同时 unique_ptr 删除了拷贝构造函数，所有直接进行调用会出错，也就是 func(std::unique_ptr\u003cC\u003e p) -\u003e func(p) 会因为触发一次拷贝而报错。因此需要分以下两种情况进行调用。 #include \u003ccstdio\u003e #include \u003cmemory\u003e struct C { C() { printf(\"分配内存!\\n\"); } ~C() { printf(\"释放内存!\\n\"); } void do_something() { printf(\"成员函数!\\n\"); } }; void func1(C *p) { p-\u003edo_something(); } std::vector\u003cstd::unique_ptr\u003cC\u003e\u003e objlist; void func2(std::unique_ptr\u003cC\u003e p) { objlist.push_back(std::move(p)); // 进一步移动到 objlist } int main() { std::unique_ptr\u003cC\u003e p = std::make_unique\u003cC\u003e(); // func1() 不需要资源的占有权，即不需要生命周期，那么就可以使用原始指针 func1(p.get()); // func2() 需要生命周期，所以可以使用移动构造函数 printf(\"移交前：%p\\n\", p.get()); // 不为 null func2(std::move(p)); // 通过移动构造函数，转移指针控制权 printf(\"移交后：%p\\n\", p.get()); // null，因为移动会清除原对象，如果需要保留，那么就提前使用 C *raw_p = p.get(); 进行获取 return 0; } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:9:1","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"shared_ptr\rshared_ptr 是更为智能的指针，它牺牲效率换来自由度，允许拷贝，它解决重复释放的方式是通过引用计数： 当一个 shared_ptr 初始化时，将计数器设为1 当一个 shared_ptr 被拷贝时，计数器加1 当一个 shared_ptr 被解构时，计数器减1。减到0时，则自动销毁他指向的对象 这样就可以保证，只要还有存在哪怕一个指针指向该对象，就不会被解构。同时我们可以使用 p.use_count() 来获取当前指针的引用计数。 #include \u003ccstdio\u003e #include \u003cmemory\u003e #include \u003cvector\u003e struct C { int m_number; C() { printf(\"分配内存!\\n\"); m_number = 42; } ~C() { printf(\"释放内存!\\n\"); m_number = -2333333; } void do_something() { printf(\"我的数字是 %d!\\n\", m_number); } }; std::vector\u003cstd::shared_ptr\u003cC\u003e\u003e objlist; void func(std::shared_ptr\u003cC\u003e p) { objlist.push_back(std::move(p)); // 这里用移动可以更高效，但不必须 } int main() { std::shared_ptr\u003cC\u003e p = std::make_shared\u003cC\u003e(); // 引用计数初始化为 1 func(p); // shared_ptr 允许拷贝！和当前指针共享所有权，引用计数加 1 func(p); // 多次也没问题，多个 shared_ptr 会共享所有权，引用计数加 1 p-\u003edo_something(); // 正常执行，p 指向的地址本来就没有改变 objlist.clear(); // 刚刚 p 移交给 func 的生命周期结束了！引用计数减 2 p-\u003edo_something(); // 正常执行，因为引用计数还剩 1，不会被释放 return 0; // 到这里最后一个引用 p 也被释放，p 指向的对象才终于释放 } ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:9:2","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["programming"],"content":"指针相关\r下面列举了使用指针类型取相关变量的数据，这里假设 eax = 0x401234 它存储了一个地址，而这个地址存储数据 0x12345678，那么对于下面的指针会获取不同的数据。 *(char*)eax; *(int*)eax; 对于 *(char*)eax;，首先 (char*)eax 将寄存器 eax 的值转换为 char* 类型，意味着 eax 被看作是指向一个字符的指针。而 *(char*)eax 是对该地址处的数据进行解引用操作，因为已经把 eax 强制转换为 char*，所以此时解引用会得到这个地址处的一个字符。因此它只会取得该地址处的 最低字节，即 0x78（注意小端序存储，0x78 0x56 0x34 0x12 顺序的数据会转化为 0x12345678） 对于 *(int*)eax; 也是同样的理解，最终会获取数据 0x12345678。 ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:10:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["config"],"content":"关于 Android Studio 的使用和配置。 ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:0:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"Gradle下载配置\r直接更换国内腾讯 镜像源，打开 gradle - wrapper -gradle-weapper.properties 进行更改。然后点击 Sync Now 进行同步。参考-\u003e Android导入项目时Gradle下载速度慢_导入gradle项目特别慢 #Sun Feb 25 20:22:32 GMT+08:00 2024 distributionBase=GRADLE_USER_HOME distributionPath=wrapper/dists distributionUrl=https\\://mirrors.cloud.tencent.com/gradle/gradle-8.2-bin.zip # 这里就对应替换为腾讯的镜像地址 zipStoreBase=GRADLE_USER_HOME zipStorePath=wrapper/dists 但是这样也是很慢，还是得等，有时候还会突然跑到源地址去下载，搞不明白。(后续补充：有时候改了国内源，然后停止加载zip文件，之后重试一下就快很多了) ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:1:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"新版 AS 添加依赖\r这里是在 settings.gradle.kts 文件中添加 maven 仓库，然后在 app 的 build.gradle.kts 文件中添加依赖。查看这里Android Studio | 2022.3.1版本解决创建项目下载gradle缓慢问题 // settings.gradle.kts 文件中 dependencyResolutionManagement { repositoriesMode.set(RepositoriesMode.FAIL_ON_PROJECT_REPOS) repositories { google() mavenCentral() maven { url = uri(\"https://jitpack.io\") }// as改版后的新添加方式 } } // build.gradle.kts 文件中 dependencies { implementation(\"com.github.Hitomis:CircleMenu:v1.1.0\") // as改版后的新添加方式 } ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:2:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"SD卡读写权限\r对于低版本 sdk，只需要以下权限即可(在AndroidManifest.xml中修改)，在manifest标签中添加 \u003cuses-permission android:name=\"android.permission.READ_EXTERNAL_STORAGE\"\u003e\u003c/uses-permission\u003e \u003cuses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\"\u003e\u003c/uses-permission\u003e 而对于高版本的 sdk，这里是34，则需要添加东西。新加入的在application标签中添加 \u003cuses-permission android:name=\"android.permission.READ_EXTERNAL_STORAGE\"\u003e\u003c/uses-permission\u003e \u003cuses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\"\u003e\u003c/uses-permission\u003e \u003cuses-permission android:name=\"android.permission.MANAGE_EXTERNAL_STORAGE\"\u003e\u003c/uses-permission\u003e android:requestLegacyExternalStorage=\"true\" ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:3:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"dataBinding使用\r刚开始创建的 Launch Activity 不用理会，但是对于新增加的Activity，想要使用 dataBinding 功能，就需要先在 build.gradle.kts文件中添加下面代码： android { ...... buildFeatures { dataBinding = true // 确保这里启用了数据绑定 } } 然后在相关 xml 文件中，对准 androidx.constraintlayout.widget.ConstraintLayout按下alt + enter 转化为 databinding 的模式。这样后续的 activity 才可以使用并编译apk成功。 ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:4:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"图片导入\r资源主要就是存放在 res 目录下，如下表所示各个目录的作用。 目录 作用 drawable 存放所有的图片及图标配置（xml文件展示） layout 布局，创建一个Activity一般会同步创建一个布局。 mipmap 存放各种分辨率的图标，平常用的就是 xxhdpi values 一些固定的配置，例如值，主题等 这里 drawable 存放的东西大多就是 图标的配置，在 As 中可以利用 File → New → Android Resource File 来生成一个配置文件，例如背景之类的可以重复使用。 同时使用File → New → Image Asset 可以创建 app 应用的图标，提供 svg 图片即可自动创建。使用File → New → Vector Asset 则是创建图片，将一个 svg 格式的图片转化为 xml 文件形式，然后供 ImageView 等控件使用。如果只有 png 格式的图片，首先需要转化为 svg 格式，这里推荐网站，其余网站转化的 svg 可能存在问题，As 不一定可以使用。 ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:5:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"So文件生成\r","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:6:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"添加新文件\r对于头文件 .h 首先在 cpp 目录下创建相应文件，然后在 CmakeLists.txt 文件中添加下面的代码 include_directories( basic.h ) 对于文件 .cpp 在 cpp 目录下创建，然后在 CmakeLists.txt 文件中的 add_libraty 添加新创建的 .cpp文件。这样多个 .cpp 文件就会编译为一个 so 库。 add_library(${CMAKE_PROJECT_NAME} SHARED # List C/C++ source files with relative paths to this CMakeLists.txt. native-lib.cpp checkfrida.cpp) 添加文件\r","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:6:1","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"编译多个so文件\r这里就是再添加一个 add_library 文件，这样就可以编译为多个了。 add_library( # so 文件的名字 checkroot # 共享库 SHARED # List C/C++ source files with relative paths to this CMakeLists.txt. checkroot.cpp) 编译多个文件\r","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:6:2","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"引入第三方库\r使用第三方库的函数 这里就是利用 target_link_libraries 进行引用，注意对于每一个so文件，都需要进行引用操作。这里上面的是默认的，要是能在 checkroot.cpp 文件中使用 log，那么就需要自己手动进行引用了。 target_link_libraries( checkroot # List libraries link to the target library android log ) 引入库\r","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:6:3","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"使用汇编配置\r起因就是需要使用 SVC 这条汇编语句完成 frida 的检测，但是查阅资料不知道怎么进行，最后终于尝试成功了，在此记录流程。 代码设置\r这里是复制 参考资料 的代码，然后做了删减达到了下面的效果。 bionic_asm.h ，它包含了汇编语言需要的一些基础配置，例如 \u003casm/unistd.h\u003e 中的系统调用号，MAX_ERRNO 是最大错误号的定义。最为关键的就是对于 ENTRY 和 END 的定义，没有这个定义，下面的汇编语言也就是会识别错误。同时这里和下面的 syscall.S 文件一样，只定义了 aarch64 ， x86_64 两个架构，所以在build.gradle.kts 的 abiFilters 选项也只能存在两个架构，不然会因为其他架构的汇编不存在而报错。 #pragma once #include \u003casm/unistd.h\u003e /* For system call numbers. */ #define MAX_ERRNO 4095 /* For recognizing system call error returns. */ #define __bionic_asm_custom_entry(f) #define __bionic_asm_custom_end(f) #define __bionic_asm_function_type @function #define __bionic_asm_custom_note_gnu_section() #if defined(__aarch64__) #define __bionic_asm_align 16 #elif defined(__x86_64__) #define __bionic_asm_align 16 #endif #define ENTRY_NO_DWARF(f) \\ .text; \\ .globl f; \\ .balign __bionic_asm_align; \\ .type f, __bionic_asm_function_type; \\ f: \\ __bionic_asm_custom_entry(f); \\ #define ENTRY(f) \\ ENTRY_NO_DWARF(f) \\ .cfi_startproc \\ #define END_NO_DWARF(f) \\ .size f, .-f; \\ __bionic_asm_custom_end(f) \\ #define END(f) \\ .cfi_endproc; \\ END_NO_DWARF(f) \\ /* Like ENTRY, but with hidden visibility. */ #define ENTRY_PRIVATE(f) \\ ENTRY(f); \\ .hidden f \\ /* Like ENTRY_NO_DWARF, but with hidden visibility. */ #define ENTRY_PRIVATE_NO_DWARF(f) \\ ENTRY_NO_DWARF(f); \\ .hidden f \\ #define __BIONIC_WEAK_ASM_FOR_NATIVE_BRIDGE(f) \\ .weak f; \\ #define ALIAS_SYMBOL(alias, original) \\ .globl alias; \\ .equ alias, original #define NOTE_GNU_PROPERTY() \\ __bionic_asm_custom_note_gnu_section() 这里就是 syscal.S 文件，它这里实现了对于 openat 函数的底层汇编，但是因为这里找不到 __set_errno_internal 这个函数所在的文件，没有办法链接，所以直接注释掉。因为这个就是对于错误进行处理的函数，就是运行失败之后进入错误处理再返回，告知错误的类型。我这里不需要进行维护，所以错误的类型可有可无，直接注释即可。 #include \"bionic_asm.h\" #if defined(__aarch64__) ENTRY(my_openat) mov x8, __NR_openat svc #0 cmn x0, #(MAX_ERRNO + 1) cneg x0, x0, hi // b.hi __set_errno_internal ret END(my_openat) #elif defined(__x86_64__) ENTRY(my_openat) movl $__NR_openat, %eax syscall cmpq $-MAX_ERRNO, %rax jb my_openat_return negl %eax movl %eax, %edi // call __set_errno_internal my_openat_return: ret END(my_openat) #endif 然后最后在需要使用外部汇编文件的代码中加入下面这一条代码。这样才可以进行函数的调用。 extern \"C\" int my_openat(int dirfd, const char *const __pass_object_size pathname, int flags, mode_t modes); AS 配置\rCMakeLists.txt\r添加 enable_language(ASM)，允许使用汇编语言，不加这个就会报错。同时下面链接库添加新增的上面的两个文件，保证可以整合到一个 so 文件中。 enable_language(ASM) add_library( # so 文件的名字 checkfrida # 共享库 SHARED # List C/C++ source files with relative paths to this CMakeLists.txt. checkfrida.cpp asm/bionic_asm.h asm/syscall.S ) build.gradle.kts\r在 android-—defaultConfig 的路径下添加 ndk，这里的 abiFilters 和官网给的样例不一致，具体看 参考资料，需要使用特定格式进行架构的添加。这里查看下面 使用不同结构的代码。同时这里因为只写了两种架构的 SVC 汇编，所以固定了架构，因此最后生成的 so 就只有这两种架构的文件了。如果不定义这个配置，那么默认就是会存在四种架构的 so 文件。 ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:6:4","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"使用不同架构\rAs 进行了改版，所以之前的方式不能使用了。这里是在 app 的 build.gradle.kts 文件中添加。下面展示了两种方式。 android { ... defaultConfig { ... ndk { // 第一种方式 abiFilters.addAll(arrayOf(\"arm64-v8a\", \"x86_64\")) // 第二种方式 //abiFilters.add(\"arm64-v8a\") //abiFilters.add(\"x86_64\") //abiFilters.add(\"armeabi-v7a\") //abiFilters.add(\"x86\") } } } ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:6:5","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"相关操作\r","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:7:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"存储空间管理\r移动 .gradle 到指定位置 将 .gradle文件 从C盘移动到D盘，这里同时还需要相应修改 idea.plugins.path 和 idea.log.path 移动 .android 到指定位置 解决方案 ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:7:1","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"生成apk\rbuild -\u003e Generate Signed Bundle or APK：选择APK，然后创建key（注意需要路径完整），之后再选择 release 即可 生成的 app-debug.apk 在路径 /app/build/outputs/apk/debug/ 下面，或者在 /app/build/intermediates/apk/debug/ 目录下。这里不知道是什么的变化引起的生成存放目录的变化。 build → Generate Signed Bundle or APK 可以生成签名后的 apk（release版本），它存放在和 debug类似的目录下。这里我的 vivo 手机不能使用 debug 版本，只能下载 release 版本。 ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:7:2","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"报错汇总\r遇到问题 Cannot use connection to Gradle distribution 'https://mirrors.cloud.tencent.com/gradle/gradle-8.2-bin.zip' as it has been stopped. 这里直接关闭项目，再重新打开即可。 Error running 'app': Default Activity not found 这里修改 configuration，更改 Launch Options -\u003e Launch:nothing android studio怎么运行没有activity的service、broadcastReceiver、cotentProvicer等 日志不能在 As 中显示 检查算法助手有没有 hook 对应程序，如果存在，那么它好像开机自启，自动将日志捕获了。关闭应用 hook 就可以显示日志了 ","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:8:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"自己对于 FixIt 主题的一些配置 ","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:0:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"大致流程\r这里我使用的就是Git 子模块的安装方式，更详细的流程参照这篇快速上手。在必要的配置后，博客就可以进行本地浏览了。之后我使用 Github Action 的方式，将本地博客的所有文件上传到一个私密仓库，之后创建 Github Action 将通过 hugo --gc --minify 命令构建的 public 目录上传到另一个公开仓库 blog 中，这样就可以设置静态网站进行博客访问了，具体可以参考Huogo 主题配置。这样博客基本上就好了，可以开始额外的操作了。 ","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:1:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"图片自适应\r我使用的图片都是存储在图床中的，使用的就是 Markdown 的经典语法。但是它在 FixIt 的渲染中会左对齐，有时还会在图片后面跟随文字，感官很不好，所以思考怎么进行改进。在参考FixIt主题使用lightgallery自适应显示图片之后，自己进行了调整，达到了现在的效果。 这里主要参照上述参考文章的两种尝试，采用 lightgallery 来呈现图片。我参照 FixIt配置篇 将 lightgallery 设置为 \"force\" 但是如果没有 alt 和 title 属性，我的图片不会按照画廊形式呈现，所以我只能另辟蹊径。因为我使用 PicGo 进行图床配置，刚好它支持修改本地输出图片链接的格式，因此我修改PicGo的配置，把 Custom Output Format 配置为![${uploadedName}](${url} \"${uploadedName}\")。这样它会自己填充 alt 和 title，我只需要按照自身需求修改 alt 属性即可。 另外点击图片之后会显示 alt 和 title 两个信息，所以打开 F12 进行观察，发现第一行来自标签 \u003ch2\u003e，也是 alt 属性，第二行来自标签 \u003cp\u003e，是 title 属性。这部分都是在 themes/layouts/partials/plugin/image.html 中，所以直接修改主题文件，把这里的 \u003cp\u003e 删除，然后 \u003ch2\u003e 移动到中间，这样渲染的时候只会在下面出现 alt 属性了，放大图片和鼠标移动到图片上才会看到 title 属性。 修改配置文件\r","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:2:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"GitHub 提交记录贪吃蛇动画\r参照GitHub 提交记录贪食蛇动画进行配置，不过我将 Github Action 写在了同名仓库中了，这样就少创建了一个仓库，其他都是按照参考文章所述的进行配置即可。插一嘴，本来想把 github-metrics.svg 单独放在一个分支中，但是不熟悉自动化部署脚本，配置了一会儿发现总是部署失败，所以直接使用GitHub 个人主页美化教程来进行配置了。 ","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:3:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"配置文章修改时间\rFixit 的 frontmatter 有一个属性 lastmod，它就是文章最后修改时间，一开始的配置不知道有没有效果，但是还是参照 loveit主题配置 之后，形成了现在的配置。 当前配置是在 atchetypes/default.md 文件中，设置 lastmod: {{ .Date }}。config/_default/hugo.toml 中设置 enableGitInfo = true， 同时在 config/_default/params.toml 中，找到 [gitInfo] 选项，设置 repo 为自己 public 目录发布的仓库地址。这样就会在文章左下角和一开始的信息标识处显示更新时间。 这里的文章修改时间很玄学，要么新创建的文章上面信息展示的地方没有修改时间，要么地下的修改时间没有提交的 hash 值，要么修改的文章信息没有变化。最近一次成功修改还是通过 git 将 content 和 public 中的所有文件都删除，然后再提交之后才可以进行时间修改的，但是这个时候所有文章的修改时间都一样了。所以目前初步认为起关键作用的还是 content 目录下面文件的 git 提交时间，之后修改了文件，就不直接使用 add 进行添加了，而是把文件先删除，之后再提交，这样不知道会不会正确显示修改时间。 验证发现 git add . 也能发挥作用，但是修改后直接进行 hugo --gc --minify 提交发现不会出现修改信息，之后本地使用 hugo server -D 反而出现了修改时间。之后尝试首先本地部署，再进行生成，发现该效果会呈现出最新的修改时间。（这里的办法没用，目前得到的信息就是本次的修改不会改变本次的修改时间，只有下一次的 push 才会真正显示出上一次的修改，所以目前只能这样了，只要修改时间不像之前一样突然没有了就行）。 ","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:4:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"网站图标\r对于网站图标实在是束手无策，一开始采用官网配置，但是给的利用网站不能生成符合要求的一系列文件，同时把生成文件都放在/static目录下，最后会把这些文件生成在/public根目录下，很不喜，所以放弃了这种方法。后来尝试和 author 的 avatar 属性配置一样，把 svg 图片放在images目录下，但是展示不出来。最后看到别人文章，发现直接使用图床的图片可以生成，所以我现在也是利用这样的方式展示网站图标。 ","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:5:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"阅读原始文档\r可以看到左下角存在 阅读原始文档 的选项，点击就直接可以看到 markdown 的原文本了，当然这个是我们不想要的（虽然网页直接下载 pdf 也是一样的）。因此我们可以设置配置中的 outputs.toml 文件，在 page 中去除 markdown，这样点击就不会看到我们的源码了。 配置修改\r","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:6:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"Git 提交\r受上面 配置文章修改时间 的影响，记录下这里的 git 操作，以便之后忘记了还可以看这里进行会议。 # 本地预览渲染效果 hugo server -D # 最小化生成渲染文件 hugo --gc --minify # 将修改和新增的文件信息都添加到暂存区 git add . # 将删除文件信息添加到暂存区 git rm xxx # 根据暂存区信息提交代码到本地仓库 git commit -m \"xxx\" # 推送本地仓库代码到远程仓库 git push -u origin main 经过上面的操作，就会把代码传到 github 上了，之后使用 GitHub Action 把 public 传到公开仓库中，之后就可以根据静态页面进行查看了。这里还可以使用 Vscode 的提交板块，它应该和 jetbrains 的产品一样，内置了删除的操作，所以我们只需要写 commit 信息然后一直点击按钮就可以进行提交了，不需要区分添加修改和删除操作（这里我没有试过，只是猜测，但是 jetbrains 和 As 的 commit 是这样设计的）。 ","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:7:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"数学公式\r本来这个只是一个小问题，但是后来发现只要公式渲染出现问题，大概就是这个原因，所以记录一下 fixit 的数学公式渲染。主要的解决方案就是在 fixit 数学公式 的“关于转义字符相关的注意事项”，这里就是 Hugo 渲染的时候，数学公式中的有些字符和 HTML 产生冲突，所以需要转义处理。这里已经罗列了很多需要转移的字符，但是除此之外还有一些，这里通过 Latex 语法来显示额外也需要进行转义的字符： { -\u003e \\\\{ } -\u003e \\\\} $ -\u003e \\\\$ ","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:8:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"一些关于 git 的操作 git流程\r","date":"2024.11.1","objectID":"/blog/posts/config/git/:0:0","tags":["config"],"title":"Some about Git","uri":"/blog/posts/config/git/"},{"categories":["config"],"content":"相关命令\r# 本地仓库初始化 git init # 将文件提交到暂存区 git add \u003cfile_name\u003e git add . # 添加全部修改和新增文件 # 将文件提交到本地仓库 git commit \u003cfile_name\u003e git commit -m \"commit information\" \u003cfile_name\u003e git commit -m \"commit inforamtion\" # 提交全部到本地仓库 # 添加远程仓库，这里是因为存在多个 git 用户所进行的配置，正常为 git@github:czTangt/blog.git git remote add origin git@github_czTangt:czTangt/blog.git # 提交到远程仓库 git push -u origin \u003cbranch_name\u003e git push -f # 强制提交 # 拉取远程仓库 git pull \u003cremote_name\u003e \u003cremote_branch_name\u003e # 这里是从远程仓库 remote_name 拉取指定分支 remote_branch_name 的更新并合并到当前分支。 # remote_name 通常是远程仓库的别名，例如默认的 origin，表示克隆时配置的远程仓库。 # git pull 是 git fetch 和 git merge 的组合操作，首先获取远程更新，然后尝试合并到当前分支。 # 分支操作 git branch -a # 查看所有分支 git checkout -b \u003clocal_branch_name\u003e # 创建本地分支 git branch -d \u003clocal_branch_name\u003e # 删除本地分支 git checkout -b \u003clocal_branch_name\u003e origin/\u003cremote_branch_name\u003e # 创建本地分支并与远程分支连接 git push origin --delete \u003cremote_branch_name\u003e # 删除远程分支 git checkout \u003cremote_branch_name\u003e # 切换分支 # 分支冲突 # 在 git 当中，通常合并分支可以自动完成。如果遇到分支冲突，需要手动选择要保留的分支，然后再次进行 git commit。 # 恢复文件为之前提交的状态 git checkout commit_version -- \u003cfile_name\u003e # 首先从 git log 获取某次提交的 commit_version，然后执行命令可以手动恢复这次提交的特定文件 ","date":"2024.11.1","objectID":"/blog/posts/config/git/:1:0","tags":["config"],"title":"Some about Git","uri":"/blog/posts/config/git/"},{"categories":["config"],"content":"文件修改\r对于 git 而言，git add . 会将所有修改和新增的文件信息提交到暂存区，之后使用 git commit -m \"xxx\" 会将暂存区的文件信息提交到本地仓库。但是这种方法是对于新增和修改的文件而言，对于删除的文件信息不会进行更新，所以可以采用两种方案： 使用 git rm xxx 一个一个手动删除文件（rm 命令没有办法使用 git rm . 一起更新全部的文件删除信息），之后这些文件删除信息就提交到暂存区了，后续就可以继续使用 git commit -m \"xxx\" 来将代码提交到本地仓库 使用 git commit -am 命令，该命令会在提交到本地仓库时，先更新修改和删除的文件信息到暂存区（注意它不会提交新增加的文件信息）。所以加了 -a 在 commit 的时候，可以帮助省一步 git add，但是也只是对修改和删除文件有效，新文件还是要 git add，不然就是 untracked 状态。 综上所述：git add 和 git rm 都是等价的操作，前者添加修改和新增文件信息，后者添加删除文件信息，他们都是将文件信息提交到暂存区，之后使用 git commit -m \"xxx\" 来将暂存区的文件信息提交到本地仓库，最后使用 git push -u origin main 来提交本地仓库代码到远程仓库的 main 分支。 ","date":"2024.11.1","objectID":"/blog/posts/config/git/:2:0","tags":["config"],"title":"Some about Git","uri":"/blog/posts/config/git/"},{"categories":["config"],"content":"远程仓库到自己仓库\r拉取别人的仓库到自己仓库，主要应对github中没有对应仓库的情况繁琐指南，存在对应仓库，直接进行 fork，然后在本地添加自己的远程。简单的操作如下： git branch -r | grep -v '\\-\u003e' | while read remote; do git branch --track \"${remote#origin/}\" \"$remote\";done # 获取所有远程分支到本地 git fetch --all # 获取该项目远程库的所有分支及其内容 git fetch --tags # 获取该项目远程库的标签(没标签就不必了) git remote rename origin old-origin # 将原来的origin重命名一下 git remote add origin git@172.28.3.77:xs-soc/test-code.git # 指定需要迁移到新的目标地址(自己的仓库) git push origin --all # 推送所有分支及其内容 git push --tags # 推送所有标签及其内容 git remote rm origin # 删除当前远程库 git branch -M main # 重命名主要分支仓库 git push -u origin main # 推送到指定分支 ","date":"2024.11.1","objectID":"/blog/posts/config/git/:3:0","tags":["config"],"title":"Some about Git","uri":"/blog/posts/config/git/"},{"categories":["config"],"content":"Git 加速\rgit失败的原因绝大多数都是网络问题，所以挂代理是最为推荐的选择。以下是起作用的一些方法 通用方法，更换 git 的代理为 443 SSH：连接到主机github.com端口22：连接时间超时 但是对于 wsl，直接使用最新 wsl2 共用主机的代理即可（最为推荐），不嫌麻烦可以给配置个代理 配置wsl镜像 Windows10系统下配置WSL2自动走Clash代理，之后clash打开allow lan模式即可 WSL2内使用Windows的v2ray代理 | Nafx’s Blog，这是v2的模式，首先最后面设置，然后前面配置bashrc 有时候最后的方法会起点作用 git clone失败解决方案 ","date":"2024.11.1","objectID":"/blog/posts/config/git/:4:0","tags":["config"],"title":"Some about Git","uri":"/blog/posts/config/git/"},{"categories":["compile"],"content":"这里记录词法分析，正则表达式，自动机的相关知识。 ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:0:0","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"正则表达式与自动机理论\r","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:1:0","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"课程目标\r这里讲解怎么写一个自动化词法分析器生成器。根据前面的理论，我们使用 ANTLR4 来生成词法分析器，其实质上是我们使用 ANTLR4 利用正则表达式（regular expression -\u003e RE）的规则来进行生成词法分析器。同时我们还学习了利用 java 来手写词法分析器，实质就是在使用 java 代码模拟状态转移图，它也就是自动机。那么我们来看 ANTLR4 原理，他就是把 .g4 文件转化为 .java 文件，也就是把正则表达式转化为了自动机，然后通过模拟自动机就可以得到词法分析器了。 因此我们的目标就是通过正则表达式来直接得到得到一个词法分析器。 conversion\r由上图，我们构建词法分析器就是把 RE 转化为 DFA（有穷状态自动机 Deterministic FInite Automata），然后再转化为词法分析器，但是这个过程往往是困难的，所以我们采用简略的方法，通过先转化为 NFA（不确定的又穷状态自动机Nondeteeministic Finite Automata），再转化为 DFA，再进行后续的操作。 ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:1:1","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"编程语言介绍\r语言是字符串构成的集合。 根据这句高度抽象的结论，我们会一层层进行解剖。 字符 字母表 $\\Sigma$ 是一个有限的符号集合，符号没有意义，它的语义是后来自己赋予的。 字符串 字符表 $\\Sigma$ 上的串(s) 是由 $\\Sigma$ 中符号构成的一个有穷序列。 其中 $\\epsilon$ 是空串，我们定义它为零，即 $|\\epsilon| = 0$ 字符串之间存在运算 连接运算， $x = day, y = houce, xy = dayhouce, \\epsilon s = s \\epsilon = s$ 指数运算，$s^{0} \\triangleq \\epsilon$，$s^{i} \\triangleq ss^{i-1}, i\u003e0$，这里存在上标就是连接的意思 语言 语言是给定字母表 $\\Sigma$ 上一个任意的可数的串集合。 $\\empty$，这一个是空集，什么语言都没有；${ \\epsilon }$，这个里面有一个语言，不过是个空串 举例：id：${a,b,c,d,a1}$；ws：${blank, tab, newline }$，if：${ if }$ 我们知道语言是串的集合，正因为是集合，所以我们可以通过集合操作构造新的语言 rules\r","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:1:2","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"RE\r每个正则表达式 r 对应一个正则语言 L(r)。正则表达式是语法（ID：[a-zA-Z][a-zA-Z0-9]*），正则语言是语义（{a1,a2,ab,……}） ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:2:0","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"语法\r给定字母表，$\\Sigma$ 上的正则表达式由且仅由以下规则定义： $\\epsilon$ 是正则表达式 $\\forall a \\in \\Sigma$，a 是正则表达式 如果 r 是正则表达式，则 (r) 是正则表达式 如果 r 与 s 是正则表达式，则 r | s，rs，r* 也是正则表达式 运算优先级：$() \\succ * \\succ 连接 \\succ |$ ，例子：$(a) \\mid ((b)^{*} (c)) \\equiv a | b^{*} c$ ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:2:1","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"语义\r正则表达式对应的正则语言 $L(r)$ $L(\\epsilon) = { \\epsilon}$ $L(a) = a, \\forall a \\in \\Sigma$ $L((r)) = L(r)$ $L(r|s)=L(r) \\cup L(s)\\quad L(rs)=L(r)L(s)\\quad L(r^{*})=(L(r))^{*}$ ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:2:2","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"符号\rsymbol\rsymbol\r","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:2:3","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"自动机\r","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:3:0","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"NFA\r语法\r非确定性有穷自动机 $\\mathcal{A}$ 是一个五元组 $\\mathcal{A} = (\\Sigma, S, s_0, \\delta, F)$ 字母表 $\\Sigma (\\epsilon \\notin \\Sigma)$ 有穷的状态集合 $S$ 唯一的初始状态 $s_0 \\in S$，这里的唯一不是强求，因为可以转化为唯一形态，转化方法就是前面再添加ige初始状态，然后通过 ${\\epsilon }$ 边转移到原始初始状态即可。 状态转移函数 $\\delta$，$\\delta: S \\times (\\Sigma \\cup {\\epsilon}) \\rightarrow 2^S$ 接受状态集合 $F \\subseteq S$，下图的 3 就是接受状态 这里非确定一个就是指接受统一字符的状态转移不唯一，如下图的 0 号节点，它接受字符 a 可以跑到两个状态上去；另一个就是可能存在 ${ \\epsilon }$ 边，在没有字符驱动的情况下自发的跑到另外一个状态。 state transfer\r上面的状态转移图没有规定如果碰到其他的字符该怎么处理，所以下图就约定所有没有对应出边的字符默认指向 空状态 $\\empty$，也就是 $(\\Sigma \\cup {\\epsilon})$，它表示达到自身，也意味着一个死状态。 state transfer\r语义\r有穷自动机是一类及其简单的计算装置，它可以识别（接收/拒绝）$\\Sigma$ 上的字符串 接收 （非确定性）有穷自动机 $\\mathcal{A}$ 接受字符串 x，当且仅当存在一条从开始状态 $s_0$ 到某个接受状态 $f \\in F$ 、标号为 x 的路径。 对于上面的状态转移图，只有 3 是接受状态，因此 $aabb \\in L(\\mathcal{a}), ababab \\notin L(\\mathcal{A})$ 因此，$\\mathcal{A}$ 定义了一种语言 $L(\\mathcal{A})$：它能接受的所有字符串构成的集合。所以根据上方状态转移图，可以得到自动机语言：$L(\\mathcal{A}) = L((a|b)^*abb)$ 由上面的语义，我们可以得到自动机的两个基本问题 Membership 问题：给定字符串 $x$，$x \\in L(\\mathcal{A})?$ $L(\\mathcal{A})$ 究竟是什么？ ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:3:1","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"DFA\r语法\r确定性有穷自动机 $\\mathcal{A}$ 是一个五元组 $\\mathcal{A} = (\\Sigma, S, s_0, \\delta, F)$ 字母表 $\\Sigma (\\epsilon \\notin \\Sigma)$ 有穷的状态集合 $S$ 唯一的初始状态 $s_0 \\in S$，这个唯一是一定需要的 状态转移函数 $\\delta$，$\\delta: S \\times \\Sigma \\rightarrow S$ 接受状态集合 $F \\subseteq S$，下图的 3 就是接受状态 state transfer\r这里的约定就是：所有没有对应出边的字符串默认指向一个“死状态” 语义\r上图的自动机语言还是 $L(\\mathcal{A}) = L((a|b)^*abb)$，也就是上面的 NFA 和下面的 DFA 等价的。因此可以看出 NFA 适合去表达一个语言，容易得出语言是什么；而 DFA 则是因为状态的转移确定，适合写词法分析器。即 NFA 简介易于理解，便于描述语言 $L(\\mathcal{A})$；DFA易于判断$x \\in L(\\mathcal{A})$，适合产生词法分析器。那么转换就是 $RE \\Rightarrow NFA \\Rightarrow DFA \\Rightarrow$ 词法分析器。 ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:3:2","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"相互转换\r这里就是根据下面这张图，使得正则表达式和自动机之间相互转换。 conversion\r","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:4:0","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"RE -\u003e NFA\r采用 Thompson 构造法，使得 $r \\Rightarrow NFA$，要求 $L(N(r)) = L(r)$，即两个语言等价。这里就是对于正则表达式语法的每个规则来定义自动机，然后最后将这些自动机按规则进行组合就得到了 NFA。 $N(r)$ 的性质以及 Thompson 构造法复杂度分析 $N(r)$ 的开始状态和接受状态均唯一 开始状态没有入边，接受状态没有出边 $N(r)$ 的状态数 $|S| \u003c 2 \\times |r|$（$|r|: r$ 中运算符和运算分量的总和） 每个状态最多有两个 $\\epsilon \\text{-}$ 入边与两个 $\\epsilon \\text{-}$ 出边 $\\forall a \\in \\Sigma$，每个状态最多有一个 $a \\text{-}$ 入边与一个 $a\\text{-}$ 出边 自动机构造如下： Thompson\r","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:4:1","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"NFA -\u003e DFA\r原理\r采用子集构造法，也就是用 DFA 模拟 NFA。 子集构造法\r下面就是从 NFA 到 DFA 的构造对应表，有了这张表就有了自动机。之所以是子集构造法，是因为构造出来的 DFA 对应于 NFA 的一个状态子集。同时这里因为在 NFA 中 10 是接受状态，所以在 DFA 中，对应的 E 也是接收状态。 构造对应表\r形式化描述子集构造法\r这里根据上图的转化，会得到两个重要的公式： $\\epsilon$ 闭包：从状态 s 开始，只通过 $\\epsilon \\text{-}$ 转移可达的状态集合 $\\epsilon\\text{-closure}(s)={t\\in S_N|s\\xrightarrow{\\epsilon^*}t}$，这个公式的含义就是把 NFA 中的初始状态归结于 DFA 中的初始状态。上图中 NFA 的 ${0,1,2,4,7}$，它是初始状态，在 NFA 中，从 0 开始，通过 $\\epsilon$ 边进行连接的状态在 DFA 中都是初始状态。之后进行扩展操作 $\\epsilon \\text{-closure(T)} = \\bigcup_{s \\in T}\\epsilon \\text{-closure(s)}$，这个就是把上面的初始状态都添加在一起，转化为了集合形式，即状态集合，它为下面的 move 公式提供操作变量。 $\\text{move(T,a)} = \\bigcup_{s\\in T} \\delta(s,a)$，这个公式就是根据集合的当前状态，然后根据转移函数 $\\delta$，逐个查看集合中每个元素在同一个字符作用的目标元素是什么，最后将目标元素添加到新集合中，这个集合就是 DFA 中的下一个状态。 之后就可以形式化描述子集构造法：子集构造法($N \\rightarrow D$) 的原理： $$ \\begin{array}{l} N: (\\Sigma_N, S_N, n_0, \\delta_N, F_N) \\\\ D: (\\Sigma_D, S_D, d_0, \\delta_D, F_D) \\\\ \\Sigma_{D} = \\Sigma_{N} \\\\ S_{D} \\subseteq 2^{S_{N}} \\quad (\\forall s_{D} \\in S_{D} : s_{D} \\subseteq S_{N}) \\end{array} $$ 初始状态：$d_{0} = \\epsilon \\text{-closure}(n_{0})$ 状态转移：$\\forall a \\in \\Sigma_{D} : \\delta_{D}(s_{D}, a) = \\epsilon\\text{-closure}(\\operatorname{move}(s_{D}, a))$ 接受状态集：$F_{\\mathcal{D}} = { s_{D} \\in S_{\\mathcal{D}} \\mid \\exists f \\in F_N \\colon f \\in s_{D} }$ 子集构造法的复杂度分析：（$|S_N=n|$，下面的符号就是算法分析中的分析符号） $$\\left|S_{D}\\right| = \\Theta\\left(2^{n}\\right) = O\\left(2^{n}\\right) \\cap \\Omega\\left(2^{n}\\right)$$ 对于任何算法，最坏情况下，$|S_{D}| = \\Omega\\left(2^{n}\\right)$。 ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:4:2","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"DFA最小化\r方法\r我们还是查看之前使用 NFA -\u003e DFA 的转换图来看，下面的 DFA 就是使用子集构造法将 NFA 转化而来的，毫无疑问，与上面的图相比，它不是最小的，所以这里需要探究的就是如何将 DFA 转化为最小化的形式。 conversion\r这里DFA最小化算法基本思想：等价的状态可以合并。对于等价而言，如果存在某个能区分状态 s 与 t 的字符串，则称 s 与 t 是可区分的；否则，称 s 与 t 是等价的。这里的字符串 x 区分状态 s 与 t，就是指如果分别从 s 与 t 出发，沿着标号为 x 的路径到达的两个状态中只有一个是接受状态，则称区分了状态 s 与 t，也就是s 与 t 不等价。 所以状态等价就是说，对于两个状态而言，在任意同一个字符的驱动下从当前状态进行转换，转换后的状态也是等价的。它可以用下面的公式进行表示： $$ \\begin{array}{l} s \\sim t \\iff \\forall a \\in \\Sigma. \\left( (s \\xrightarrow{a} s’) \\land (t \\xrightarrow{a} t’) \\implies (s’ \\sim t’) \\right)\\\\ s \\nsim t \\iff \\exists a \\in \\Sigma. \\left( (s \\xrightarrow{a} s’) \\land (t \\xrightarrow{a} t’) \\land (s’ \\nsim t’) \\right) \\end{array} $$ 基于该定义，不断合并等价的状态，直到无法合并为止。但是我们的定义是一个递归的，不知道一开始要从什么地方入手，同时我们又得到所有的接受状态并不是等价的。所以这里采取的办法就是划分，利用反例公式 $s \\nsim t \\Longleftrightarrow \\exists a \\in \\Sigma. ( s \\xrightarrow{a} s’ ) \\land ( t \\xrightarrow{a} t’ ) \\land ( s’ \\nsim t’ )$ 进行划分，而非合并。也就是首先根据接受状态与非接受状态必定不等价先划分为两类 $\\Pi = {F, S \\setminus F}$，然后在这个基础上根据上面的反例公式进行分裂，直至再也无法划分为止，这里就到达了不动点，之后就是将同一等价类里的状态合并。 划分步骤\r上面就是分裂的过程，在 $\\Pi_0$ 到 $\\Pi_1$ 的过程中，${A,B,C}$ 和 ${D}$ 在经过 b 进行传递的状态是不等价的，此时 D 转移到 E 上了，E 输出 $S \\setminus F$，所以不等价。之后的操作也是这样挑选字符看转移后的状态处于哪一个集合中，如果不在本身的集合，那么就是不等价，需要进行分裂。 合并\r上图就是最后的分裂之后再合并得到最小化 DFA 的转换。 注意\r需要注意处理\"死状态\"，也就是指向 ${ \\empty}$ 的一些没有画出来的边，在进行分裂时需要添加上，即${F, S \\setminus F, { \\empty }}$ 刚刚的算法不适用于 NFA 最小化，NFA最小化问题是 PSPACE-complete 的，复杂度很高。 ","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:4:3","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["compile"],"content":"DFA -\u003e 词法分析器\r这里对于词法分析器的构造，需要注意一下几个要求，然后按照之前使用 java 模拟的方法进行构造即可： 需要满足最前优先匹配和最长优先匹配，与此同时，因为需要生成词法分析器的特定目的，所以要保留各个 NFA 的接受状态的信息，表明匹配的是什么正则表达式 需要消除 “死状态”，避免词法分析器徒劳消耗输入流。如果加上死状态，那么词法分析器就有可能走这条路径，然后会进行一直匹配，最后匹配出的也是死状态，妨碍正确匹配。 进行模拟的过程如下图所示，和之前 java 模拟的过程一样。 模拟过程\r最后需要注意初始划分需要考虑不同的词法单元。之前的划分按照接受状态和非接受状态进行划分，但是这里需要写词法分析器，所以最后的接收状态对应了不同的词法单元，所以也需要进一步划分为不同的集合。 特定词法单元\r","date":"2024.10.31","objectID":"/blog/posts/compile/lexer-re-automata/:4:4","tags":["compile"],"title":"01 Lexer Re Automata","uri":"/blog/posts/compile/lexer-re-automata/"},{"categories":["programming"],"content":"这里是 python 使用技巧的记录，包括日常使用和数据之间的转换。 ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:0:0","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"基础知识\r","date":"2024.10.31","objectID":"/blog/posts/programming/python/:1:0","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"字符串\r\"\"\" \"\"\" 可以存储数行字符串 str = \"\"\"learn python the smart way 2nd edition hello word\"\"\" 使用 enumerate() 可以获得元素的序号 for idx, c in enumerate(str): print(idx, c) str.split 会把字符串划分为一个列表，依照空格进行划分 for word in str.split(): print(word) str.splitlines 会把字符串划分为一个列表，依照\"\\n\"进行划分 for line in str.splitlines(): if(line.startswith(\"hello\")): # startswith print(line) ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:1:1","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"函数\r接收不定长参数，*args 表示参数数目不定，可以看成一个元组，把第一个参数后面的参数当作元组中的元素 def add(x, *args): total = x for arg in args: total += arg return total 上面的函数不能使用关键词传入参数，要使用关键词 **kwargs，它表示参数数目不定，相当于一个字典，键和值对应于键值对 def add(x, **kwargs): total = x for arg, value in kwargs.items(): print(\"adding %s=%s\" % (arg,value)) total += value return total # 使用方法如下： def foo(*args, **kwargs): print(args, kwargs) add(1, 2, 3, 4) foo(2, 3, x='bar', z=10) map 方法生成序列，map(aFun, aSeq)，函数 aFun 应用到序列 aSeq 上的每一个元素上，返回一个列表，不管这个序列原来是什么类型。事实上，根据函数参数的多少，map 可以接受多组序列，将其对应的元素作为参数传入函数。 def square(a, b, c): return a**2 + b + c a = [1,2,3] b = (4, 5, 6) print(list(map(square, a, b, b))) ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:1:2","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"文件读写\rpython 提供安全的 with 来进行文件读写，当 with 块的内容结束后，Python 会自动调用它的 close 方法，确保读写的安全。 模式 描述 r 只读。该文件必须已存在。 r+ 可读可写。该文件必须已存在，写为追加在文件内容末尾。 rb 表示以二进制方式读取文件。该文件必须已存在。 w 只写。打开即默认创建一个新文件，如果文件已存在，则覆盖写（即文件内原始数据会被新写入的数据清空覆盖）。 w+ 写读。打开创建新文件并写入数据，如果文件已存在，则覆盖写。 wb 表示以二进制写方式打开，只能写文件， 如果文件不存在，创建该文件；如果文件已存在，则覆盖写。 a 追加写。若打开的是已有文件则直接对已有文件操作，若打开文件不存在则创建新文件，只能执行写（追加在后面），不能读。 a+ 追加读写。打开文件方式与写入方式和a一样，但是可以读。需注意的是你若刚用a+打开一个文件，一般不能直接读取，因为此时光标已经是文件末尾，除非你把光标移动到初始位置或任意非末尾的位置。 import os os.remove('newfile.txt') with open('newfile.txt','w+') as f: for i in range(30): x = 1.0 / (i - 10) f.write('hello world: ' + str(i) + '\\n') ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:1:3","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"其他\r通过 split 对 “,” 进行分割，使得一行可以输入多个值。 a, b = input().split(\",\") print(f\"a = {a}, b = {b}\") print 操作，默认每次输入后会换行，控制结尾的参数是 end，设置 end 把 “\\n” 替换成了 “//\"。同时它一次也可以输出多个内容，默认以空格分隔，这里控制分割的参数就是 sep，修改之后空格变成 “//\"。 print(\"data\", end=\"//\") print(\"Data\", \"whale\", sep=\"//\") ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:1:4","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"数据转换\r这里强制自己使用byte类型，这样可以统一python的不同数据类型 ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:2:0","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"AllToBytes\r字符串转化为 bytes，也可以直接在前面加 'b' 来转换 string = \"Hello World\" str_byte = bytes(string, 'utf-8') # -\u003e b'Hello World' 二进制字符串转化为 bytes hex_string = \"68 656c6c6f20776f726c64\" # 这里空格不会影响结果，但是需要是两个字符(68中间不能加空格)一组 hex_byte = bytes.fromhex(hex_string) # -\u003e b'hello world' # list(hex_byte) -\u003e [104, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100] 长整型转换为 bytes，小端序方式 long_i = 6788912312 # 下面就是计算转化为16进制的字节数 int.to_bytes(long_i, (long_i.bit_length() + 7) // 8, byteorder=\"little\") # -\u003e b'\\xb8\\x94\\xa6\\x94\\x01' 十六进制数转化为 bytes，小端序方式 hex_int = 0x12345678 int_byte = int.to_bytes(hex_int, 4, byteorder='little') # -\u003e b'xV4\\x12' 整型列表转化为 bytes list_num = [0x12, 0x34, 0x56, 0x78] list_byte = bytes(list_num) # -\u003e b'\\x124Vx' 字节列表转化为 bytes，先转化为字符串，再转化 str_list = ['1', 'C', 'E', 'B', 'E', '0', '8', '9', '7', '4', 'A', '9', '6', '1', 'C', '5'] # 先转str再转byte bytes(\"\".join(str_list), encoding=\"utf-8\") # -\u003e b'1CEBE08974A961C5' ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:2:1","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"AllToBytes\rbytes 转化为字符串 byte = b'Hello World' byte_str = str(byte, 'utf-8') # -\u003e 'Hello World' bytes 转化为十六进制字符串 byte = b'hello world' byte_hex = byte.hex() # -\u003e '68656c6c6f20776f726c64' bytes 转化为长整型，小端序 byte = b'\\xb8\\x94\\xa6\\x94\\x01' i = int.from_bytes(byte, byteorder='little') # -\u003e 6788912312 bytes 转化为十六进制整型 byte = b'xV4\\x12' int_num = int.from_bytes(byte, byteorder='little') # -\u003e 305419896 0x12345678 bytes 转化为整型列表 byte = b'\\x124Vx' list_num = list(byte) # -\u003e [18, 52, 86, 120] bytes 转化为字符串列表 byte = b'1CEBE08974A961C5' str_list = [str(byte[i:i + 2], 'utf-8') for i in range(0, len(byte), 2)] # -\u003e ['1C', 'EB', 'E0', '89', '74', 'A9', '61', 'C5'] ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:2:2","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"其余转换处理\r转化为字符串 chr(a) # 将 int 类型的 a 根据其 ascii 码转化为 str 字符 hex(a) # 将 int 类型的 a 转化为其十六进制 str 类型 str(a) # 将所有类型的 a 按照其本身转化为 str 类型 str = a.decode() # 将 bytes 类型的 a 转化为 str 类型 转化为整型 # a 为 k 进制数，使用 int 将 k 进制数的 a 转化为十进制数 # # int(a) 直接将字符 a 转化为 int 类型，此时 a 必须为数字字符，注意：不是转化 为ascii 码，而是转化为数字类型，即值不变，类型改变 int(a,k) # 将 str 类型的十六进制数 a 转化为 int 类型(这里十六进制需要加上0x) eval(a) # 将字符类型的 a 按其 ascii 码转化为 int 类型 ord(a) ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:2:3","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"数据处理\rstruct 模块可以解决 bytes 和其他二进制数据类型的转换。pack 函数把任意数据类型变成 bytes，unpack 把 bytes 变成相应的数据类型。这里的格式就是(format:str, v1, v2, …)，其中format对于后面的数据进行匹配，然后输出。 ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:3:0","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"pack\rpack 函数把任意数据类型变成 bytes struct.pack('\u003cII', 10240099, 1767863401) # -\u003e b'\\x00\\x9c@ci_ti' 如果符合ascii的标准，就直接转化为字符 ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:3:1","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"unpack\runpack 把 bytes 变成相应的数据类型 struct.unpack('\u003cI', b'it_i') # -\u003e (1767863401,) 这里只有一个符合 I 的规则，所以只有一个数据 ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:3:2","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"数据格式\rformat 参数就是上面使用的描述符，struct 利用它可以指定使用大端序还是小端序来解析或者生成数据 Character Byte order Size Alignment @ native native native，凑足4个字节 = native standard none \u003c little-endian standard none \u003e big-endian standard none ! network(=big-endian) standard none 数据格式，用于匹配当前字符的数据 Format C Type Python type Standard size x pad byte no value c char string of length 1 1 b signed char integer 1 B unsigned char integer 1 ? _Bool bool 1 h short integer 2 H unsigned short integer 2 i int integer 4 I unsigned int integer 4 l long integer 4 L unsigned long integer 4 q long long integer 8 Q unsigned long long integer 8 f float float 4 d double float 8 s char[] string 1 p char[] string 1 P void * integer 0 ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:3:3","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"ipython\r","date":"2024.10.31","objectID":"/blog/posts/programming/python/:4:0","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"特点\ripython 比原生的 python 解释器好用很多，它拥有高亮、补全、魔法函数等功能 Tab，可以自动补全，例如输入 imp 然后按 Tab 键，它会自动补齐 import 这个单词；如果再按 tab，提示所有可导入的模块，按方向键可以进行导航。 ?，在变量和函数后面添加 ? 会输出相关文档，?? 会打印源码（前提库是 python 写的） %hist 会显示用户输入命令的历史记录 %edit 会打开系统文本编辑器 %edit x-y 打开 Notepad 并写入指定范围内的命令 %history -n 会显示历史记录及对应的序号，然后通过 %edit x-y 命令对某一范围输入为脚本供后续使用 ","date":"2024.10.31","objectID":"/blog/posts/programming/python/:4:1","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":["programming"],"content":"使用相关\r对于 for 和 def 这些需要换行缩进的地方而言，换行会自动进行缩进处理。如果想删除这个缩进，直接使用 back 就可以了。如果需要保存或者运行，enter 之后不再输入内容，直接再按一次即可。 换行缩进使用\r","date":"2024.10.31","objectID":"/blog/posts/programming/python/:4:2","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":null,"content":"关于我\r在系统/软件安全领域学习的菜狗 有趣的事情总能吸引我，然后忘记正事 ","date":"2024.10.29","objectID":"/blog/about/:1:0","tags":null,"title":"About","uri":"/blog/about/"},{"categories":null,"content":"网址\rhttps://cztangt.github.io/blog/ https://github.com/czTangt ","date":"2024.10.29","objectID":"/blog/about/:2:0","tags":null,"title":"About","uri":"/blog/about/"},{"categories":null,"content":"联系方式\r渠道 信息 QQ Mjk3MzE3NDU5Mg== 邮箱 Y3ouVGFuZ3RAZ21haWwuY29t ","date":"2024.10.29","objectID":"/blog/about/:3:0","tags":null,"title":"About","uri":"/blog/about/"}]
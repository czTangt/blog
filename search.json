[{"categories":["android"],"content":"这里记录一下对于 UE4.27 SDK 的理解，同时补充完善 2024第九届腾讯游戏安全技术竞赛初赛安卓赛道 中的分析。源码在 SDKDumper。 注意事项 为了更好地理解 UE4.27 SDK 的获取，这里根据 UE4.27SDK-Dump 的内容对 UE4.27 源码进行分析，同时结合 frida-ue4dump 和 UE4Dumper 的代码对 2024第九届腾讯游戏安全技术竞赛初赛安卓赛道 的游戏样本进行分析。同时在分析的过程中穿插对于 libUE.so 内存布局的查看，以便应对魔改的情况。 基本结构 查看 UE4Dumper 的使用指南，可以发现 dump sdk 通常需要 libUE.so 中三个变量的地址 GWorld，GName 和 GUObjectArray（也被称为 GUobject）。 GWorld：GWorld 是一个全局变量，其类型为 UWorld**。它存储着指向当前活动游戏世界实例（UWorld*）的指针的地址。*GWorld 提供了访问当前世界（UWorld）的直接指针。UWorld 对象包含了游戏运行时的核心状态，如关卡、Actor 列表、玩家控制器、游戏模式、游戏状态、物理和导航系统等。它是游戏逻辑和对象交互的中心枢纽，是逆向工程中定位游戏状态和对象的起点。 GName：GName 是一个全局的 FNamePool 实例。FNamePool 管理着引擎中所有唯一字符串标识符（FName）的存储池。它采用大块内存分配策略，块内划分槽位存储字符串条目。GName 使得通过 FName 的索引或句柄快速查找和比较字符串成为可能，是解析对象类型名、函数名、属性名等字符串的关键。 GUObjectArray：GUObjectArray 是一个全局的 FUObjectArray 类型的实例。它是 UE 垃圾回收系统的核心组成部分，是所有 UObject 及其派生类实例的全局容器和注册表。通过遍历 GUObjectArray，可以枚举、跟踪和管理引擎中存在的所有 UObject 实例。 在获取这些变量的地址之后，就可以进行下一步了。这里三个变量的获取方法不再赘述，网上很多资料讲述如何获取。 Strings 获取 Strings UE 使用 FName 存储唯一且不可变的字符串标识符（如对象名称、属性名、资源路径等），它为每个字符串分配唯一数字 ID（如 123 对应 “Player”），将文本名称转化为高效标识符，并集中存储在全局池中，使得游戏对象（如 Actor）能通过 ID 快速检索名称。 这里字符串的存储依赖于 GName，上文说到 GName 是一个全局的 FNamePool 实例。那么可以在源码中查看 FNamePool 这个类，如下所示： 20250313173020 在这个类中，存在函数 TArray\u003cconst FNameEntry *\u003e DebugDump() const，它用于调试目的，负责收集名称池中所有字符串条目的指针。而有了这个指针，我们就可以获取所有的字符串了，因此这里可以通过实现这个函数来达成我们 dump Strings 的目的。 20250712183818 查看这个函数的实现，可以发现它创建输出容器 Out，然后预分配内存，之后通过 Entries.DebugDump(Out) 委托给内部的成员进行处理来获取字符串条目的指针。这里根据函数的实现可以发现，获取字符串条目指针的函数就是 Entries.DebugDump(Out)，因此这里了解实现这个函数就可以达成我们的目标，因此首先就需要了解相关的数据 Entries 的结构。 FNameEntryAllocator 这里翻阅 FNamePool 类的源码可以发现第一个成员变量就是 Entries，它的类型为 FNameEntryAllocator。 class FNamePool { private: FNameEntryAllocator Entries; ...... } 得到了 Entries，那么就可以看同文件下的 Entries.DebugDump(Out) 函数了，这个函数就是 FNameEntryAllocator 类的一个成员函数。但是若要进行后续的探索，需要先知道 FNameEntryAllocator 这个类的结构。 20250313183511 提取相关成员变量如下所示： static constexpr uint32 FNameMaxBlockBits = 13; static constexpr uint32 FNameBlockOffsetBits = 16; static constexpr uint32 FNameMaxBlocks = 1 \u003c\u003c FNameMaxBlockBits; static constexpr uint32 FNameBlockOffsets = 1 \u003c\u003c FNameBlockOffsetBits; class FNameEntryAllocator { public: enum { Stride = alignof(FNameEntry) }; enum { BlockSizeBytes = Stride * FNameBlockOffsets }; mutable FRWLock Lock; uint32 CurrentBlock = 0; uint32 CurrentByteCursor = 0; uint8* Blocks[FNameMaxBlocks] = {}; } 注意这个结构中存在成员变量 Blocks，它是 UE 中字符串存储的关键。FNamePool 由多个固定大小的内存块（Blocks）组成，每个块大小为 BlockSize = FNameStride * 65536。当当前块（CurrentBlock）用满后，会分配新块继续存储字符串。CurrentByteCursor 记录当前块已使用的字节数，最后一个块可能未完全使用。知道了这些就可以继续看 FNameEntryAllocator 的成员函数 DebugDump() 的代码。 同时还需要注意 mutable FRWLock Lock;，这里没有信息得知它的大小，但是这是对于 Android 平台，所以可以找到相关的定义，由此找到了 FRWLock 的定义。 20250313223325 然后顺藤摸瓜可以找到 FPThreadsRWLock 类型的定义。 20250313223419 这个 FPThreadsRWLock 只有一个成员变量，如下所示： class FPThreadsRWLock { private: pthread_rwlock_t Mutex; } 因此知道了 FRWLock 的大小就是 pthread_rwlock_t 的大小，而这个数据类型定义在 \u003cpthread.h\u003e 这个 Linux 库文件中，由此可以直接得到它的大小。它在 32 位安卓平台上此成员大小为 0x28，在 64 位安卓平台上是 0x38。 而对于 FNameEntryAllocator 中的 Stride = alignof(FNameEntry)，这里的 alignof() 用于 FNameEntry 的对齐要求。这里 FNameEntry 的对齐要求可以查看下面对于 FNameEntry 结构体的介绍，它是 2 字节，那么这里的 Stride 就是 2 了。于此同时，CurrentBlock 和 CurrentByteCursor 都是 uint32 类型，所以大小为 4 字节。而 Blocks 存储的则是 uint8* 类型的指针，它的大小在 64 为系统上为 8 字节。 DebugDump 得到的 DebugDump() 函数实现如下： 20250712194213 忽略一开始加读锁的操作，这里的代码就是遍历所有的内存块，也就是 Blocks 数组，然后采用 DebugDumpBlock() 解析单个块中的字符串条目。for 循环内部使用完整快的固定大小 BlockSizeBytes，而 for 循环外对于最后一个块，因为可能没有用完，所以使用当前块的实际填充大小 CurrentByteCursor。 DebugDumpBlock 然后找到 DebugDumpBlock() 函数进行分析： 20250713102617 这里 End 的获取就是从 Block 的开始加上 BlockSize，然后减去特定结构 FNameEntry 中的一个大小，因此这里要知道为什么要减去，需要知道 FNameEntry 的结构。 FNameEntry 20250313192458 这里需要知道在 Block 中，字符串的存储其实就是 FNameEntry 的存储，在 Block 中紧邻的就是一个个 FNameEntry 结构，它负责对于字符串的封装处理。然后再看这个 FNameEntry 结构，它有一个在编译运行时才有效的宏，所以可以忽略不管。因此它的成员变量如下所示，只有一个 FNameEntryHeader Header; 和一个联合体，它们都会参与字符串的存储。 enum { NAME_SIZE = 1024 }; struct FNameEntry { private: FNameEntryHeader Header; union { ANSICHAR AnsiName[NAME_SIZE]; WIDECHAR WideName[NAME_SIZE]; }; } 继续查看这里的 FNameEntryHeader 结构。 ","date":"2025.7.8","objectID":"/blog/posts/android/ue-structure/:0:0","tags":["android","game"],"title":"UE 结构分析","uri":"/blog/posts/android/ue-structure/"},{"categories":["android"],"content":"记录一下对于2024腾讯游戏安全竞赛安卓赛道的复现。 版本与结构 按照初赛的逻辑，首先查看这个游戏的 ue 版本，然后发现和初赛一样，在 libUE4.so 中发现了 ++UE4+Release-4.27，确定是 4.27 版本，不过这里是 32 位架构的程序。然后就是按照常规流程来寻找 GWorld，GUObjectArray，GName 三件套。对于前面两个而言，就是通过 SeamlessTravel FlushLevelStreaming 和 CloseDisregardForGC 进行字符串交叉引用即可找到。然后由下图得到了 GWorld 为 0x4F5C0D0，GUObjectArray 为 0x4E533AC。 20250327214918 20250327220856 不过这里按照常规流程却不好解析 GName 这个关键结构。这里首先搜索字符串 ByteProperty，然后排除上面的宽字符串（因为没有交叉引用），找到最后一个字符串找到其交叉引用。 20250327221140 然后这里就是不同之处了，这里往下翻可以看见是 None，IntProperty 等字符串，但是未识别成函数，按 p 也没有效果。因此查看这个 loc_1C2E26C 发现存在两个交叉引用，其中一个还是自己引用自己，所以跳转到第一个引用的地方。 20250327221728 之后发现 loc_1C2E0B0 还是没有识别为函数，同时是最后跳转到上面的 loc_1C2E26C。查看这个小的代码片段没发现什么关键的地方，同时查看其交叉引用发现有很多函数调用这个地方，因此继续往上查看这个地方的调用点。 20250327222041 随便选了交叉引用中的一个函数，发现这里就和之前找到 GName 的汇编代码很相近了。这里 R0 就是传入的 this 指针，也就是 GName，因此 GName 为 0x4E2EC00。 20250327222352 dumpSDK 获取上述结构偏移之后就准备 dumpSDK 了，但是这里使用 UE4Dumper 发现报错，而且解析的对象数量也不对，由此怀疑更改了 UE 相关结构。 20250330200342 因此这里就需要动态调试获取魔改的偏移，这里结合UE 结构分析的内容分析结构获取偏移，然后修改 SDKDumper 中的偏移来 dumpSDK。 dump Strings 首先在手机中以 root 权限启动 ceserver_arm64，然后转发端口 52736，这样就可以使用 Cheat Engine 了。之后在 CE 中手动添加 GName 的地址 libUE4.so + 0x4E2EC00，然后 Ctrl + B 查看该地址的内存布局。这里由于是 32 位的程序，所以采用 4 字节 HEX 的方式查看。 查看该内存布局，按照正常的结构，前面的结构应该是 FNamePool 中的第一个结构 FNameEntryAllocator。 class FNamePool { private: FNameEntryAllocator Entries; ...... } 它一开始就是 FRWLock Lock;，在 32 位程序上占据 0x28 字节。因此剔除这 0x28 字节的数据，发现第一个 4 字节数据为 0xB，那么这个应该就是 uint32 CurrentBlock 了。同时在原本结构中，后面为 uint32 CurrentByteCursor 和 uint8* Blocks[FNameMaxBlocks]，那么红框中的指针就是 Blocks 的内容了。 static constexpr uint32 FNameMaxBlockBits = 13; static constexpr uint32 FNameBlockOffsetBits = 16; static constexpr uint32 FNameMaxBlocks = 1 \u003c\u003c FNameMaxBlockBits; static constexpr uint32 FNameBlockOffsets = 1 \u003c\u003c FNameBlockOffsetBits; class FNameEntryAllocator { public: enum { Stride = alignof(FNameEntry) }; enum { BlockSizeBytes = Stride * FNameBlockOffsets }; mutable FRWLock Lock; uint32 CurrentBlock = 0; uint32 CurrentByteCursor = 0; uint8* Blocks[FNameMaxBlocks] = {}; } 20250808101826 之后按空格继续查看这些指针指向的内存布局，发现是一个个字符串，那么就确定这些都是 Block 了。 20250808102825 这里按 Back 回退到原本的内存布局，刚好有（0xB + 1 = 0xC）个指针，它和 CurrentBlock 对应，那么直接修改相关偏移就可以 dump Strings。然后结合 dump 结果可以发现推测是正确的，这里的结构没有魔改。 dump SDK 对象获取 TUObjectArray 首先根据 GUObjectArray 来获取 FUObjectArray 结构的内存布局，前面 0x10 没有帮助，然后后面紧接着就是 TUObjectArray ObjObjects;。 class COREUOBJECT_API FUObjectArray { private: //typedef TStaticIndirectArrayThreadSafeRead\u003cUObjectBase, 8 * 1024 * 1024 /* Max 8M UObjects */, 16384 /* allocated in 64K/128K chunks */ \u003e TUObjectArray; typedef FChunkedFixedUObjectArray TUObjectArray; // note these variables are left with the Obj prefix so they can be related to the historical GObj versions /** First index into objects array taken into account for GC. */ int32 ObjFirstGCIndex; /** Index pointing to last object created in range disregarded for GC. */ int32 ObjLastNonGCIndex; /** Maximum number of objects in the disregard for GC Pool */ int32 MaxObjectsNotConsideredByGC; /** If true this is the intial load and we should load objects int the disregarded for GC range. */ bool OpenForDisregardForGC; /** Array of all live objects. */ TUObjectArray ObjObjects; ...... } 之后查看 TUObjectArray 结构，可以看到红框中的第一个 4 字节元素就是地址指针，它应该就是对应着 Objects。然后继续往后看，可以看到这些数值和类型都很对应，所以猜测这里没有进行魔改，只不过因为是 32 位程序，所以需要修改偏移。那么就知道这里 0x3C09 对应着 NumElements，偏移为 0xC。而 MaxChunks = 3，NumChunks = 1。 class FChunkedFixedUObjectArray { enum { NumElementsPerChunk = 64 * 1024, }; /** Master table to chunks of pointers **/ FUObjectItem** Objects; /** If requested, a contiguous memory where all objects are allocated **/ FUObjectItem* PreAllocatedObjects; /** Maximum number of elements **/ int32 MaxElements; /** Number of elements we currently have **/ int32 NumElements; /** Maximum number of chunks **/ int32 MaxChunks; /** Number of chunks we currently have **/ int32 NumChunks; } 20250808144343 这里确定了 0xB415B4FF0 这个地址指向了 Objects，因此按空格查看该地址的内存布局。因为上面 Objects 的类型为 FUObjectItem** Objects;，所以这里看到的不是 FUObjectItem 类型，而是一个个 Chunk(FUObjectItem *)。查看这里红","date":"2025.3.27","objectID":"/blog/posts/android/2024-tencent-gamesec-final/:0:0","tags":["android","game"],"title":"2024腾讯游戏安全竞赛决赛","uri":"/blog/posts/android/2024-tencent-gamesec-final/"},{"categories":["android"],"content":"记录一下对于2024腾讯游戏安全竞赛安卓赛道的复现。 UE 基础知识 在进行逆向前，首先需要知道一些 UE 的基本知识，不然后面会越来越混乱。这里可以从 虚幻引擎是什么 这篇文章了解到什么是虚幻引擎。同时这篇文章也罗列了 UE 结构图，可以从这些继承关系图中查看 UE 相关的重要结构，下面就是对于其中的重要结构和一些概念进行讲解。 相关概念 蓝图 虚幻引擎中的 蓝图可视化脚本 系统是一类完整的游戏性脚本系统，此系统的基础概念是使用基于节点的界面在虚幻编辑器中创建游戏性元素。它基于节点的可视化编程工具，通过逻辑节点图实现游戏逻辑，无需传统代码编写。 常见基类 Uobject UObject 是虚幻引擎中的核心基础类，大部分其他游戏对象和资源类都直接或间接地继承自它。它作为虚幻引擎的基石，提供了多项关键功能，包括内存管理、序列化、反射、垃圾回收以及元数据支持。在虚幻引擎中，UObject 类的实例通常被称为 对象，它们构成了游戏世界及其相关资源的基本单元。它的作用如下： 内存管理：UObject 提供了强大的内存管理机制，确保在创建和销毁对象时正确分配和释放内存。它引入了一套自动化的内存清理系统，使得对象可以在不再被引用时自动释放所占用的资源，自动进行垃圾回收，从而有效防止内存泄漏。这种机制不仅简化了开发者的任务，还提高了应用的稳定性和性能。 序列化与反序列化：UObject 支持将对象的状态保存到磁盘文件（如关卡、材质、模型等资源），并在需要时从这些文件中恢复。这一特性使得虚幻引擎能够高效地加载和保存游戏内容，确保游戏状态可以持久化，并且可以在不同的会话之间保持一致。此外，序列化能力也使得跨平台的数据交换变得更加简单。 反射：UObject 实现了反射机制，允许程序在运行时动态地检查和操作对象的结构和行为。尽管 C++ 本身并不具备内置的反射功能，但虚幻引擎通过 UObject 提供了这一强大特性。开发者可以通过反射访问对象的属性和方法，这对于编辑器功能（如属性面板、蓝图编辑）和运行时调试非常有用。反射机制还为自动化工具和脚本提供了便利，增强了开发效率。 Actor Actor 指 AActor 基类，它是一个核心类，作为游戏世界内所有可交互对象的基础。任何可以在关卡中放置或动态生成的对象，几乎都是从 AActor 类派生而来。这包括但不限于角色、道具、特效、静态和动态物体等。它作为基类，为所有继承自它的类提供了一套通用的功能和接口。它不仅代表了游戏中可见的实体，还包含了控制这些实体行为的逻辑。每个 AActor 都可以拥有多个组件（如渲染组件、碰撞组件、音频组件等），这些组件赋予 AActor 特定的行为和特性。通过组合不同的组件，开发者可以构建出复杂且功能丰富的游戏元素。Actor 最主要的能力就是 能被挂载组件，只有需要挂载组件时，才应该继承自 Actor 类。 在虚幻引擎中，所有的 AActor 实例都由 ULevel 类管理，存储在一个名为 Actors 的成员变量中，该成员是一个 TArray 容器（TArray\u003cAActor*\u003e Actors;），包含着当前关卡中所有的 AActor 对象。那么就可以通过遍历这个数组来访问和操作关卡内的所有 AActor。此外，虚幻引擎还提供了多种工具和函数，使得查找特定类型的 AActor 或根据条件筛选 AActor 变得更加容易。例如，可以使用 GetAllActorsOfClass 函数来获取指定类的所有实例，或者使用 TActorIterator 来遍历符合特定条件的 AActor。 Pawn APawn 派生自 AActor，它作为玩家或AI控制的代理实体（如角色、载具）。它代表国际象棋中的棋子，提供了被 操作 的特性。它能被后面要提到的 Controller 所操纵。 Character ACharacter 派生自 APawn，它提供了一个特殊组件：Character Movement。这个组件提供了一个基础的，基于胶囊体的角色移动功能。包括移动和跳跃，还能扩展出蹲伏和爬行等。所以如果游戏角色是人类的话，特别适合使用 Character 类。简单而言，对于需要移动的角色，都适用于 Character 类的逻辑。 Controller AController 是基类，Controller 是用来操控 Pawn/Character 的人。可以把它看作是下棋的棋手，或者提线木偶的操作者。它既可以是玩家，比如 Player Controller，通过键盘或者手柄输入来操作游戏角色，也可以是电脑 AI，比如 AI Controller 来操作游戏中的 NPC 和怪物等角色。它通过 Possess 来接管并控制一个角色，然后通过 UnPossess 来结束接管一个角色。 Game Mode 这里指 AGameModeBase 基类，它是游戏规则与流程管理者，定义了游戏是如何被执行的，游戏规则，游戏流程以及其他方面的内容。它仅在服务端存在，客户端无法直接访问。核心职责就是定义玩家加入流程（如重生规则、队伍分配）；设置默认 Pawn 类、PlayerController 类、HUD 类；实现胜利/失败条件判定逻辑。 相关结构 UEngine UEngine 作为虚幻引擎的基石，以抽象基类的形式通过 UCLASS(abstract) 宏定义，承载着引擎运行时全局状态管理的核心职责。其派生类体系严格遵循环境隔离原则，针对游戏运行时与编辑器环境分别派生出 UGameEngine 与 UEditorEngine 两个子类。这两个子类在内存管理、对象生命周期和系统交互层面存在显著差异，共同构建起引擎的多环境适应能力。 UGameEngine：当引擎以独立游戏模式运行时，UGameEngine 将成为主导实例。此子类的核心使命是维护一个完整且封闭的游戏会话环境。在引擎初始化阶段（通常通过 UGameEngine::Init() 方法触发），其实例会创建唯一的 UGameInstance 对象。该对象作为游戏会话的根容器，不仅承载玩家控制器、在线会话接口、关卡流送系统等全局组件，还通过 FWorldContext 机制管理游戏世界的上下文信息。例如，当游戏支持分屏合作或多窗口渲染时，每个视口会关联独立的 FWorldContext，但这些上下文最终仍由 UGameEngine 统一协调。 UEditorEngine：当引擎运行于编辑器模式时，UEditorEngine 将取代其基类成为主导实例。这一子类展现出高度复杂的双重特性：既要作为资源编辑的管理平台，又要承担游戏逻辑的实时预览功能。其内部通过 FPlayInEditorSessionInfo 等专用结构体实现角色切换，使得开发者能在同一进程中无缝切换编辑态与运行态。 UGameInstance UGameInstance 在 Unreal Engine 中扮演着非常重要的角色，它是一个运行游戏的高级管理器，负责存储和管理整个游戏会话期间的状态和数据。 生命周期管理：UGameInstance 的实例通常在游戏启动时创建，并在整个游戏会话期间持续存在，直到游戏结束。在编辑器模式下，它的生命周期从编辑器打开开始，到编辑器关闭结束。 存储游戏信息：UGameInstance 保存了一个指向 FWorldContext 的指针。FWorldContext 是一个包含当前世界（UWorld）上下文信息的结构体，它允许 UGameInstance 访问和管理当前游戏世界的状态。同时它还存储了游戏中所有的本地玩家（Local Player）、游戏会话（Game Session）等信息。这些信息对于游戏的运行至关重要，需要在整个游戏会话中持续跟踪和管理。 在游戏过程中，当玩家从一个 Level 切换到另一个 Level 时，当前 Level 的数据通常会被释放，包括管理该 Level 的 UWorld 对象。由于 UGameInstance 的生命周期不依赖于单个 Level，它非常适合用于存储那些需要跨 Level 持久存在或独立于 Level 的数据和功能。 FWorldContent FWorldContext 是一个核心类，用于管理游戏世界（UWorld）的生命周期和上下文。 在 UE4 中，特别是在开发过程中，可能会同时存在多个世界。FWorldContext 提供了一种机制来管理和跟踪这些世界的状态。与许多其他 UE4 类不同，FWorldContext 类型以 F 开头，表名它不是从 UObject 或 AActor 派生的。这意味着它不遵循UE4的垃圾回收机制，并且没有 Serialize 和 Deserialize 函数，因此它通常用于管理那些不通过 UE4 的序列化机制存储的数据。 FWorldContext 是 UEngine 用来管理世界生成、销毁、切换的类。它包含对当前世界（UWorld* ThisCurrentWorld）的引用和一个指向拥有它的 UGameInstance 的指针（UGameInstance* OwningGameInstance）。 在独立运行的游戏中，通常只有一个 Game WorldContext。然而，在编辑器模式下，可能存在多个 FWorldContext 实例，例如： Editor Context：用于编辑器视图的世界上下文。 PIE WorldContext：用于实时预览（Play In Editor）的世界上下文。 Preview World：用于编辑器视图中尚未运行的游戏场景的预览世界。 当从一个世界切换到另一个世","date":"2025.3.3","objectID":"/blog/posts/android/2024-tencent-gamesec-prelim/:0:0","tags":["android","game"],"title":"2024腾讯游戏安全竞赛初赛","uri":"/blog/posts/android/2024-tencent-gamesec-prelim/"},{"categories":["android"],"content":"记录一下对于安卓壳的学习 学习资源 加壳与脱壳\u0026刷机 App 的类加载器 下面代码用于获取类加载器的层次结构，同时加载调用一个 dex 文件中的某个函数。这里通过 classLoadingOrder() 可以看出当前的类加载器层次结构，可以看到当前的类加载器为 PathClassLoader，父类加载器为 BootClassLoader，同时只有两层结构。而通过 loadDex() 则可以加载一个普通普通的函数，注意这个函数不能存在生命周期，即不是 Activity，否则就会加载失败。而加载一个 Activity 函数则是下面 壳的动态加载与修复 涉及的内容。 package com.cztang.shell; import android.content.Context; import android.os.Environment; import android.util.Log; import androidx.annotation.NonNull; import java.io.File; import java.lang.reflect.InvocationTargetException; import java.lang.reflect.Method; import dalvik.system.DexClassLoader; public class LoadCommonClass { private static final String TAG = \"loadClass\"; private final MainActivity mainActivity; // 构造函数，初始化主活动引用 public LoadCommonClass(MainActivity mainActivity) { this.mainActivity = mainActivity; } /** * 加载指定的 dex 文件并调用其中的 test01 类的 testFunc 方法。 * * @param filename 外部 dex 文件的文件名 */ public void loadDex(String filename) { File dexFile = new File(Environment.getExternalStorageDirectory(), filename); Log.i(TAG, \"dexFile: \" + dexFile.getAbsolutePath()); // 获取 DexClassLoader 实例 DexClassLoader dexClassLoader = getDexClassLoader(dexFile.getPath()); // 尝试从 dex 文件中加载指定的类 Class\u003c?\u003e loadClass = null; try { loadClass = dexClassLoader.loadClass(\"com.cztang.test.test01\"); Log.i(TAG, \"loadClass test01 success\"); } catch (ClassNotFoundException e) { Log.e(TAG, \"Class test01 not found: \", e); return; // 类未找到，直接返回 } // 获取并反射调用 test01 类中的 testFunc 方法 try { Method testFuncMethod = loadClass.getDeclaredMethod(\"testFunc\"); Object obj = loadClass.newInstance(); // 需要先创建一个 test01 的实例 testFuncMethod.invoke(obj); Log.i(TAG, \"testFunc method invoked successfully.\"); } catch (NoSuchMethodException | IllegalAccessException | InvocationTargetException | InstantiationException e) { Log.e(TAG, \"Failed to invoke testFunc method: \", e); } } /** * 创建一个 DexClassLoader，用于加载指定的 dex 文件。 * * @param dexfilepath 外部 dex 文件路径 * @return DexClassLoader 实例 */ private @NonNull DexClassLoader getDexClassLoader(String dexfilepath) { Context context = mainActivity.getApplicationContext(); // 创建优化文件目录和库文件目录 File optFile = context.getDir(\"opt_dex\", 0); File libFile = context.getDir(\"lib_path\", 0); // 获取当前的 ClassLoader ClassLoader currentClassLoader = MainActivity.class.getClassLoader(); // 实例化 DexClassLoader，用于加载 dex 文件 return new DexClassLoader(dexfilepath, optFile.getAbsolutePath(), libFile.getAbsolutePath(), currentClassLoader); } /** * 打印当前类加载器及其父类加载器的层次结构，直到根类加载器。 */ public void classLoadingOrder() { try { // 获取当前 MainActivity 类的类加载器 ClassLoader thisClassLoader = MainActivity.class.getClassLoader(); // 获取当前类加载器的父类加载器 assert thisClassLoader != null; ClassLoader parentClassLoader = thisClassLoader.getParent(); // 遍历类加载器的父级加载器，直到找到根类加载器 while (parentClassLoader != null) { Log.i(TAG, \"this: \" + thisClassLoader + \" - - - parent: \" + parentClassLoader); // 准备下一次循环所需的数据 thisClassLoader = parentClassLoader; parentClassLoader = parentClassLoader.getParent(); } Log.i(TAG, \"root: \" + thisClassLoader); } catch (Exception e) { Log.e(TAG, \"Error during class loader traversal.\", e); } } } 下面就是上面加载的普通函数了，直接使用上面的代码就可以调用 testFunc() 函数，输出日志。这里注意下面是另外一个 app 的类，而由于 android sdk 的限制，只能生成多个 classes.dex 文件。而上述代码使用的是 classes3.dex 这个文件，自己写的相关类都在这个 dex 文件中。 package com.cztang.test; import android.util.Log; public class test01 { public void testFunc() { Log.i(\"loadClass\", \"I am from test01.testFunc\"); } } 壳的动态加载与修复 这里记录壳中 Activity 类的动态加载和修复过程。之所以需要修复，是因为我们一直通过 DexClassLoader 动态加载类，但它本身没有生命周期管理能力。之前的方法运行时无需生命周期支持，因为它只是一个普通的 Java 类方法，运行时只有一个界面。然而，当我们修改类使其继承 AppCompatActivity 或 Activity 后，它就变成了 Android 的一个组件类，需要完整的生命周期支持。因此，我们需要额外的机制来提供生命周期管理，从而产生了两种解决方法。 同时，在利用上面代码运行下面的 testActivity 类时，发现报错为 Failed to invoke method，查看错误栈信息后发现是 NoSuchMethodException，表明目标方法不存在。这说明 DexClassLoader 无法识别这种形式的 Dex 文件，导致动态加载失败。 package com.cztang.test; import android.app.Activity; import android.os.Bundle; import android.util.Log; // 这里采用 AppCompatActivity 的话，第二种修复方式不可用，会报错 java.lang.ClassNotFoundException: Didn't find class \"com.cztang.te","date":"2025.2.23","objectID":"/blog/posts/android/shell/:0:0","tags":["android","reverse"],"title":"Shell","uri":"/blog/posts/android/shell/"},{"categories":["android"],"content":"记录安卓逆向的相关操作。 Android 命令 这里对于基于 Linux 的 Android 系统命令进行简单罗列。 基础命令 ps 命令可输出当前设备正在运行的进程。在 Android 8 之后，ps 命令只能打印出当前进程，需要加上 -e 参数才能打印出全部的进程。 ps -ef | grep \u003cpackage-infomation\u003e netstat 该命令输出 App 连接的 IP、端口、协议等网络相关信息，通常使用的参数组合为 -alpe。netstat -alpe 用于查看所有 sockets 连接的IP和端口以及相应的进程名和 pid。 netstat -alpe | grep \u003cpackage-infomation\u003e lsof 该命令可以用于查看对应进程打开的文件 lsof -p \u003cpid\u003e -l | grep \u003cfile_name\u003e 手机信息查看 通过查看手机信息来决定使用什么版本的工具和程序。 cat /proc/cpuinfo # 查看手机架构 getprop ro.product.cpu.abi # 查看cpu处理器位数 包信息查看 # 获取当前活动（处于前台）的系统服务信息然后过滤出正在活动的任务 dumpsys activity top | grep TASK # 查看包的信息 dumpsys package \u003cpackage-name\u003e # 查看包含 /data 的虚拟内存区域的详细信息，即查看包含 /data 名称的进程的相关信息。这里就是找到对应虚拟内存区域中的所有文件，它可以寻找包名所在文件的目录 cat /proc/\u003cpid\u003e/maps | grep /data 其他 am 命令主要用于启动或停止服务、发送广播、启动 Activity 等。 # 以 Debug 模式启动 App am start-activity -D -N \u003cpackage-name\u003e/.\u003cclass-name\u003e # 启动指定的 Activity # 按 AndroidManifest 的路径（com.kbtx.redpack_simple.FlagActivity），打开指定控件，这里就是类的路径前面为包的路径，所以直接用 \".\"替代，不一致的情况下需要写全。 am start -n com.kbtx.redpack_simple/.FlagActivity am start -n owasp.mstg.uncrackable2/sg.vantagepoint.uncrackable2.MainActivity # 监视设备上的 Activity Manager 输出 am monitor # 结束进程，这里也可以通过 kill -9 \u003cpid\u003e 使用信号杀死，但是可能会出现进程重启杀不掉的情况 am force-stop \u003cpackage-name\u003e pm 它是 Android 中 packageManager 的命令行，是用于管理 package 的命令。 # 列出所有的包名 pm list package # 寻找包名所在文件的目录 pm path \u003cpackage-name\u003e logcat 可以查看日志的输出 # 查看日志输出 logcat | grep Adb 相关 Adb 原理 Adb（Android Debug Bridge）是 Android 开发工具链中的一个重要组件，属于 Android Open Source Project（AOSP）的一部分。它主要用于在开发环境中实现 PC 端与 Android 设备（包括物理设备和模拟器）之间的通信，支持多种设备操作，是连接 PC 端开发环境与移动终端的桥梁。 Adb 采用 C/S（客户端/服务器）架构，主要由以下三个组件构成： Client：运行在 PC 端，主要用于发送命令。用户可以通过命令行工具（如 adb）调用客户端，执行如文件推送（push）、应用安装（install）等操作。客户端会解析这些命令，进行预处理，并将处理后的指令或数据通过网络发送给服务器端。 Server：作为后台进程运行在 PC 端。负责检测 USB 端口，感知设备的连接和拔除，以及模拟器实例的启动或停止。它会维护一张设备状态表，为每个设备标记状态，如 offline（离线）、bootloader（引导程序模式）、recovery（恢复模式）或 online（在线）。同时将客户端的请求通过 USB 或 TCP/IP 方式发送到对应的设备上的 adbd（守护进程）。 Daemon：存在于 Android 设备上，由设备的 init 进程启动，系统开机时自动运行。处理来自服务器端的命令请求，执行相关命令，并将结果返回给服务器端。 20240304195530684 工作原理 客户端启动：当用户在 PC 终端中输入 Adb 命令时，客户端会启动。 服务端检测与启动： 客户端会检查 PC 后台是否已运行 Adb 服务器。如果未运行，客户端会自动启动服务器进程。 服务器启动后，会绑定到本地 TCP 端口 5037，并监听来自客户端的命令。 设备连接建立： 服务器会尝试与所有连接的设备建立连接。对于通过 USB 连接的设备，服务器会通过 USB 接口与设备上的 adbd 守护进程通信。 对于模拟器，服务器会扫描本地 TCP 端口范围 5555-5585（前 16 个模拟器使用奇数号端口进行 Adb 通信，偶数号端口用于控制台连接）。例如： 模拟器 1：控制台端口 5554，Adb 端口 5555。 模拟器 2：控制台端口 5556，Adb 端口 5557。 通信过程： 客户端将命令发送到服务器（端口 5037）。 服务器根据设备状态表，将命令转发到对应的设备上的 adbd。 adbd 执行命令并将结果返回给服务器，服务器再将结果返回给客户端。 202403042042159 使用归纳 安卓模拟器 通常认为，开启模拟器的 USB 调试后，使用 adb connect 127.0.0.1:port 命令进行连接，然后通过 adb devices 查看设备列表，会看到以 \u003cip:port\u003e 格式显示的设备。然而，结合真机调试和模拟器测试，可以发现： 真机：使用 USB 连接时，插入 USB 线并开启 USB 调试后，设备会被 Adb 服务器识别，adb devices 显示的设备名称为设备的 序列号。 模拟器：通常不使用 USB 调试，而是通过 TCP/IP 连接。直接使用 adb connect 命令连接特定端口即可发现设备。在 NAT 模式下，模拟器必须有 WIFI 连接。模拟器通过 WIFI 连接到主机网卡时，会绑定本地端口，但 Adb 服务器可能无法自动发现模拟器（尤其是模拟器未使用默认端口范围 5555-5585），因此需要手动使用 adb connect 命令进行绑定。 多设备下的 Adb 在多设备环境中（例如多个模拟器或真机），直接使用 adb shell 等命令可能会因无法确定目标设备而报错。此时需要通过 -s \u003c名称\u003e 参数指定设备进行调试。例如： adb -s 127.0.0.1:21503 shell 在使用 adb 和 frida-ps 进行设备检测时，可能会发现识别出的信息不同。这里连接真机喝逍遥模拟器，前者通过 USB 连接，后者使用 nat 连接 WIFI。以下是相关工具的参数说明： adb --help global options: -a listen on all network interfaces, not just localhost -d use USB device (error if multiple devices connected) -e use TCP/IP device (error if multiple TCP/IP devices available) -s SERIAL use device with given serial (overrides $ANDROID_SERIAL) frida-ps --help Options: -U, --usb connect to USB device -D ID, --device=ID connect to device with the given ID objection --help Options: -N, --network Connect using a network connection instead of USB. -h, --host TEXT [default: 127.0.0.1] -p, --port INTEGER [default: 27042] -ah, --api-host TEXT [default: 127.0.0.1] -ap, --api-port INTEGER [default: 8888] -g, --gadget TEXT Name of the Frida Gadget/Process to connect to. [default: Gadget] -S, --serial TEXT A device serial to connect to. 尝试之后可以得到下面的结论： 使用 Adb 的 -d 选项可以匹配 USB 连接的真机，而 -e 选项可以连接模拟器。 使用 frida-ps 的 -U 选项连接的却是模拟器，这表明二者的检测机制不同。 对于 frida 和 frida-ps，可以使用 -D ID 参数，通过 adb devices 中显示的设备 I","date":"2025.1.31","objectID":"/blog/posts/android/android-reverse/:0:0","tags":["reverse","android"],"title":"Android Reverse","uri":"/blog/posts/android/android-reverse/"},{"categories":["config"],"content":"记录一下 docker 的安装和使用 Docker 安装 这里就是根据 Win11 安装 Docker Desktop 进行配置，安装了 wsl2 和 docker，然后进行了位置的迁移。不过这里注意，新版的 docker 只有 docker-desktop 了，所以文章中对于 docker-desktop-data 的操作可以不用管，具体可以看 官方网址。 同时在上面进行配置后，docker-desktop 会形成一个 ext4.vhdx 文件，表示存储的硬盘。但是之后在 Docker Desktop 的 Resources 中更换 Disk image 位置时，会将之前的 ext4.vhdx 文件重新组织到 DockerDesktopWSL/main 目录下，然后在 DockerDesktopWSL/disk 目录下生成一个 docker_data.vhdx 文件。猜测这里不进行迁移也行，修改这里就会自己进行位置迁移。 20250120220914 Docker 镜像 由于 Docker 的镜像拉去被墙了，所以需要别的方法来获取，这里就是根据 Docker 停服了怎么办 来进行的操作。在 Docker Desktop 的 Docker Engine 中进行修改，不过随时有可能没了。 同时可以自己写 Dockerfile 来创建镜像。下面就是通过 Dockerfile 来构建一个 docker 镜像的例子，这里 RUN 属性只在创建容器时才会进行调用，而 CMD 属性则在使用容器时就会被调用。 # Use an official Python runtime as a parent image FROM python:3.9 # Set the working directory in the container WORKDIR /app # Install curl or wget, if not already available RUN apt-get update \u0026\u0026 apt-get install -y curl # Copy the current directory contents into the container at /usr/src/app COPY . /app # Install any needed packages specified in requirements.txt RUN pip install --no-cache-dir -r /app/requirements.txt # Download and extract the Linux kernel source RUN curl -L https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.14.tar.xz | tar -xJ # Run bash when the container launches CMD [\"/bin/bash\"] Docker 使用 镜像操作 docker pull \u003c镜像名\u003e:\u003c标签\u003e：拉取镜像 docker images：列出本地所有的 Docker 镜像 docker rmi \u003c镜像ID或镜像名\u003e：删除本地的一个镜像 容器操作 docker run [选项] \u003c镜像名\u003e:\u003c标签\u003e：从镜像启动一个容器 -i：交互模式 -t：分配一个伪终端 -d：后台运行 -p：端口映射（如 -p 80:80） -v：挂载卷（如 -v /host/path:/container/path） docker ps：列出当前正在运行的容器 docker ps -a：列出所有容器（包括已停止的） docker stop \u003c容器ID或容器名\u003e：停止一个运行中的容器 docker start \u003c容器ID或容器名\u003e：启动一个已停止的容器 docker rm \u003c容器ID或容器名\u003e：删除一个已停止的容器 docker exec -it \u003c容器ID或容器名\u003e /bin/bash：进入一个正在运行的容器并启动交互式终端 Docker-Compose 功能定位 Docker 命令：Docker 命令主要用于管理单个容器的生命周期，例如启动、停止、删除容器等。它适合简单的单容器场景，灵活性高，但需要手动管理容器之间的依赖关系和配置。 Docker Compose：Docker Compose 用于定义和管理多容器应用程序，适合复杂的应用场景（如微服务架构）。它通过一个 docker-compose.yml 文件集中管理服务、网络、卷等，简化了多容器的配置和部署。 简单而言，docker 适合管理单一容器，而 docker-compose 适合管理多容器，其包含容器的依赖、网络、数据卷、环境变量等配置管理。 使用方式 Docker 命令 需要手动编写和执行命令。例如，启动一个 Nginx 容器： docker run -d --name web -p 80:80 nginx 对于多容器场景 需要分别启动每个容器，并手动处理它们之间的依赖关系。例如，如果容器 A 依赖容器 B，必须先启动容器 B，再启动容器 A； 需要手动创建和管理网络，并将容器连接到网络； 手动创建和管理数据卷，并将其挂载到容器； 需要手动在命令行中指定环境变量。 Docker Compose 使用 docker-compose.yml 文件定义服务，然后在该文件目录下使用 docker-compose up 就可以启动了。举例如下： # 指定 Docker Compose 文件的版本为 3.1，在较新的 docker 版本中不再需要了，可以删除 # version: '3.1' # 定义服务（容器） services: # 定义名为 db 的服务 db: image: mysql # 使用 MySQL 官方镜像 # 设置环境变量 environment: MYSQL_ROOT_PASSWORD: example # 设置 MySQL 的 root 用户密码为 example # 定义数据卷 volumes: - mydata:/var/lib/mysql # 将名为 mydata 的数据卷挂载到容器的 /var/lib/mysql 目录，用于持久化 MySQL 数据 # 健康检查配置 healthcheck: # 使用 mysqladmin ping 命令检查 MySQL 是否健康 test: [\"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\"] interval: 5s # 每 5 秒检查一次 timeout: 10s # 每次检查的超时时间为 10 秒 retries: 5 # 重试 5 次后标记为不健康 # 定义网络 networks: - mynet # 将 db 服务连接到名为 mynet 的网络 # 定义名为 web 的服务 web: image: nginx # 使用 Nginx 官方镜像 # 定义依赖关系，web 服务依赖于 db 服务 depends_on: db: condition: service_healthy # 确保 db 服务健康后再启动 web 服务 # 定义端口映射 ports: - \"8080:80\" # 将主机的 8080 端口映射到容器的 80 端口 # 定义网络 networks: - mynet # 将 web 服务连接到名为 mynet 的网络 # 设置重启策略为 always，确保容器在异常退出后自动重启 restart: always # 定义数据卷 volumes: mydata: # 定义名为 mydata 的数据卷，用于持久化 MySQL 数据 # 定义网络 networks: mynet: # 定义名为 mynet 的网络 driver: bridge # 使用 bridge 驱动创建网络 命令对比 功能 Docker 命令 Docker Compose 命令 启动容器 docker run docker-compose up 停止容器 docker stop docker-compose stop 查看日志 docker logs docker-compose logs 构建镜像 docker build docker-compose build 查看运行中的容器 docker ps docker-compose ps 进入容器 docker exec -it docker-compose exec 删除容器 docker rm docker-compose rm 这里 docker-compose down 会停止并删除容器，之后再启动就会根据之前的镜像来创建容器了。 ","date":"2025.1.20","objectID":"/blog/posts/config/docker/:0:0","tags":["config"],"title":"Docker","uri":"/blog/posts/config/docker/"},{"categories":["Static Analysis"],"content":"记录一下对于数据流分析的理解。 注意事项 下面的内容大部分来自于 数据流分析及其应用，它是对 《软件分析》 课程中相关内容的总结，同时添加 《软件分析技术》 课程的相关内容。 命令式程序的基本构成单元是命令，而程序本身则是通过 顺序、选择和循环 三种控制结构来组织这些命令。在 数据流分析框架 中，主要关注如何对这些控制结构进行抽象，以便于理解和优化程序的行为。 数据流分析概述 数据流分析 简单来说，程序可以看成是状态（数据）和状态之间的转移（控制）两部分，因为状态转移的条件都被忽略了，核心分析的部分是状态数据在转移过程中的变化，所以叫做数据流分析。 上述就是对于数据流分析的简单定义，但是数据流分析在处理复杂程序时面临挑战，因为直接追踪数据流动既复杂又耗时。为了简化这一过程，通常采用近似方法，即对程序进行适当的修改，以便得到一个更易于分析的版本，同时确保分析结果与原始程序保持一致。这种近似方法主要包含两种手段：忽略条件判断和提前合并。 近似方案 条件判断 忽略条件判断 忽略条件判断的核心思想是进行非确定性抽象，即假设所有分支条件都可能成立，从而生成一个程序行为的超集，确保原始程序的结果包含在抽象程序的结果中。 这种处理方式能够分析程序的所有可能路径，并确保分析结果的正确性。具体来说，有两种常见的抽象方式。 一种是对于分支条件的抽象。对于 if-else 语句，忽略条件判断，直接将分支抽象为非确定性选择。这里的 nondet_choice 表示程序可能执行 stmt1 或 stmt2，从而形成包含所有可能路径的抽象超集。 if (condition) { stmt1; } else { stmt2; } nondet_choice stmt1; nondet_choice stmt2; 另一种是对于循环条件的抽象。对于循环结构，将循环条件抽象为非确定性路径。这种处理方式消除了控制流图中的环结构，保证程序一定能终止。 while (condition) { body; } nondet_choice body; nondet_choice skip_loop; 上述两种语句的抽象本质上是构造一个超集。对于只有一条执行路径的原始程序，抽象后将存在多条执行路径，其中一定包含原始程序的执行路径。 提前合并 提前合并 提前合并的核心思想是不在路径末尾做合并，而是在控制流的汇合点提前进行合并。换句话说，对于忽略条件判断的结果，不是在计算每条路径的结果之后再进行汇总，而是首先考虑每条路径都会遍历，因此在多条路径的汇聚点就进行分支结果的合并，最终得到一个稳定的值，它就是程序的最终结果。 这种处理方式能够避免路径末尾合并带来的冗余计算，通过提前合并，可以加速分析过程并简化结果的计算。具体来说，没有提前合并，那么每条分支就都需要维护整个分支上的所有信息，直到最后才进行处理，这无疑会加重信息的存储，同时末尾过多信息的处理也会拖慢分析速度。 上述两种近似方案，对程序控制部分的分析进行了优化，但是对于程序数据部分的分析没有什么帮助。而数据的分析优化就是下面 符号抽象 的用途。 符号抽象 注意事项 下面的内容大部分来自于 静态分析概述。该文章介绍的是抽象的方法，但是我觉得这个和 《软件分析技术》 中介绍的符号分析方法简直一模一样，所以就将二者进行组合介绍。 在静态分析中，重点在于程序的特定性质，而非每个细节。抽象就是从程序中提取与研究特性相关的部分，忽略无关细节。这种方法不仅简化了问题，还能高效分析复杂程序的潜在问题。例如，分析除零错误（Zero Division Error）时，只需判断值是否为 0，而无需关心具体数值大小。通过将程序的 具体值集（Concrete Domain） 映射到 抽象值集（Abstract Domain），问题得以简化，同时保证分析结果仍涵盖原程序的所有可能性。 符号抽象 对于程序 P 的 具体值集（Concrete Domain） $D_C$，静态分析 S 基于要研究的性质 Q 设计 抽象值集（Abstract Domain） $D_A$，并建立映射关系 $f_{D_C \\rightarrow D_A} \\ (f \\subseteq D_C \\times D_A)$，这个过程称为 S 对 P 关于 Q 的 抽象（Abstraction）。 通常 $|D_A| \u003c |D_C|$，因为抽象的目的是简化问题。而在 $D_A$ 中，常见两个特殊值： $\\top$ 为 未确定值（Unknown） $\\bot$ 为 未定义值（Undefined） $\\top \\in D_A \\land \\bot \\in D_A$，它们需要额外定义运算规则以适应表达式计算。 这里的 $D_C$ 包含程序中变量的所有具体值，如 $\\{-2,-1,0,1,2,3,\\ldots\\}$，而 $D_A$ 是一个抽象化的集合，如 $\\{\\text{+},\\text{-},\\text{零}\\}$。$f_{D_C \\rightarrow D_A}$ 则是其 映射函数，将程序中的具体状态或值转化为适合静态分析的抽象状态或值。其中关系 $f \\subseteq D_C \\times D_A$ 表示映射 $f$ 是具体值域 $D_C$ 和抽象值域 $D_A$ 笛卡尔积的一个子集，即 $f = \\{(c, a) \\ | \\ c \\in D_C, a \\in D_A\\}$。这种表示方式允许 $f$ 是一个多对一的关系，即多个具体值可以映射到同一个抽象值，上述 $D_C$ 中的所有正数都可以映射为 $D_A$ 中的 $+$。 上述是对于单个变量而言的抽象，而程序中不止变量，还存在表达式，所以下面需要对于表达式进行处理。 状态转移 假设 $f_1 = f_{D_C \\rightarrow D_A}$。对于程序 P 的二元操作集 op，定义映射： $$ f_2 = f_{op \\times D_A \\times D_A \\rightarrow D_A} \\ (f_2 \\subseteq op \\times D_A \\times D_A \\times D_A) $$ 之后就可以通过 $f_2 \\circ f_1$，将 $D_C$ 相关的表达式值映射到 $D_A$。其中： $f_1$为 状态函数（State Function），定义如何将具体值转化为抽象值 $f_2$为 转移函数（Transfer Function），定义如何基于抽象值解析表达式 这里的 $f_2$ 定义了如何基于抽象值解析二元操作，这是对于具体值集中函数的抽象，使得经过符号抽象的变量可以通过抽象后的函数进行运算。其中 $op$ 是程序种的操作符集合（例如加法 +、减法 -、逻辑与 \u0026\u0026 等），$op \\times D_A \\times D_A \\rightarrow D_A$ 表示两个抽象值通过一个操作符生成新的抽象值。而这里的 组合 $f_2 \\circ f_1$ 表示了对于变量的所有处理操作，先通过 $f_1$ 将具体值转换为抽象值，再通过 $f_2$ 对这些抽象值进行操作，得到新的抽象结果。 那么对于上述符号抽象过程，可以使用研究程序中变量的正负性来举例，则若是 $D_A = \\{+,-,0,\\top,\\bot \\}$，那么 $f_1 = f_{D_C \\rightarrow D_A}$ 为 $$ \\forall x \\in D_C, \\quad f_1(x) = \\begin{cases} +, \u0026 \\text{if } x \u003e 0 \\\\ 0, \u0026 \\text{if } x = 0 \\\\ -, \u0026 \\text{if } x \u003c 0 \\end{cases} $$ $f_2 = f_{op \\times D_A \\times D_A \\rightarrow D_A}$ 就是 $$ f_2 = \\{(+, +, +, +), (+, -, -, -), (+, +, -, \\top), (+, 0, 0, 0), \\\\ (/, +, +, +), (/, -, -, +), (\\top, 0, \\bot, \\bot), (/, +, -, -), \\ldots \\} $$ 可以使用 Sound、过近似的分析原则分析下面的代码： x = 1; if input then y = 10; else y = -1; z = x + y; 这里会发现在进入 2-5 行的条件语句时，y 的值可能为 10，也可能为 -1。于是最终会认为 y 的抽象值为 $\\top$，最终 z 的抽象值也就为 $\\top$。这样的分析就是尽可能全面的，虽然它并不精准。这里 y 的抽象值会为 $\\top$ 是根据 常量传播 的规则来的，在下面常量传播的板块会进行规则说明。 基本概念 数据流分析 数据流分析（Data Flow Analysis） 是指分析数据在程序中是怎么流动的，具体而言，其分析的对象是基于抽象的应用特定型数据；行为是数据的流动；方式是安全近似，根据安全性需求选择过近似还是欠近似；基础是控制流图。而在数据的流动中，场景只有两个： 在 CFG 的点内流动，即程序基本块内部的数据流。 在 CFG 的边上的流动，即由基本块间控制流触发的数据流。 由此可以看出不同的数据流分析应当有： 不同的数据抽象； 不同的流安全近似策略 — 过近似或者欠近似； 不同的 转移函数 和 控制流处理方法； 上述对于转移函数进行了定义，那么下面还需要对于控制流处理方法进行介绍。 数据流值 定义程序 P 的 抽象数据状态（Abstract Data State，ADS），也即 数据流值 为程","date":"2024.12.22","objectID":"/blog/posts/staticanalysis/data-flow-analysis/:0:0","tags":["Static Analysis"],"title":"03 Data Flow Analysis","uri":"/blog/posts/staticanalysis/data-flow-analysis/"},{"categories":["Static Analysis"],"content":"记录一下对于控制流分析的理解。 注意事项 下面的内容大部分来自于 程序分析与优化 - 2 控制流图，它是对 《DCC888》 课程中相关内容的总结。重点围绕 LLVM 中端优化器（Optimizer）的优化技术进行阐述与介绍。 控制流分析 注意事项 以下内容主要参考了 程序的中间表示 的内容，主要说明控制流图的构建方法。 控制流分析（Control Flow Analysis, CFA） 通常是指构建 控制流图（Control Flow Graph，CFG） 的过程。上篇文章使用 Soot 和 LLVM 得到了中间表示 IR，之后使用 IR 转化为了控制流图，而下图也是这样的过程，转化的方法就是划分基本块。 20241222104429 基本块 CFG 是静态分析的基础，而在上图可以看出，将 IR 按照相应规则划分为数个指令快，之后采用箭头显示控制就构成了 CFG。这里的指令块就被称为基本块。 基本块 记一个程序 P 在 IR 表示下 的指令序列为 $P = \\{a_1, a_2, …, a_n\\}$，这里 P 是一个有序集，那么 $IN_i = \\{a_j | next(a_j) = a_i\\}$，其中 $next(a_j)$ 表示控制流中 $a_j$ 的下一条指令； $OUT_i = \\{a_j \\mid prev(a_j) = a_i\\}$，其中 $prev(a_j)$ 表示 $a_j$ 的上一条指令。 如果连续的指令序列 $a_p, a_{p+1}, a_{p+2}, …, a_q$ 满足如下性质： $$ \\forall i \\in [p+1, q], IN_i = {a_{i-1}} \\land \\forall i \\in [p, q-1], OUT_i = {a_{i+1}} $$ 并且 $a_{p-1}, a_p, …, a_{q-1}, a_q$ 和 $a_p, a_{p+1}, …, a_q, a_{q+1}$ 都不满足上述性质，则称 $\\{a_p, a_{p+1}, …, a_q\\}$ 为 基本块（Basic Block）。 简单而言，基本块就是满足以下性质的最长指令序列： 程序的控制流只能从首指令进入，不能存在跳转指令跳入执行基本块中的某行指令。 程序的控制流只能从尾指令流出，只有最后一条指令允许包含离开基本快的分支或者挂机指令。 由上面的定义，可以知道跳转指令会将一个完成的程序切割为几个基本快，所以只需要将基本快的分割点找到，那么整个程序就可以按照分割点划分为数个基本块了。而这个分割点就是 基本块的首领（leader）。 基本块的首领 基本块首领 对于 IR 表示下的程序 $P = \\{a_1, a_2, …, a_n\\}$，考虑某个基本块 $B = \\{a_p, a_{p+1}, …, a_{q-1}, a_q\\}$，称 $a_p$ 为 $P$ 的基本块 $B$ 的 首领（Leader），而程序 $P$ 中所有的首领组成的集合为 $L$，则 $$ L = \\{a_1\\} \\cup \\{a_i \\mid type(a_i) = jump \\land target(a_i) \\} \\cup \\{a_{i+1} \\mid type(a_i) = jump\\} $$ 其中，$type(a_i)$ 表示指令 $a_i$ 的类型，$jump$ 类型是跳转指令，包括 条件跳转（Conditional Jump） 和 无条件跳转（Unconditional Jump）。 $target(a_i)$ 仅用于 $a_i$ 是跳转指令的时候，表示 $a_i$ 的目标指令。 简单而言，首领就是每个基本块的首指令，其可以分为三种类型： 整个程序的首指令。 跳转指令（包括条件跳转和无条件跳转）的目标指令。 紧邻跳转指令（包括条件跳转和无条件跳转）的下一条指令。 基本块的界定 基本块的界定 对于程序 $P = \\{a_1, a_2, …, a_n\\}$ 而言，其所有的首领构成的集合为 $L$，则 $$ a_p \\in L \\land a_{q+1} \\in L \\land \\forall a_i (i \\in [p+1, q]), a_i \\notin L \\iff \\{a_p, a_{p+1}, …, a_{q-1}, a_q\\} $$ 得到的指令序列就是一个基本块。 简单而言，基本块的首领就是基本块之间的分割线，从一个基本块的首领到紧接着的下一个基本块的首领之前的所有指令组成了一个基本块。 局部优化 在 Basic Block 作用域内部的优化被称为 局部优化（Local Optimization），也就是将优化限制在单个基本块的上下文中，例如 基于 DAG 的优化（DAG based optimizations）、窥孔优化（Peephole optimizations）、局部寄存器分配（Local register allocation）。而基于整个程序的控制流图进行的优化被称为 全局优化（Global Optimization），静态分析的优化大部分为全局优化，这里就对局部优化进行介绍。 基于 DAG 的优化 代码优化技术是需要直接分析一整个程序的 CFG，所以一般不怎么使用 DAG 的方式来进行数据结构的优化。但是下面介绍的两种优化方法不仅仅只是使用在 DAG 优化中，而在静态分析中也有很大的作用，所以这里只对优化方式进行简单介绍。这里 DAG 就是指 有向无环图（Directed Acyclic Graph），在图论中，如果一个有向图从任意顶点触发无法经过若干条边回到该点，则这个图是一个有向无环图，DAG 如下图所示： 20241222151645 而对于上述程序而言，DAG 的构造涉及程序指令的含义： 每个输入值对应 DAG 中的一个结点，例如 a = b + c，这里的 b，c 就是输入值，需要作为结点出现。 基本块中的每行指令生成一个结点，例如 a = b + c，会产生 +,a 这样的结点。 如果指令 $S$ 用到了指令 $S_1, \\ldots ,S_n$ 中的变量，则需要一条从 $S_1，i \\in \\{1, \\ldots, n\\}$ 到 $S$ 的边。 基本块中定义但未在基本块中使用的变量称为输出值，这些值可能会被后续基本块使用，因此为输出值。 a = b + c b = a - d c = b + c d = a - d 对于上面的基本快指令，会生成下面的 DAG： 20241222152350 公共子表达式消除 对于上述程序，可以直观看到 a - d 被利用了两次，并且其返回的结果不变，因此可以将其视为公共子表达式，从而进行 公共子表达式消除（Common subexpression elimination）。它们的值相同，那么其赋值对象 b 和 d 就是别名关系，于是可以直接使用上面计算的结果 b 直接赋值给 d，不必再进行表达式的计算。而 b + c 就不可以再次利用，因为两个表达式之间存在 b = a - d，它对表达式的其中一个变量进行了重新赋值，因此不是相同表达式。 在实际应用过程中，采用 值标记 方法来计算相同子表达式： 对于 DAG 的每个结点关联一个 签名（$lb, v_1, \\ldots, v_n$），其中 $lb$ 是该结点的标签，$v_i(1 \\leq i \\leq n)$ 是该节点的所有子结点。 将签名中的子结点序列作为 hash 函数的 key； hash 函数的值就是该变量的值标记 当有新的结点加入 DAG 时，先根据它的所有子结点计算出一个 hash 值， 如果已经存在，直接返回该 hash 值对应的索引； 如果找不到，则创建该结点。 根据上面的方法，生成的值标记的 hash 表如下，可以看出最后一列显然是不必要的： 表达式 b c d a = b + c b = a - d c = b + c d = a - d hash key b c d (+,1, 2) (-,4,3) (+,5, 2) (-,4,3) value number 1 2 3 4 5 6 5 总的而言，上述方法就是在构建 DAG 的每一条语句的结点时，如果语句之前未出现过，则构建新的结点，如果是出现过相同 hash 的结点，则直接将新的结点指向之前那个相同hash 的结点。因此就可以把下图中的 -,d 结点直接删除，然后标识 d 变量的数据就和 -,b 结点的数据一样。 20241222161800 为了找到更多的 CSE（Common SubExpressions），需要指定更多的定理： 交换律：对 $+$ 运算符，$x + y$ 和 $y + x$ 等同。 特性转换：$x\u003cy$ 一般转换成 $t = x - y; \\ t \u003c 0$。 结合律: 对 $a = b + c;$，$t = c + d;$，$e = t + b;$ 等同于 $a = b + c;$，$e = a + d;$。 算术特性转换：$x + 0 = 0 + x = x;$，$x * 1 = 1 * x = x;$，$x - 0 = x;$，$x / 1 = x;$。 计算强度降维转换：$x^2 = x * x;$，$2 * x = x + x;$，$x / 2 = x * 0.5$。 常量折叠：在编译阶段计算表达式的值，并将表达式替换成对应的值。这个也是后面数据流分析中主要介绍的方法。 死代码消除 死代码（Dead Code） 是指程序中不可达的代码，即不会被执行的代码，或者是执行结果永远不会被其他计算过程用到的代码。对于 DAG 而言，满足下面两个","date":"2024.12.22","objectID":"/blog/posts/staticanalysis/control-flow-analysis/:0:0","tags":["Static Analysis"],"title":"02 Control Flow Analysis","uri":"/blog/posts/staticanalysis/control-flow-analysis/"},{"categories":["programming"],"content":"记录一下 java 的学习。 基础知识 相关基础知识可以从 菜鸟教程，二哥的Java进阶之路，cs61b 中进行学习，这些都很详细。对于 cs61b 可以直接看 相关笔记1，相关笔记2。下面主要记录 cs61b 中的相关结构源码与知识点辨析。 List and Deque 对于 java 的列表和队列不太了解，所以这里进行相关记录。 SLList SLList 就是 Singly Linked List，即单向链表，代码如下所示。可以看出： 内部类 Node：对于链表的单个结构进行封装的结果，其类型为 private，保证了封闭性。 哨兵 sentinel：用来维护下面 addFirst 和 addLast 的一致性。正是因为这个哨兵节点的存在，他们可以对所有节点保持一样的操作，而不必考虑一开始没有节点的情况。 列表大小 size：记录当前列表的大小，因为在每次操作都会记录，所以可以直接通过 size() 获取大小。这样添加一个变量定理，遏制了列表从头遍历获取长度的操作，使长度获取更快速。 同时由下可以看出，列表对于最后一个元素的添加和获取速度很慢，但是其可以动态分配内存、插入和删除效率高，无连续内存要求。 public class SLList\u003cItem\u003e { private class Node { public Item item; public Node next; public Node(Item i, Node n) { item = i; next = n; } } /* The first item (if it exists) is at sentinel.next. */ private Node sentinel; private int size; /** Creates an empty timingtest.SLList. */ public SLList() { sentinel = new Node(null, null); size = 0; } public SLList(Item x) { sentinel = new Node(null, null); sentinel.next = new Node(x, null); size = 1; } /** Adds x to the front of the list. */ public void addFirst(Item x) { sentinel.next = new Node(x, sentinel.next); size += 1; } /** Returns the first item in the list. */ public Item getFirst() { return sentinel.next.item; } /** Adds x to the end of the list. */ public void addLast(Item x) { size += 1; Node p = sentinel; /* Advance p to the end of the list. */ while (p.next != null) { p = p.next; } p.next = new Node(x, null); } /** returns last item in the list */ public Item getLast() { Node p = sentinel; /* Advance p to the end of the list. */ while (p.next != null) { p = p.next; } return p.item; } /** Returns the size of the list. */ public int size() { return size; } } AList AList 就是 Array List，即数组列表，代码如下所示。可以看出： 列表大小 size：记录当前列表的大小，因为在每次操作都会记录，所以可以直接通过 size() 获取大小。 扩容 resize：进行扩容的函数，当 addLast 时发现大小不够时，就通过该函数对数组大小进行扩容处理。但是该操作是创建一个新数组，然后将原本的内容进行复制处理，所以对于大量数据速度会很慢。 使用数组的列表结构，可以快速随机访问，能直接通过索引进行访问，并且简单直观。但是扩容成本高，内存一开始开辟，填不满浪费空间，同时也不适合平凡的插入和删除。 public class AList\u003cItem\u003e { private Item[] items; private int size; /** Creates an empty list. */ public AList() { items = (Item[]) new Object[100]; size = 0; } /** Resizes the underlying array to the target capacity. */ private void resize(int capacity) { Item[] a = (Item[]) new Object[capacity]; System.arraycopy(items, 0, a, 0, size); items = a; } /** Inserts X into the back of the list. */ public void addLast(Item x) { if (size == items.length) { resize(size * 2); } items[size] = x; size = size + 1; } /** Returns the item from the back of the list. */ public Item getLast() { return items[size - 1]; } /** Gets the ith item in the list (0 is the front). */ public Item get(int i) { return items[i]; } /** Returns the number of items in the list. */ public int size() { return size; } /** Deletes item from back of the list and * returns deleted item. */ public Item removeLast() { Item x = getLast(); items[size - 1] = null; size = size - 1; return x; } } LinkedListDeque 下面的代码实现了双端队列，他就是基于上面 SLList 的基础上进行改进的。 哨兵 sentinel：这里的哨兵和上文的作用一样，但是这里采用了更为巧妙的方法。这里对于双端队列，只设置一个哨兵，这样通过哨兵关联头尾，形成了一个环，这样就能保证双端队列的添加一致性。 这里双端队列相比于上文的单向链表，对于尾端的插入迅速，不必再遍历整个链表。 import java.util.Iterator; public class LinkedListDeque\u003cT\u003e implements Iterable\u003cT\u003e { // define the basic struct private class Node { T item; Node prev; Node next; Node(T item, Node prev, Node next) { this.item = item; this.prev = prev; this.next = next; } } // the first item (if it exits) is at sentinel.next // and the last item is at sentinel.prev private Node sentinel; private int size; public LinkedListDeque() { sentinel = new Node(null, null, null); sentinel.next = sentinel; sentinel.prev = sentinel; size = 0; } @Override public void addFirst(T item) { Node tempItem = new Node(item, sentinel, sentinel.next); sentinel.next.prev = tempItem; sentinel.next = tempItem; size += 1; } @Override public void addLast(T item) { Node tempItem = new Node(item, sentinel.prev, sentinel); sentinel.prev.next = tempItem; sentinel.prev = tempItem; size += 1; } @Override public int size() { return size; } @Override public void printDequ","date":"2024.12.20","objectID":"/blog/posts/programming/java/:0:0","tags":["programming"],"title":"Some about Java","uri":"/blog/posts/programming/java/"},{"categories":["Static Analysis"],"content":"记录一下对于静态分析的理解。 前提说明 由于我的知识面受限，所以关于当前系列文章做出以下解释： 在计算机科学中，程序分析 是指自动分析一个程序的包括正确性、健壮性、安全性和活跃性等特征的过程。程序分析主要研究两大领域：程序的优化和程序的正确性。前者研究如何提升程序性能并且降低程序的资源占用，后者研究如何确保程序完成预期的任务。同时程序分析可以在不执行程序的情况下进行（静态程序分析），也可以在执行时进行（动态程序分析），或结合二者。这里都是来自 wiki 的介绍，而本文的相关术语也遵从上面的介绍，静态分析就是程序分析的一个方面，全称为静态程序分析。 在我的学习中，感觉静态分析的相关知识和编译器优化的内容存在很大程度上的重叠，所以就将 DCC888 的内容也补充进来。后来发现该课程主页的名称为 Static Program Analysis，拿过来记录也名正言顺。所以本系列文章就是基于 《软件分析》，《软件分析技术》，《DCC888》 三门课程与其余参考资料所写的笔记。 静态分析概览 注意事项 下面的内容大部分来自于 沉浸式《程序分析》教材，但是在那篇文章中，对于程序分析的描述为本文一开始提到的静态程序分析。所以在这篇文章中，采用静态分析替代那篇文章中的程序分析。 静态分析定义 静态分析 静态分析（Static Analysis） 是一种在实际运行程序 P 之前，通过分析静态程序 P 本身来推测程序的行为，并判断程序是否满足某些特定的 属性（Property） Q 的方法。 上述中静态程序指的就是不运行程序的状态，它也被称为 “静态” 或 “编译时”，它与程序的 “动态” 和 “运行时” 相对应。由此可以看出，静态分析就是对于给定的程序代码进行自动化扫描、分析，而不必运行程序。 静态分析用途 静态分析的用处有很多，主要可以分为下面的内容： 程序可靠性（Program Reliability）：空指针异常而导致的程序崩溃会影响程序的可靠性，诸如这样的 bug 还存在很多，但是他们中很多都可以在没有运行的状态下被静态分析检测出来。同时导致程序不响应的程序缺陷，例如内存泄漏，也会被静态分析检测出来。 程序安全性（Program Security）：对于程序中的可能引起注入攻击等的缺陷代码，静态分析也可以进行识别。 编译优化（Compiler Optimization）：在将源码编译为目标平台程序的过程中，静态分析可以在中间环节对中间代码进行优化。其中 Dead code elimination 可以避免永远执行不到的代码最终编译到目标平台程序中；Code motion 可以将循环中的某些计算不变式语句提取到循环外部，进行避免冗余计算，提高程序运行速度。 程序理解（Program Understanding）：IDE 提供的不止有代码编辑功能，还有程序理解功能。比如 IDE 可以提示代码的调用关系、继承关系、声明类型等信息，这些关于程序的诸多信息的提取很多都是通过静态分析技术来完成的。 静态分析定位 静态分析属于程序设计语言的一部分，而程序设计语言主要分为三类研究内容： 理论：设计一款程序设计语言一般是从其语法、语义的设计开始，也包括选择什么类型系统，支持什么语言特性等问题。一般情况下，这类理论研究一般可以自证，即可以将语言的语法、语义、类型系统等形式化，然后在其形式化基础上用理论方法证明该语言的诸多属性，这也就是为什么很多 PL 的论文并没有实现实验部分。 环境：程序设计语言有了理论设计，在实际中想要运行的起来，必须要有支撑它的环境系统，这主要包括编译系统和运行时系统两个部分。编译系统强调语法的解析（如果是静态语言还会有类型检查等），运行时系统强调语义的解释执行（比解释器更复杂的运行时系统也会负责垃圾回收等内存问题）。PL 的环境系统往往避免不了在实现细节上做很多脏活累活，使得语言在实际中真能好用起来。 应用：有了理论与环境的支撑，语言就能跑起来了。然而，一个工业级的程序设计语言通常是一个非常复杂的系统，如何保障该复杂系统的可靠性、安全性、高性能等需求，是需要一系列方法来支撑的，这些方法（如静态分析、程序验证、程序合成等）通常要以语言的理论部分为基础（如语法、语义），结合不同的数学理论来完成各自应用的目标。在 PL 应用中，最具代表性的技术就是静态分析。 虽然程序设计语言数量繁多，但是无非属于以下三大类（称为 程序设计语言范式，Programming Paradigm）： 命令式程序设计语言（Imperative Programming Languages，IP）：在 IP 中，指令一个一个给出，用条件、循环等来控制逻辑（指令执行的顺序），同时这些逻辑通过程序变量不断修改程序状态，最终计算出结果。尽管 IP 现在都是高级语言了，但是本质上并没有脱离那种 “类似汇编的，通过读取、写入等指令操作内存数据” 的编程方式。国内高等教育中接触的绝大多数编程语言都是 IP 的，比如 Java、C、C++ 等。 函数式程序设计语言（Functional Programming Language，FP）：在 FP 中，逻辑（用函数来表达）可以像数据一样抽象起来，复杂的逻辑（高阶函数）可以通过操纵（传递、调用、返回）简单的逻辑（低阶函数）和数据来表达，没有了时序与状态，隐藏了计算的很多细节。不同的逻辑因为没有被时序和状态耦合在一起，程序本身模块化更强，也更利于不同逻辑被并行的处理，同时避免因并行或并发处理可能带来的程序故障隐患，这也说明了为什么 FP 语言如 Haskell 在金融等领域（高并发且需要避免程序并发错误）受到瞩目。 逻辑式程序设计语言（Logic Programming Language，LP）：LP 抽象的能力就更强了，计算细节干脆不见了，把想表达的逻辑直观表达出来就好了。如今，在数据驱动计算日益增加的背景下，LP 中的声明式语言，如 Datalog 作为代表开始崭露头角，在诸多专家领域开拓应用市场。 不完备性 由上文静态分析的定义可知，静态分析是通过分析程序的代码而推理出程序在动态运行时可能的行为，然后判断程序是否满足关注的一些属性的一种方法。这里关注的信息可能是： 该程序是否会泄漏私有信息？ 该程序是否会引用空指针？ 该程序中所有 cast 操作都是安全的吗？ 该程序的这块代码是否是死代码？ …… 可以看出，静态分析可以判断的属性有很多，而且有些至关重要。所以如果静态分析可以准确无误地判断上述程序的所有属性，那么程序就不愁还会存在可靠性和安全性的问题了，只需要关注于静态分析的优化即可。但是显示情况却不是这样的，这就需要下面一系列理论的支持了。 不可判定 可判定问题是指：对于回答是或否的问题，如果存在一个算法，使得对于该问题的每一个实例都能给出 是/否 的答案，那么这个问题就是可判定问题。而将这个问题转移到程序上面，就是说对于一个程序或者代码而言，只看其初始状态，而不运行这个程序，那么是否可以判断其是否会停机？答案就是它是不可判定的。 而要知道它为什么是不可判定问题，就需要知道哥德尔不完备定理和图灵停机问题的相关知识，因此可以从 停机悖论三句话就能证明不完备性定理？ 来进行了解。在观看之后就可以明白一个概念，不存在一个算法能够回答停机问题，它是不可判定的。 莱斯定理 现在关注 静态分析是否可以准确无误地判断上述程序的所有属性问题，那么就需要引入莱斯定理。 Rice 定理 对于使用 递归可枚举（Recursively Enumerable） 的语言描述的程序，其任何 非平凡（Non-trivial） 的属性都是不可判定的。 这里的 递归可枚举 就可以理解为图灵完备语言；而对于 非平凡属性，定义一个属性是平凡的，那么这个属性要么对任何一个递归可枚举语言编写的所有程序为真，要么为假，否则它就是非平凡的。由此可以把这里的非平凡属性理解为和程序运行时行为相关的属性，它体现的是一种语义相关而不是语法相关的属性。例如，一个程序是否存在 while 循环、是否存在左右括号等类似的就是和 语法相关 的属性，而这里讨论的是否会泄漏私有信息等就是和 语义相关 的属性。因此可以进一步将莱斯定理理解为下面的表述： Rice 定理 一个程序的任何语义（运行时行为）相关的属性都是不可判定的。 莱斯定理验证 既然成功理解了莱斯定理，知道其含义，那么就需要知道它为什么是正确的，这样就涉及到上面提起的不可判定了。这里的证明思路需要和图灵机停机进行联系，也就是将证明这个问题（非平凡属性）是否可判定 规约 到是否可以判定图灵机停机问题上。如此一来，如果该问题可判定，那么就可以得到图灵停机问题也可以判定的结果，继而根据已知事情反证出来该问题不可判定。下面就是使用 python 来定义一个 Halt 函数： def Halt(p, i): def trick(k): p(i) return k * k * k return is_cube(trick) 这里 Halt 函数用来判定在给定程序 p 和输入 i 的条件下，p 是否会停机。之后再内部定义一个函数 trick，它的输入是 k，首先执行输入为 i 的程序 p，之后返回输入 k 的立方。如果 p(i) 不停机，也就是一直处于运行状态，那么这个 trick 函数就不会进行返回操作；而如果 p(i) 能够停机，那么这个函数就会返回给定参数的立方值。 现在假设 Halt 函数中的 is_cube(trick) 是可以确切无误地判断 给定函数 trick 是否可以计算立方值问题 的函数（这里可以把计算立方值替换为任何非平凡的属性），那么就可以得到下面的两","date":"2024.12.19","objectID":"/blog/posts/staticanalysis/understanding/:0:0","tags":["Static Analysis"],"title":"01 Understanding Static Analysis","uri":"/blog/posts/staticanalysis/understanding/"},{"categories":["config"],"content":"记录一下 vscode 及其相关插件的配置和使用。 具体使用 快捷方式 这里只描述 vscode 本体的快捷方式或者后续添加的，与 Vim 相关的操作在具体描述 Vim 的文章中进行讲述。 多功能按键 \u003cCtrl-Shift-p\u003e：这个按键就是调出设置框，如下图所示。通过这个设置框，我们可以在里面寻找 vscode 的任何操作说明，点击即可进行相关操作。 20241205215507 \u003cCtrl-p\u003e：和上面按键类似，但是这个是对于文件的处理，它可以寻找当前项目的文件，点击即可打开，同时聚焦于新文件。 20241205215709 界面聚焦 这里的聚焦实际指当前光标的位置，因为 vscode 的区域可以分为侧边栏，编辑区，终端等区域，所以这里记录区域切换的方式。 \u003cCtrl-`\u003e：这个按键用于打开/隐藏终端，但是打开/隐藏的时候会伴随着光标的切换。也就是当打开终端时，会自动聚焦于终端上；隐藏终端时，会自动聚焦于编辑框。由此能把这个按键作为编辑框和终端的光标转换按键，需要终端时使其打开出现，不需要时也可以令其隐藏使光标处于编辑框中。 \u003cCtrl-Shift-E\u003e：这个是光标跳转到左侧边栏的 Explorer 的快捷键，使用它就可以使光标在左侧边栏和离侧边栏最近的编辑框进行跳转了，它类似于上面的 \u003cCtrl-`\u003e，不过这里只是光标的跳转，上面还可以打开/隐藏终端。 \u003cCtrl-count\u003e：count 指的就是数字键，这个组合是对于横向的窗口而言的。比如 \u003cCtrl-0\u003e 就会把光标放在左侧边栏中，这样对于文件栏而言可以使用 enter 进行打开；\u003cCtrl-1\u003e 则是当前编辑框；Ctrl-2 就是第二个编辑框，若是当前没有就会进行创建，然后我们就可以使用 \u003cCtrl-p\u003e 来打开文件了。后面的数字依次类推。 \u003cAlt-count\u003e：上面的 Ctrl 是对于不同窗口而言的，那么这里的 Alt 就是对于不同标签页而言的。使用这个按键组合就可以在当前窗口中切换相应标签页了。这里使用 \u003cCtrl+Tab\u003e 也是切换标签页，不过有一个切换界面。 页面操作 \u003cCtrl-w\u003e：关闭当前标签页，\u003cCtrl-Shift-w\u003e就是关闭当前项目了。 \u003cCtrl-b\u003e：打开/关闭侧边栏。 侧边栏操作 配置了下面的快捷方式，使得在侧边栏操作更为方便。 // -------------------------- 侧边栏操作 -------------------------- [ { // Rename file \"key\": \"r\", \"command\": \"renameFile\", \"when\": \"explorerViewletVisible \u0026\u0026 filesExplorerFocus \u0026\u0026 !explorerResourceIsRoot \u0026\u0026 !explorerResourceReadonly \u0026\u0026 !inputFocus\" }, { // New file \"key\": \"a\", \"command\": \"explorer.newFile\", \"when\": \"explorerViewletVisible \u0026\u0026 filesExplorerFocus \u0026\u0026 !explorerResourceIsRoot \u0026\u0026 !explorerResourceReadonly \u0026\u0026 !inputFocus\" }, { // New folder \"key\": \"shift+a\", \"command\": \"explorer.newFolder\", \"when\": \"explorerViewletVisible \u0026\u0026 filesExplorerFocus \u0026\u0026 !explorerResourceIsRoot \u0026\u0026 !explorerResourceReadonly \u0026\u0026 !inputFocus\" }, { // Delete file \"key\": \"d\", \"command\": \"deleteFile\", \"when\": \"explorerViewletVisible \u0026\u0026 filesExplorerFocus \u0026\u0026 !explorerResourceIsRoot \u0026\u0026 !explorerResourceReadonly \u0026\u0026 !inputFocus\" }, { // Copy \"key\": \"y\", \"command\": \"filesExplorer.copy\", \"when\": \"explorerViewletVisible \u0026\u0026 filesExplorerFocus \u0026\u0026 !explorerResourceIsRoot \u0026\u0026 !explorerResourceReadonly \u0026\u0026 !inputFocus\" }, { // Cut \"key\": \"x\", \"command\": \"filesExplorer.cut\", \"when\": \"explorerViewletVisible \u0026\u0026 filesExplorerFocus \u0026\u0026 !explorerResourceIsRoot \u0026\u0026 !explorerResourceReadonly \u0026\u0026 !inputFocus\" }, { // Paste \"key\": \"p\", \"command\": \"filesExplorer.paste\", \"when\": \"explorerViewletVisible \u0026\u0026 filesExplorerFocus \u0026\u0026 !explorerResourceIsRoot \u0026\u0026 !explorerResourceReadonly \u0026\u0026 !inputFocus\" } ] 配置辨析 为了更改目录相关的配置，我们可以设置 settings.json 文件实现。在此过程中，我们选择使用 Workspace（工作区）配置，而非全局的 User 配置。这样 vscode 会在当前目录的根目录下生成 .vscode 文件夹，其含有 settings.json 文件，专门用于当前目录的配置。因此，每个独立的目录可以被视为一个单独的工作区。 对于工作区配置，其核心是通过一个专门的配置文件 .code-workspace 来管理多个子项目和工作区的 settings.json 文件。同时，每个子项目的目录下仍可以存在单独的 .vscode 文件夹，用于个性化配置。这种方案的优点是粒度更细，可以分别对工作区和子项目进行配置。但缺点也较为明显：如果需要按之前的配置打开相关项目，就必须通过工作区文件打开多个子项目。此外，工作区文件记录的是绝对路径，若项目地址发生变动，原配置文件就失效了。这对我当前随机分配项目的需求而言并不适用。 至于 Profiles 功能，它允许为不同目录设置独立的配置文件。然而，根据实际尝试，这种方式存在一个问题：每个配置文件需要单独下载插件，并无法共享，这对于插件依赖较多的场景来说非常不便，因此我放弃了这种方案。 最终，我选择将每个目录视为一个独立的工作区，并通过禁用不相关插件来优化体验。尽管目前大多数语言相关插件都支持按需加载（未使用时不加载），且加载后会显示加载时间，但我注意到部分插件在未使用时依然被加载。因此，为了针对不同目录提高效率，我仍倾向于手动禁用无关插件，以实现更精准的控制和优化。 配置记录 记录一下自己的 settings.json 配置。 { // ----------------------------- 编辑器配置 ----------------------------- // workbench 配置，用于设置工作台的外观和行为 \"workbench.editor.enablePreview\": false, \"workbench.startupEditor\": \"none\", \"workbench.colorTheme\": \"Learn with Sumit - Blue Velvet\", \"workbench.iconTheme\": \"material-icon-theme\", \"workbench.layoutControl.enabled\": false , // files 配置，用于设置文件相关的行为 \"files.autoSave\": \"onFocusChange\", \"files.autoGuessEncoding\": true, // editor 配置，用于设置编辑器的外观和行为 \"editor.wordWrap\": \"on\", // 软换行，没有横向滚动条 \"editor.formatOnPaste\": true, \"editor.fontSize\": 13, \"editor.fontFamily\": \"JetBrainsMono Nerd Font Propo\", \"editor.tabCompletion\": \"on\", \"editor.formatOnType\": true, \"editor.acceptSuggestionOnEnter\": \"off\", \"editor.detectIndentation\": false, \"editor.minimap.autohide\": true, \"editor.unicodeHighlight.invisibleCharacters\": false, // 不高亮显示不可见字符 // window 配置，用于设置窗口的行为 \"window.openFoldersInNewWindow\": \"on\", // ----------------------------- 终端配置 ----------------------","date":"2024.12.3","objectID":"/blog/posts/config/vscode/:0:0","tags":["config"],"title":"VsCode 配置和使用","uri":"/blog/posts/config/vscode/"},{"categories":["android"],"content":"记录一下 Unidbg 的使用。 具体的介绍就不讲了，使用就是直接从 官网 拉取代码，然后在 IDEA 中进行配置即可。基础操作可以看 博客。 基础板子 下面展示的就是基础使用的板子，每次对于 so 文件的分析都需要先设置这个板子，然后再在板子上进行自己需要的配置。 package com.ctf.wmctf; import com.github.unidbg.AndroidEmulator; import com.github.unidbg.Module; import com.github.unidbg.linux.android.AndroidEmulatorBuilder; import com.github.unidbg.linux.android.AndroidResolver; import com.github.unidbg.linux.android.dvm.AbstractJni; import com.github.unidbg.linux.android.dvm.DalvikModule; import com.github.unidbg.linux.android.dvm.VM; import com.github.unidbg.memory.Memory; import java.io.File; public class easyAndroid extends AbstractJni { private final AndroidEmulator emulator; private final Memory memory; private final VM vm; private final Module module; private final boolean logging; easyAndroid(boolean logging) { this.logging = logging; // 1. 创建模拟器实例（32位或64位），进程名建议依照实际进程名填写，可以规避针对进程名的校验 emulator = AndroidEmulatorBuilder .for64Bit() .setProcessName(\"com.s0rry.easyandroid\") .build(); // 2. 获取内存对象（由此操作内存） memory = emulator.getMemory(); // 3. 设置安卓 sdk 版本，即设置系统类库解析（只支持19、23） memory.setLibraryResolver(new AndroidResolver(23)); // 设置模块加载监听器，可以在模块加载时做一些其他事情，这里就是在 .init 段代码执行前添加 hook 模块 // memory.addModuleListener(new initModuleListener()); // 4. 创建 Android 虚拟机并传入 APK，Unidbg 可以替我们做部分签名校验的工作 vm = emulator.createDalvikVM(new File(\"unidbg-android\\\\src\\\\test\\\\resources\\\\ctf\\\\wmctf\\\\easyAndroid.apk\")); vm.setJni(this); // 在当前对象中寻找 so 调用的 java 代码，它可以帮助补充 so 需要的 java 代码 vm.setVerbose(logging); // 设置是否打印 Jni 调用细节 // 5. 加载目标 so 文件到 unicorn 虚拟内存，false 参数确定不会自动调用 init 函数 DalvikModule dm = vm.loadLibrary(new File(\"unidbg-android\\\\src\\\\test\\\\resources\\\\ctf\\\\wmctf\\\\libeasyandroid.so\"), false); dm.callJNI_OnLoad(emulator); // 执行 JNI_OnLoad 函数 // 6. dm 表示内存中 so 文件，下面就是得到 module 对象，我们可以基于这个对象实现对于 so 中成员的访问 module = dm.getModule(); // 获取本 so 模块的句柄 } public static void main(String[] args) { easyAndroid easyandroid = new easyAndroid(true); } } Hook hook 在 Unidbg 感觉是最为重要的东西。有了它的存在，我们才能在调试中获取更多的信息。这里推荐一篇 文章，这个写的极好，感觉把我自己能想到的需要 hook 的场景方法都讲了一遍。 hook 时机过晚 我们正常的 hook 都是位于 so 加载之后，执行 JNI_OnLoad 之前，而我们的加载顺序为 init -\u003e init_array -\u003e JNI_OnLoad，所以如果 .init 段 和 .init_array 段存在代码逻辑，我们想要去 hook，那么使用之前的方法就太晚了，所以我们需要将 hook 的时机提前到 init 执行前。由此可以看上面文章的 讲述，存在三种应对方案，我这里只是为了快速回忆而做的笔记： 提前加载 libc：这个就需要我们想要 hook 的是目标函数中的 libc 函数。比如 .init 段存在 strcmp，我们想看看比对的数据，这个时候就可以首先 hook libc 来得到相关数据。但是如果目标函数不是这个，而是某个地址的寄存器信息等，那么就没有办法了。 固定地址下断点：我们都是通过 vm.loadLibrary 来加载第一个用户的 so 文件，基地址固定为 0x40000000。因此可以通过偏移和基地址计算出固定地址，之后通过 Console Debugger 来 Hook，例如 emulator.attach().addBreakPoint(0x40000000 + 0x18968);。 使用 Unidbg 提供的模块监听器：这是我认为最为合适的方案，就是添加一个监听器。之后要么用第三方 hook 框架，要么使用原生 unicornHook，这两个分情况使用，但是这个方案我觉得最为合适。具体的使用可以看看自己写的 WMCTF2024 easyAndroid 的反混淆 -\u003e notion。 注意事项 在 unidbg 的项目中不要进行 IDA 的分析，因为产生的分析文件是只读的，Maven 不能自动复制它们，这就会产生 build 的错误 对于 load dependency xxx.so failed 的问题有不同的解决方案： 最为常见的就是 libandroid.so 报错，这是因为 libandroid.so 的依赖太多了，Unidbg很难一一处理，所以作者采用了折中的方案，自己注册虚拟模块。这里 libandroid.so 已经由作者实现了，实现了常用的几个Assets操作的API。因此只需要加上下面的语句即可 new AndroidModule(emulator, vm).register(memory);，具体参考 SO逆向入门实战教程十：SimpleSign。 而对于其他 so 的缺失，比如要分析的 so 依赖另外的 so，我这里的处理就是使用 loadLibrary 提前加载一下，然后结果也是好的（但是后来发现只需要把依赖的 so 和分析的 so 放在同一目录下，就会自动进行加载）。不过最好采用 VirtualModule 来加载，可以通过查看 unidbg中的VirtualModule 来进行处理。 ","date":"2024.11.30","objectID":"/blog/posts/android/unidbg/:0:0","tags":["android"],"title":"Unidbg 记录","uri":"/blog/posts/android/unidbg/"},{"categories":["reverse"],"content":"记录一下在逆向过程中常使用的算法，记录一下 python 脚本。 base64 from Crypto.Util.number import * # Base64 字符表 table = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\" def encode(data): n = bytes_to_long(data) # 转换为整数 pad = (3 - (len(data) % 3)) % 3 # 计算需要填充的字节数 n \u003c\u003c= 8 * pad # 左移填充 indices = [] # 存储 Base64 索引 while n: # 逐步取模 indices.append(n % 64) n //= 64 indices = indices[::-1] # 反转顺序 result = \"\".join([table[i] for i in indices]) # 索引映射到字符表 result += \"=\" * pad # 添加填充字符 print(result) encode(b\"flag{wecome_to_try_base64}\") 直接使用库来进行加解密 import base64 # Python3 中字符都是 unicode 编码，而 b64encode函数的参数为 byte 类型，所以必须先转码 enc = base64.b64encode(\"AlwaysBeta\".encode(\"utf-8\")) dec = base64.b64decode(enc) # 换表解密 new_table = \"ABCDEFQRSTUVWXYPGHIJKLMNOZabcdefghijklmnopqrstuvwxyz0123456789+/\" old_table = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\" cipher = \"zMXHz3TIgnxLxJhFAdtZn2fFk3lYCrtPC2l9\".swapcase() # swapcase 是大小写转化，大写转小写等 print(base64.b64decode(cipher.translate(str.maketrans(new_table, old_table)))) RC4 def RC4(input, key): sbox = list(range(256)) j = 0 for i in range(256): j = (j + sbox[i] + key[i % len(key)]) % 256 sbox[i], sbox[j] = sbox[j], sbox[i] i, j = 0, 0 output = [] keystream = [] for k in range(len(input)): i = (i + 1) % 256 j = (j + sbox[i]) % 256 sbox[i], sbox[j] = sbox[j], sbox[i] keystream.append(sbox[(sbox[i] + sbox[j]) % 256]) output.append(input[k] ^ keystream[k]) return bytes(output), keystream key = b\"fun@eZ\" out = RC4(b\"Hello, world!\", key)[0] print(out) inp = RC4(out, key)[0] print(inp) Tea 系列 tea from ctypes import * def encrypt(rounds, v, k): v0, v1 = c_uint32(v[0]), c_uint32(v[1]) delta = 0x9E3779B9 sum = c_uint32(0) k0, k1, k2, k3 = c_uint32(k[0]), c_uint32(k[1]), c_uint32(k[2]), c_uint32(k[3]) for i in range(rounds): sum.value += delta v0.value += ((v1.value \u003c\u003c 4) + k0.value) ^ (v1.value + sum.value) ^ ((v1.value \u003e\u003e 5) + k1.value) v1.value += ((v0.value \u003c\u003c 4) + k2.value) ^ (v0.value + sum.value) ^ ((v0.value \u003e\u003e 5) + k3.value) return [v0.value, v1.value] def decrypt(rounds, v, k): v0, v1 = c_uint32(v[0]), c_uint32(v[1]) delta = 0x9E3779B9 sum = c_uint32(delta * rounds) k0, k1, k2, k3 = c_uint32(k[0]), c_uint32(k[1]), c_uint32(k[2]), c_uint32(k[3]) for i in range(rounds): v1.value -= (((v0.value \u003c\u003c 4) + k2.value) ^ (v0.value + sum.value) ^ ((v0.value \u003e\u003e 5) + k3.value)) v0.value -= (((v1.value \u003c\u003c 4) + k0.value) ^ (v1.value + sum.value) ^ ((v1.value \u003e\u003e 5) + k1.value)) sum.value -= delta return [v0.value, v1.value] v = [1, 2] k = [1, 2, 3, 4] enc = encrypt(32, v, k) print(\"%#x %#x\" % (enc[0], enc[1])) dec = decrypt(32, enc, k) print(\"%#x %#x\" % (dec[0], dec[1])) xtea from ctypes import * def encrypt(rounds, v, k): v0, v1 = c_uint32(v[0]), c_uint32(v[1]) delta = 0x9E3779B9 sum = c_uint32(0) for i in range(rounds): v0.value += (((v1.value \u003c\u003c 4) ^ (v1.value \u003e\u003e 5)) + v1.value) ^ (sum.value + k[sum.value \u0026 3]) sum.value += delta v1.value += (((v0.value \u003c\u003c 4) ^ (v0.value \u003e\u003e 5)) + v0.value) ^ (sum.value + k[(sum.value \u003e\u003e 11) \u0026 3]) return [v0.value, v1.value] def decrypt(rounds, v, k): v0, v1 = c_uint32(v[0]), c_uint32(v[1]) delta = 0x9E3779B9 sum = c_uint32(delta * rounds) for i in range(rounds): v1.value -= (((v0.value \u003c\u003c 4) ^ (v0.value \u003e\u003e 5)) + v0.value) ^ (sum.value + k[(sum.value \u003e\u003e 11) \u0026 3]) sum.value -= delta v0.value -= (((v1.value \u003c\u003c 4) ^ (v1.value \u003e\u003e 5)) + v1.value) ^ (sum.value + k[sum.value \u0026 3]) return [v0.value, v1.value] v = [1, 2] k = [1, 2, 3, 4] enc = encrypt(32, v, k) print(\"%#x %#x\" % (enc[0], enc[1])) dec = decrypt(32, enc, k) print(\"%#x %#x\" % (dec[0], dec[1])) xxtea from ctypes import * def MX(z, y, total, key, p, e): temp1 = (z.value \u003e\u003e 5 ^ y.value \u003c\u003c 2) + (y.value \u003e\u003e 3 ^ z.value \u003c\u003c 4) temp2 = (total.value ^ y.value) + (key[(p \u0026 3) ^ e.value] ^ z.value) return c_uint32(temp1 ^ temp2) def encrypt(n, v, key): delta = 0x9E3779B9 rounds = 6 + 52 // n total = c_uint32(0) z = c_uint32(v[n - 1]) e = c_uint32(0) while rounds \u003e 0: total.value += delta e.value = (total.value \u003e\u003e 2) \u0026 3 for p in ra","date":"2024.11.27","objectID":"/blog/posts/reverse/algorithm/:0:0","tags":["reverse","algorithm"],"title":"逆向中的算法","uri":"/blog/posts/reverse/algorithm/"},{"categories":["config"],"content":"记录一下每次刷机和刷机之后需要的配置 刷机 这里记录一下刷机的流程，都是按照我的 pixel3 手机来的。 解锁 OEM 和 BL 首先是通过在设置 \u003e 系统 \u003e 关于手机多次点击版本号，直到提示进入开发者模式。之后在手机的设置 \u003e 系统 \u003e 开发者选项中找到 OEM 解锁，将其打开。 最后就是使用以下命令解锁 BL 锁，解锁之后，手机会重置。 adb devices # 先检查设备是否存在，存在则执行以下指令 adb reboot bootloader # 重启进入fastboot mode fastboot flashing unlock # 解锁 驱动安装 windows 需要进行这一步，不然可能识别不了手机。从 官网 下载驱动安装，之后进入设备管理器 \u003e 其它设备下查看相应的设备，右键更新驱动程序，选择浏览我的电脑以查找驱动程序，将下载驱动解压缩路径选中，点击下一步，安装即可 刷入官方镜像 我使用的手机是 pixel3，所以直接从 google 镜像官网找 blueline 型号的镜像下载。解压压缩包之后进入目录，运行下面的命令，等待萨湖如官方镜像完成。 adb reboot bootloader # 先进入bootloader模式 ./flash-all.sh 使用 Magisk 进行 Root 先从 官方 下载面具，之后使用 adb install xx.apk 来进行安装。之后从上面的官方镜像的 image-blueline-xxxxxx.zip 中得到 boot.img 文件，通过 adb push boot.img /sdcard/ 上传到手机之后，使用 Magisk，点击安装 \u003e 选择并修补一个文件对该文件进行修补，之后会得到 magisk_patched-xxx_xxx.img 文件。在把这个文件通过 adb pull /sdcard/Download/magisk_patched-xxx_xxx.img 下载到电脑，再次刷入即可 root。 adb reboot bootloader # 先进入fastboot mode fastboot flash boot magisk_patched-xxx_xxx.img 只需要在 adb shell 中执行 su 命令，Magisk 弹出确认，点击允许即可获取 root。 软件下载 Magisk 上面说了下载链接，这里就不展开述说了。面具的作用有很多，我觉得最主要的就是获取 root 权限，由此可以配合使用很多操作。 同时可以下载 zygisk，可以有更多修改能力，也可以下载 LSPosed，启动 Xposed Hook。 CaptiveMgr 去除 WiFi 受限无法连接叹号的问题，自己软件的下在链接忘了，贴一个别人存的地址，应该是一样的。相关博客。 Termux Termux是一个适用于 Android 的终端模拟器，其环境类似于 Linux 环境。 无需Root或设置即可使用。 Termux 会自动进行最小安装 - 使用 APT 包管理器即可获得其他软件包。可以从 官方网址 进行下载。 Linux 中很多命令 Android 中都没有，下载又很麻烦，所以使用这个终端可以方便运行各项命令，因为可以直接使用包管理来进行软件下载。 使用 投屏 因为存在需求要把安卓的屏幕投射到电脑上，所以下载了 晨钟酱 的 投屏控制器，虽然启动的慢，但是它可以进行黑屏启动，这样就不需要被手机的息屏给打断了。不过后续发现，过一段时间，这个也会和 QtScrcpy 一样黑屏不显示，所以还是推荐使用 QtScrcpy，毕竟它启动的快一些。 20241128221636 ","date":"2024.11.24","objectID":"/blog/posts/config/android-phone/:0:0","tags":["config","android"],"title":"安卓手机配置","uri":"/blog/posts/config/android-phone/"},{"categories":["android"],"content":"借鉴 《程序员的自我修养》，ELF视频 和 文字记录 做的笔记。主要想要探究一下 ELF 的链接和装载。 基础配置 分析文件 这里以 ARM-v8a 架构中的 ls 举例讲解 ELF 文件格式。 使用 /system/bin/ls 文件来进行分析，首先将其复制一份放在 /data/local/tmp 目录中，之后 pull 到本地使用 010 Editor 进行修改，然后再 push 上去运行验证。下面为了方便采用 bat 脚本执行。 adb push ls /data/local/tmp/ls adb shell \"chmod 777 /data/local/tmp/ls\" adb shell \"cd /data/local/tmp \u0026\u0026 ./ls\" 要提及一下 Toybox，它是一个小型、高效的命令工具集，为嵌入式系统和 Android 提供了常用命令的实现。同时它也是单一的可执行文件，集成了多个常用命令，如 ls、cp、mv、mkdir 等。我们使用的 ls 就是 Toybox 的软链接，它通过识别程序调用时的名称（即 argv[0]）决定执行的具体命令。所以我尝试把 ls 更改名称为 modify-ls，一开始能用，然后后面就报错 toybox: Unknown command modify-ls 了，所以还是使用原来的名称。 elf_header 20241124111008 上图就是 elf_header 的结构，它包含数个结构信息。下面主要展示真正起作用的部分和相关知识点，其余没有用处的部分一笔带过，这里有没有用处的评价标准是相对于在 Linux 中正常运行而言的，不影响运行就是没有作用的。 结构分析 e_ident elf_header 下面有一个子结构体 e_ident，它里面其实只有第一个 file_identification 是有用的，并且是固定的，为 .ELF。 20241124111154 其余的属性，例如 ei_class_2_e，它是用来描述 elf 的位数的，32位和64位。但是实际上 linker 加载该 elf 文件的时候，根本不会在意这个值。如果把这个结构中除了 file_identification 全部更改为 EE（FF为 -1，可能存在作用），程序依然可以正常运行。 e_type 这个的值虽然是一个枚举，但是是实际上无论是 exe 还是 so，它们的值都必须是 ET_DYN (3) ，如果是一个 exe 文件，将这个值改成 ET_EXEC (2)，它反而不能运行。 e_machine 这个字段说明 CPU 平台，比如 x86，arm32，arm64 等。如果这个地方给错了，不能正常运行。 e_entry_START_ADDRESS 这个是 elf 加载到内存时执行的初始地址，也就是程序加载后，加载器将控制权转移到的第一条指令地址，通常是 _start 函数的地址，之后这个函数会调用 libc 的启动函数 __libc_start_main，而 __libc_start_main 就会调用用户定义的 main 函数。这里它是一个虚拟地址，表示的相对偏移，真实的虚拟地址 = 加载的虚拟地址的基址 + 这个相对偏移。 PROGRAM_HEADER_OFFSET 指 e_phoff_PROGRAM_HEADER_OFFSET_IN_FILE，它是 program_header_table 段的偏移。elf_header 后面就是 program_header_table，斯普哦它一般也是 elf_header 的大小。除非有人故意在这两者之间插入一些无用的数据。 SECTION_HEADER_OFFSET 指 e_shoff_SECTION_HEADER_OFFSET_IN_FILE，它表示 section header table 段的偏移，但是没有什么用处，实际上跟 section 有关的都没啥用，因为 elf 加载的时候根本就不使用 section 相关的东西。上面是 Android 8 之前的版本，而 Android 8 及以后还是会读取 section header的，但不是所有的 section 都会读取。但是我使用 Android 9 进行实验，SDK 为 28，我发现按照之前的修改方式进行，程序还是可以运行。这里是 Android14 的 linker 代码，可以看到它存在 ReadSectionHeaders()、ReadDynamicSection() 函数来读取相关信息。 20241124115041 但是 IDA 是使用 section 来进行解析的。我们将 section header 都覆盖为 EE。之后可以正常运行，但是 IDA 解析一开始会报错，之后发现解析不了段信息。实际上加载一个 so 文件的时候，IDA 的 segment view 里面就是解析的 section header。如果我们破坏了甚至是弄一个假的 .text/.data section，那么 IDA 就没有办法正常解析了。 20241124115521 其余信息 e_ehsize_ELF_HEADER_SIZE：没有用处，加载的时候根本不检查，它是根据位数的默认大小，所以改动 elf_header 的大小会有不可预料的后果 e_phentsize_PROGRAM_HEADER_ENTRY_SIZE_IN_FILE：program_header_table 是一个数组，这个表示数组中每个元素的大小 e_phnum_NUMBER_OF_PROGRAM_HEADER_ENTRIES：这个表示上面数组中元素的个数 总结 所以最后可以把 elf_header 修改成下面的形式，它也是可以正常运行的。下面保留的相关结构就是 file_identification、e_type、e_machine、e_entry_START_ADDRESS、e_phoff_PROGRAM_HEADER_OFFSET_IN_FILE、e_phentsize_PROGRAM_HEADER_ENTRY_SIZE_IN_FILE、e_phnum_NUMBER_OF_PROGRAM_HEADER_ENTRIES。 20241124145051 program_header_table 这是一个数组，拥有数个元素结构体 program_table_element，元素个数和元素大小都在 elf_header 中展示出来了。这里是对单个元素结构进行分析，它每一个元素结构描述的都是内存和文件的对应关系。 20241124150034 结构分析 p_type 段类型，为 1 表示可加载段，然后根据读写权限可以分成代码段和数据段。这两个可加载段最为重要，其它段就是服务这两个段而存在的。 p_flags 段属性。表示段为可读，可写，可执行等。对于加载段很重要，区分了代码段和数据段，其它段就基本没什么意义。 FROM_FILE_BEGIN 指 p_offset_FROM_FILE_BEGIN，它表示段在文件中的偏移，可以直接在文件中根据偏移进行查看。 VIRTUAL_ADDRESS 指 p_vaddr_VIRTUAL_ADDRESS，它表示段的虚拟地址。它表示的是一个相对偏移，因为段被加载到的虚拟地址是不确定的，所以真实的虚拟地址 = 加载的虚拟地址的基址 + 这个相对偏移 PHYSICAL_ADDRESS 指 p_paddr_PHYSICAL_ADDRESS，它表示段的物理地址。因为都运行在用户态，没有物理地址的概念，所以所有段的这个都没有用。段只有虚拟地址才有意义。 SEGMENT_FILE_LENGTH 指 p_filesz_SEGMENT_FILE_LENGTH，表示段在文件中的长度。 SEGMENT_RAM_LENGTH 指 p_memsz_SEGMENT_RAM_LENGTH，表示段在内存中的长度。 p_align 段的对齐方式。ELF 中的对齐都是内存对齐，不存在文件对齐，它都是密集排列的。它没有什么作用，加载器中写定了内存对齐都是 4K。 文件内存映射 program_header_table 中的每个元素，描述的其实是将段加载到内存中时，elf文件中的段映射到了内存中。 p_offset_FROM_FILE_BEGIN 与 p_filesz_SEGMENT_FILE_LENGTH 表示了文件中的段。 p_vaddr_VIRTUAL_ADDRESS 与 p_memsz_SEGMENT_RAM_LENGTH 表示了内存中的段。 这两者构成一个映射关系，linker 在加载 elf 的时候采用的是 mmap。p_filesz_SEGMENT_FILE_LENGTH 与 p_memsz_SEGMENT_RAM_LENGTH 的大小不一定一样，因为为了节省 elf 文件大小，有些值为 0 的段，比如 .bss 就不占文件空间。但是加载到内存后，还是要分配空间的。 Program Header 这个段里只有两块数据有用，其余都可以忽略。 20241124194018 文件偏移与虚拟地址，它们都是 0x40，而且这个值与 elf_header 必须是相等的。这个值某种意义上就是 elf_header 的大小。那为什么还需要在这里再储存一次呢？ 可以简单理解，linker 里面有一些指针指向的是 elf_header，而有些指针指向的是 program_header，互相转换的时候，会使用指针偏移来计算，偏移大小就是这里的 0x40，所以就在这里也记录了值，偏于","date":"2024.11.24","objectID":"/blog/posts/android/elf/:0:0","tags":["reverse","android"],"title":"ELF 解析","uri":"/blog/posts/android/elf/"},{"categories":["config"],"content":"记录一下 IDA 的使用。 下载 这里贴一个 IDA9.0rc1 的 来源，虽然不是从这里获取的资源，但是想来应该都差不多。之后就是使用评论区给出的 keygen2.py 文件进行 patch 和生成 License，也就是 idapro.hexlic 文件，这样就可以正常使用了。 配置 修改 python 版本 想让 IDA 使用自己的 python，那么就需要进行相关配置，这里直接使用 idapyswitch.exe 进行切换即可，下面的命令就会更改 IDA 使用的 python 版本。我这里使用的是 miniconda 的虚拟环境，但是都是一样的，只要找到 python3.dll 就行。 .\\idapyswitch.exe --force-path E:\\xxxxx\\miniconda3\\envs\\re\\python3.dll 插件 IDA 有很多好用的插件，但是按照之前 beta 的版本，有一些会产生冲突，所以这里记录目前可以使用或者被修改过的插件。 keypatch 从 修改仓库 获取的，直接把 keypatch.py 放在 plugins 目录中就可以使用了。具体使用可以看链接的 README 文件 lazyida 从 官方仓库 获取的，作者修改了错误的地方，配置方式和上面一样，具体使用也是看 README。 D810 从 官方仓库 获取的，反正最开始的时候没有报错，当作可以正常使用 🐶。之后使用时选择适当的规则，然后点击 start，就可以按 F5 自动反编译，解决 OLLVM 混淆。如果已经存在 F5 缓存，可以将一段代码 nop 掉，之后撤销操作，再 F5 反编译即可 20240115213925148 findcrypt-yara 从 官方仓库 获取之后，把 findcrypt3.py 和 findcrypt3.rules 放在 plugins 目录中。之后因为 yara-python 版本的问题，需要进行 修正，直接将下面的代码覆盖原来的即可。同时也可以给 rules 添加国密SM4算法的识别规则。 def yarasearch(self, memory, offsets, rules): print(\"\u003e\u003e\u003e start yara search\") values = list() matches = rules.match(data=memory) for match in matches: for stringR in match.strings: name = match.rule for string in stringR.instances: if name.endswith(\"_API\"): try: name = name + \"_\" + idc.GetString(self.toVirtualAddress(string.offset, offsets)) except: pass value = [ self.toVirtualAddress(string.offset, offsets), match.namespace, name + \"_\" + hex(self.toVirtualAddress(string.offset, offsets)).lstrip(\"0x\").rstrip(\"L\").upper(), stringR.identifier, repr(string.matched_data) ] idaapi.set_name(value[0], name + \"_\" + hex(self.toVirtualAddress(string.offset, offsets)).lstrip(\"0x\").rstrip(\"L\").upper() , 0) values.append(value) print(\"\u003c\u003c\u003c end yara search\") return values ipyida 可以在 IDA 中配置 ipython 来执行 python 代码。直接从 官方仓库 执行命令下载即可。然后使用 Shift + . 就可以打开进行使用了，注意 exit 的使用，它会直接退出 IDA，然后分析文件会遗留，但是是分散的格式。 bindiff 直接去 官网 下载 bindiff，我这里下载的是 bindiff 8。然后在它的 Plugins 目录下存在 IDA 的插件，我这里是找到 IDA-9.0-rc1 的 适配 版本，直接放到 IDA 的 plugins 目录下，然后点击 File 就可以看到 bindiff 并使用了。 使用 可以查看别人的 博客1、博客2、博客3 来学习具体的使用方法和小技巧。 日常使用 这里补一下 IDA 官方快捷方式，这个更为全面。 主要操作 ctrl + e：找到main函数 Shift + f12：可以打开 string 窗口，一键找出所有的字符串，右击 setup，对窗口的属性进行设置。同时附加时使用可以显示 strings Shift + f7：可以查看 Segments 窗口。查看不同的段 空格：在 Text View 和 Group View 中来回切换 f5/Tab：一键反汇编，Tab 可以在汇编界面与伪代码界面来回切换 Ctrl + X：交叉引用 Alt + T：在汇编界面中搜索汇编语言 Shift + E：提取数据 Ctrl + Shift + W：保存快照，它会生成一个新的 ida 数据库文件，本质为另存为 插件操作 Ctrl + Alt + K：(Keypatch快捷键) 进行patch Shift + .：打开 ipyida 插件 类型更改 D 转换为原始数据 C 转换为汇编代码 P 重新生成函数 a 将数据转换为字符串，主要可以应对小端序存储 N 更改变量的名称 Y 更改变量的类型，比如把 _int64 更正为 BYTE*（或者 char *） U undefine，取消定义函数、代码、数据的定义，转化为原始字节的形式 V 简化函数的格式，有时候函数没有 return 时可以使用，查看更方便 M 枚举所有相同的数据 ; 在反汇编后的界面中写下注释 / 在反编译后伪代码的界面中写下注释 \\ 在反编译后伪代码的界面中隐藏/显示变量和函数的类型描述 有时候变量特别多的时候隐藏掉类型描述看起来会轻松很多 右键点击 Hide casts 也可以隐藏类似 *(DWORD) 的类型描述 动态调试 快捷键 F2 增加断点 F7 单步步入，遇到函数，将进入函数代码内部 F8 单步步过，执行下一条指令，不进入函数代码内部 F4 运行到光标处（断点处） F9 继续运行 Ctrl + F2 终止一个正在运行的调试进程，重新开始调试 Ctrl + F7 自动步入，在所有的函数调用中一条一条地执行命令，断点或异常时，自动停止 Ctrl + F8 自动步过，一条一条的执行命令，程序到达断点，或者发生异常时，自动步过过程都会停止 附加 应对一些强壳，可以先启动 .exe 程序，之后使用IDA的附加功能 (Debugger-\u003eattach)，附加进程，可以越过壳。之后可以使用 Shift + f12 和 Shift + f7 定位关键字符位置和段属性，将该程序的 Code 段使用 IDAPYTHON 转化为反汇编形式进行动调。 from ida_ua import * cur_addr = 0x401000 #起始地址 end_addr = 0x410000 #终止地址 def make_insn(start,end): adr = start out_ins = insn_t() while True: if(adr \u003e= end): break create_insn(adr) size = decode_insn(out_ins,adr) adr += size print(\"end!\") make_insn(cur_addr,end_addr) print(\"Done\") 可能 Code 段很大，编译很慢，可以结合手动按c反汇编结合查看 ELF 文件 以下就是注意事项，具体流程直接上网查找即可。 Linux开启远程连接服务，在虚拟机中打开 IDA 在 Linux 中的调试工具 首先需要将文件提权，否则不能运行，也就不能调试了 IDA连接虚拟机，开始动调 Linux进行附加时，需要先打开 linux_server 服务，然后另起端口打开运行的程序，之后就可以附加了。这里需要先使用 sudo vim /etc/sysctl.d/10-ptrace.conf 更改最后一行 kernel.yama.ptrace_scope = 0，重启系统后，普通用户就可以使用 attach ID 连接程序调试了。 注意 wsl 的 Hosrname 可以设置为 127.0.0.1，有时候设置成 wsl 的 ip 不太起效果 为了方便 IDA 中的 application，可以使用 realpath ./file 直接获取文件的路径 idapython idapython 可以对相关数据进行操作，学习可以参照下面的文章。 IDA Python 使用总结 相关技巧 从IDA中获取数据时，如果在分析程序中发现数据的排列为 qword 等，建议不要以小端序转化，而是直接从 IDA 的 IDA View-RIP 界面复制，不用 Ctrl + e 提取数据。除此之外， qword 的转化可能会出现一些多余数据，记得识别 这里补充一点：若是在 IDA View-RIP 界面中的数据不是正规数据（这里指十六","date":"2024.11.20","objectID":"/blog/posts/config/ida/:0:0","tags":["config"],"title":"IDA 配置和使用","uri":"/blog/posts/config/ida/"},{"categories":["AI"],"content":"这里记录在学习人工智能，主要是大语言模型时的相关知识点，用以梳理逻辑。 人工智能相关 基础概念 简单而言，人工智能是一个很宽泛的概念，只是一个广义上的称呼，这里主要还是区分机器学习、神经网络、深度学习的相关概念。 机器学习：这是人工智能的基础，通过提供大量样本数据来建立模型，以识别和预测新的事物。例如，通过输入一张图片并经过一系列的运算后，模型可以判断这张图片属于哪一类。机器学习的核心目的是从数据中发现模式和规律，并通过构建一个模型来处理数据，实现预测和决策。通过训练数学模型，机器学习能够根据已知的数据和结果的映射关系，在遇到新数据时准确预测输出结果。 神经网络：神经网络模仿动物大脑的结构和功能，本质上是用数学公式来构建模型。它是机器学习的一个分支。机器学习本身依赖数学公式进行计算，而神经网络的特别之处在于拥有大量“神经元”，即隐藏层。可以简单地理解为，机器学习是基于数学公式建模的总体概念，而神经网络和其他方法（如k-means聚类）则是不同的具体实现形式，主要差异体现在算法，即数学公式的不同。如下图，机器学习的每个类别对应一种算法。具体细节可参考这个视频，虽然标题涉及机器学习，但讲解的重点主要是神经网络的原理和概念。同时也可以观看这个视频，讲解更为细致全面。 深度学习：这是人工神经网络的一个特例，其复杂性远超一般神经网络。深度学习通过增加神经网络的隐藏层数量来实现更高难度的任务。与一般神经网络相比，深度学习网络结构更为深层和复杂。其他类型的神经网络是在不同方面进行了改进，因此产生了不同的类别，但它们都包含隐藏层这一特征。 20241113125354 更为详细的解释可以看这篇文章，讲述了更为细节的内容。 大语言模型 自然语言处理阶段 第一阶段：统计模型 + 数据（特征工程） 决策树、SVM、HMM、CRF、TF-IDF、BOW 第二阶段：神经网路 + 数据 Linear、CNN、RNN、GRU、LSTM、Transformer、Word2vec、Glove 第三阶段：神经网络 + 预训练模型 + （少量）数据 GPT、BERT、ROBERTa、ALBERT、BART、T5 第四阶段：神经网络 + 更大的预训练模型 + Prompt ChatGPT、Bloom、LLaMA、Alpaca、Vicuna、MOSS、文心一言、通义千问、星火 Transformer 使用 GPT 进行举例，它的全称为 Generative Pre-trained Transformer。显而易见，Transformer 就是它技术的关键所在，这里可以通过这篇文章详细了解它们之间的联系，以及 Transformer 的核心 Self-Attention。然后这个视频更为细致的讲解其底层知识。 ","date":"2024.11.12","objectID":"/blog/posts/ai/ai_knowledge/:0:0","tags":["AI"],"title":"AI Knowledge","uri":"/blog/posts/ai/ai_knowledge/"},{"categories":["android"],"content":"RiskGuard app 的总览，介绍该项目的相关信息。 UI 设计 跟随 Project Manager 进行 UI 设计，采用 kotilin 进行了实现，延续该项目的配色风格，在此基础上添加自己的模块。这里补充一下状态栏的设计，在 res/values/themes.xml 中删除 style 标签下所有内容，转化为下面的内容，那么状态栏就会透明的，图标和文字为深色，这样 UI 会更适配。 20241111221551 展开二级列表 一开始是想的实现珍惜大佬 hunter 的 UI 设计，所以一直寻找可折叠的 textview 项目，但是发现都不尽如人意。直到找到了 ExpandableRecyclerView 这个项目，所以就使用这个进行二级列表的设置。也因此改为 kotilin 作为 UI 界面的语言，这样便于直接进行代码移植。之后把之前的设备信息获取代码移植后，配置了列表的折叠和展开后，也添加了一个全部展开/折叠功能。 ","date":"2024.11.9","objectID":"/blog/posts/android/riskguard/:0:0","tags":["android"],"title":"RiskGuard","uri":"/blog/posts/android/riskguard/"},{"categories":["programming"],"content":"学习 C++ 的使用，主要区分 C++ 和 C 的区别。 C++ 历史速览 这里通过求和的案例来记录 C、C++98、C++11、C++17 的变化。 古代 C 语言，采用 malloc 和 free 来管理内存，同时数据需要自己进行定义，并通过 for 循环实现求和操作。同时打印采用 printf，需要声明打印数据的类型才可以正确打印。 #include \u003cstdlib.h\u003e #include \u003cstdio.h\u003e int main() { size_t nv = 4; int *v = (int *)malloc(nv * sizeof(int)); v[0] = 4; v[1] = 3; v[2] = 2; v[3] = 1; int sum = 0; for (size_t i = 0; i \u003c nv; i++) { sum += v[i]; } printf(\"%d\\n\", sum); free(v); return 0; } 近代 C++98 引入 STL 容器库，这样就不需要自己进行内存的释放了，离开了当前作用域会自己进行销毁。这里的创建和销毁实质上就是 STL 容器的构造函数和析构函数。同时引入了重载的 cout 函数，因此不需要指定变量类型，可以直接进行打印， #include \u003cvector\u003e #include \u003ciostream\u003e int main() { std::vector\u003cint\u003e v(4); v[0] = 4; v[1] = 3; v[2] = 2; v[3] = 1; int sum = 0; for (size_t i = 0; i \u003c v.size(); i++) { sum += v[i]; } std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } 近现代 C++11 引入了 {} 初始化表达式和 range-based for-loop 机制。这样可以通过花括号来进行赋值，并且支持通过迭代器来进行遍历，应用函数。 #include \u003cvector\u003e #include \u003ciostream\u003e #include \u003calgorithm\u003e int sum = 0; void func(int vi) { sum += vi; } int main() { std::vector\u003cint\u003e v = {4, 3, 2, 1}; // 在 \u003calgorithm\u003e 中进行实现 std::for_each(v.begin(), v.end(), func); std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } 同时近现代 C++11 还引入了 lambda 表达式。如下可以看出不需要定义全局变量 sum 了，可以对局部变量进行相关操作。 #include \u003cvector\u003e #include \u003ciostream\u003e #include \u003calgorithm\u003e int main() { std::vector\u003cint\u003e v = {4, 3, 2, 1}; int sum = 0; std::for_each(v.begin(), v.end(), [\u0026] (int vi) { sum += vi; }); std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } 现代 C++14 支持 lambda 用 auto 自动推断类型。 #include \u003cvector\u003e #include \u003ciostream\u003e #include \u003calgorithm\u003e int main() { std::vector\u003cint\u003e v = {4, 3, 2, 1}; int sum = 0; std::for_each(v.begin(), v.end(), [\u0026] (auto vi) { sum += vi; }); std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } 当代 C++17 拥有 CTAD（compile-time argument deduction），可以进行编译期参数推断，但是需要在 CMAKE 中添加 set(CMAKE_CXX_STANDARD 17)。同时还引入常用数值算法。 #include \u003cvector\u003e #include \u003ciostream\u003e #include \u003calgorithm\u003e int main() { std::vector v = {4, 3, 2, 1}; int sum = 0; std::for_each(v.begin(), v.end(), [\u0026] (auto vi) { sum += vi; }); std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } #include \u003cvector\u003e #include \u003ciostream\u003e #include \u003cnumeric\u003e int main() { std::vector v = { 4, 3, 2, 1 }; // 下面三者效果等同 //int sum = std::reduce(v.begin(), v.end(), 0, [](int x, int y) { // return x + y; //}); // 下面两种就是引入常用数值算法，主要实现在 \u003cnumeric\u003e 头文件中 //int sum = std::reduce(v.begin(), v.end()); int sum = std::reduce(v.begin(), v.end(), 0, std::plus{}); std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } 头文件 C++ 包含标准 C 语言头文件，对于原本 C 的头文件，C++ 有两种方式进行引用，一种是原有的方式（后面跟 .h），一种就是去掉 .h，在库前面添加一个 c 标识这是原本 C 的头文件。对于自己写的头文件还是原方式进行引用，即 \"\"。 #include \u003ciostream\u003e // 基本输入输出 #include \u003ccstdio\u003e // 在原来 C 语言的库前面加一个 c，去掉 .h #include \u003cstdio.h\u003e // 采用原有方式进行引用 #include \"myFile.h\" // 自己的文件，采用原有方式引用 命名空间 基础知识 命名空间增加了标识符的使用率，减少因为命名产生的冲突。对于命名空间而言，其中的变量和函数等都是属于自己这个空间的，需要通过标识空间名来指明数据的归属，这样可以使得不同命名空间可以存在同样名称的数据，它们之间不会产生冲突。 声明命名空间：namespace 空间名{}，命名空间的声明不能写在函数中 访问数据：空间名::空间中的成员名 省略前缀的方式：using namespace 空间名，表示从这个地方开始，后面都可以省略前缀。 #include \u003ciostream\u003e using namespace std; // 标准命名空间 namespace A{ int num = 1; void print(){ printf(\"A\\n\"); } } namespace B{ int num = 2; void print(){ printf(\"A\\n\"); } } namespace C{ namespace D{ int cd_num = 3; } } int g_num = 1001; int main(){ // 使用省略前缀的方式，可以直接使用其中的函数 cout \u003c\u003c \"命名空间\" \u003c\u003c endl; std::cout\u003c\u003c \"命名空间\" \u003c\u003c endl; // 不同命名空间访问数据 A::num = 2; B::print(); // 省略前缀方式访问数据 using namespace A; num = 3; // A 命名空间数据 using namespace B; B::num = 4; // B 命名空间数据，省略前缀需要注意二义性的问题，所以还需要标识命名空间 // 嵌套命名空间 C::D::cd_num = 5; using namespace C::D; cd_num = 5; // :: 为作用域分辨符，同时可以用于指明全局变量 int g_num = 11; printf(\"num %d\\n\", g_num); // 变量访问采用就近原则，这里就是访问上面的局部变量，返回 11 printf(\"num %d\\n\", ::g_num); // 使用作用域分辨符，指明访问全局变量，返回 1001 return 0; } 内联命名空间 对于嵌套命名空间，访问需要使用多层空间名，但是可以采用内联命名空间的方式直接进行访问。 #include \u003ciostream\u003e using namespace std; namespace Version{ inline namespace v2017{ void showVersion(){ cout \u003c\u003c \"v2017\" \u003c\u003c endl; } } namespace v2020{ void showVersion(){ cout \u003c\u003c \"v2020\" \u003c\u003c endl; } } } int main(){ // 上面采用内联命名空间，即添加了 inline，设置了默认的情况，使得下面的两个语句效果等价。 // Version::v2017::showVersion(); Version::showVersion(); } 动态内存分配 C ","date":"2024.11.6","objectID":"/blog/posts/programming/cpp/:0:0","tags":["programming"],"title":"C 拾遗和 C++ 学习","uri":"/blog/posts/programming/cpp/"},{"categories":["config"],"content":"关于 Android Studio 的使用和配置。 Gradle下载配置 直接更换国内腾讯 镜像源，打开 gradle - wrapper -gradle-weapper.properties 进行更改。然后点击 Sync Now 进行同步。参考-\u003e Android导入项目时Gradle下载速度慢_导入gradle项目特别慢 #Sun Feb 25 20:22:32 GMT+08:00 2024 distributionBase=GRADLE_USER_HOME distributionPath=wrapper/dists distributionUrl=https\\://mirrors.cloud.tencent.com/gradle/gradle-8.2-bin.zip # 这里就对应替换为腾讯的镜像地址 zipStoreBase=GRADLE_USER_HOME zipStorePath=wrapper/dists 但是这样也是很慢，还是得等，有时候还会突然跑到源地址去下载，搞不明白。(后续补充：有时候改了国内源，然后停止加载zip文件，之后重试一下就快很多了) 新版 AS 添加依赖 这里是在 settings.gradle.kts 文件中添加 maven 仓库，然后在 app 的 build.gradle.kts 文件中添加依赖。查看这里Android Studio | 2022.3.1版本解决创建项目下载gradle缓慢问题 // settings.gradle.kts 文件中 dependencyResolutionManagement { repositoriesMode.set(RepositoriesMode.FAIL_ON_PROJECT_REPOS) repositories { google() mavenCentral() maven { url = uri(\"https://jitpack.io\") }// as改版后的新添加方式 } } // build.gradle.kts 文件中 dependencies { implementation(\"com.github.Hitomis:CircleMenu:v1.1.0\") // as改版后的新添加方式 } SD卡读写权限 对于低版本 sdk，只需要以下权限即可(在AndroidManifest.xml中修改)，在manifest标签中添加 \u003cuses-permission android:name=\"android.permission.READ_EXTERNAL_STORAGE\"\u003e\u003c/uses-permission\u003e \u003cuses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\"\u003e\u003c/uses-permission\u003e 而对于高版本的 sdk，这里是34，则需要添加东西。新加入的在application标签中添加 \u003cuses-permission android:name=\"android.permission.READ_EXTERNAL_STORAGE\"\u003e\u003c/uses-permission\u003e \u003cuses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\"\u003e\u003c/uses-permission\u003e \u003cuses-permission android:name=\"android.permission.MANAGE_EXTERNAL_STORAGE\"\u003e\u003c/uses-permission\u003e android:requestLegacyExternalStorage=\"true\" dataBinding使用 刚开始创建的 Launch Activity 不用理会，但是对于新增加的Activity，想要使用 dataBinding 功能，就需要先在 build.gradle.kts文件中添加下面代码： android { ...... buildFeatures { dataBinding = true // 确保这里启用了数据绑定 } } 然后在相关 xml 文件中，对准 androidx.constraintlayout.widget.ConstraintLayout按下alt + enter 转化为 databinding 的模式。这样后续的 activity 才可以使用并编译apk成功。 图片导入 资源主要就是存放在 res 目录下，如下表所示各个目录的作用。 目录 作用 drawable 存放所有的图片及图标配置（xml文件展示） layout 布局，创建一个Activity一般会同步创建一个布局。 mipmap 存放各种分辨率的图标，平常用的就是 xxhdpi values 一些固定的配置，例如值，主题等 这里 drawable 存放的东西大多就是 图标的配置，在 As 中可以利用 File → New → Android Resource File 来生成一个配置文件，例如背景之类的可以重复使用。 同时使用File → New → Image Asset 可以创建 app 应用的图标，提供 svg 图片即可自动创建。使用File → New → Vector Asset 则是创建图片，将一个 svg 格式的图片转化为 xml 文件形式，然后供 ImageView 等控件使用。如果只有 png 格式的图片，首先需要转化为 svg 格式，这里推荐网站，其余网站转化的 svg 可能存在问题，As 不一定可以使用。 So文件生成 添加新文件 对于头文件 .h，首先在 cpp 目录下创建相应文件，然后在 CmakeLists.txt 文件中添加下面的代码 include_directories( basic.h ) 对于文件 .cpp，在 cpp 目录下创建，然后在 CmakeLists.txt 文件中的 add_libraty 添加新创建的 .cpp文件。这样多个 .cpp 文件就会编译为一个 so 库。 add_library(${CMAKE_PROJECT_NAME} SHARED # List C/C++ source files with relative paths to this CMakeLists.txt. native-lib.cpp checkfrida.cpp) 20241105172840 编译多个so文件 这里就是再添加一个 add_library 文件，这样就可以编译为多个了。 add_library( # so 文件的名字 checkroot # 共享库 SHARED # List C/C++ source files with relative paths to this CMakeLists.txt. checkroot.cpp) 20241105173015 引入第三方库 使用第三方库的函数，这里就是利用 target_link_libraries 进行引用，注意对于每一个so文件，都需要进行引用操作。这里上面的是默认的，要是能在 checkroot.cpp 文件中使用 log，那么就需要自己手动进行引用了。 target_link_libraries( checkroot # List libraries link to the target library android log ) 20241105173045 使用汇编配置 起因就是需要使用 SVC 这条汇编语句完成 frida 的检测，但是查阅资料不知道怎么进行，最后终于尝试成功了，在此记录流程。 代码设置 这里是复制 参考资料 的代码，然后做了删减达到了下面的效果。 bionic_asm.h ，它包含了汇编语言需要的一些基础配置，例如 \u003casm/unistd.h\u003e 中的系统调用号，MAX_ERRNO 是最大错误号的定义。最为关键的就是对于 ENTRY 和 END 的定义，没有这个定义，下面的汇编语言也就是会识别错误。同时这里和下面的 syscall.S 文件一样，只定义了 aarch64 ， x86_64 两个架构，所以在build.gradle.kts 的 abiFilters 选项也只能存在两个架构，不然会因为其他架构的汇编不存在而报错。 #pragma once #include \u003casm/unistd.h\u003e /* For system call numbers. */ #define MAX_ERRNO 4095 /* For recognizing system call error returns. */ #define __bionic_asm_custom_entry(f) #define __bionic_asm_custom_end(f) #define __bionic_asm_function_type @function #define __bionic_asm_custom_note_gnu_section() #if defined(__aarch64__) #define __bionic_asm_align 16 #elif defined(__x86_64__) #define __bionic_asm_align 16 #endif #define ENTRY_NO_DWARF(f) \\ .text; \\ .globl f; \\ .balign __bionic_asm_align;","date":"2024.11.5","objectID":"/blog/posts/config/android-studio/:0:0","tags":["config","android"],"title":"Android Studio 配置","uri":"/blog/posts/config/android-studio/"},{"categories":["config"],"content":"自己对于 FixIt 主题的一些配置 大致流程 这里我使用的就是Git 子模块的安装方式，更详细的流程参照这篇快速上手。在必要的配置后，博客就可以进行本地浏览了。之后我使用 Github Action 的方式，将本地博客的所有文件上传到一个私密仓库，之后创建 Github Action 将通过 hugo --gc --minify 命令构建的 public 目录上传到另一个公开仓库 blog 中，这样就可以设置静态网站进行博客访问了，具体可以参考Huogo 主题配置。这样博客基本上就好了，可以开始额外的操作了。 图片自适应 我使用的图片都是存储在图床中的，使用的就是 Markdown 的经典语法。但是它在 FixIt 的渲染中会左对齐，有时还会在图片后面跟随文字，感官很不好，所以思考怎么进行改进。在参考FixIt主题使用lightgallery自适应显示图片之后，自己进行了调整，达到了现在的效果。 这里主要参照上述参考文章的两种尝试，采用 lightgallery 来呈现图片。我参照 FixIt配置篇 将 lightgallery 设置为 \"force\" 但是如果没有 alt 和 title 属性，我的图片不会按照画廊形式呈现，所以我只能另辟蹊径。因为我使用 PicGo 进行图床配置，刚好它支持修改本地输出图片链接的格式，因此我修改PicGo的配置，把 Custom Output Format 配置为![${uploadedName}](${url} \"${uploadedName}\")。这样它会自己填充 alt 和 title，我只需要按照自身需求修改 alt 属性即可。 另外点击图片之后会显示 alt 和 title 两个信息，所以打开 F12 进行观察，发现第一行来自标签 \u003ch2\u003e，也是 alt 属性，第二行来自标签 \u003cp\u003e，是 title 属性。这部分都是在 themes/layouts/partials/plugin/image.html 中，所以直接修改主题文件，把这里的 \u003cp\u003e 删除，然后 \u003ch2\u003e 移动到中间，这样渲染的时候只会在下面出现 alt 属性了，放大图片和鼠标移动到图片上才会看到 title 属性。 20241101122906 GitHub 提交记录贪吃蛇动画 参照GitHub 提交记录贪食蛇动画进行配置，不过我将 Github Action 写在了同名仓库中了，这样就少创建了一个仓库，其他都是按照参考文章所述的进行配置即可。插一嘴，本来想把 github-metrics.svg 单独放在一个分支中，但是不熟悉自动化部署脚本，配置了一会儿发现总是部署失败，所以直接使用GitHub 个人主页美化教程来进行配置了。 配置文章修改时间 Fixit 的 frontmatter 有一个属性 lastmod，它就是文章最后修改时间，一开始的配置不知道有没有效果，但是还是参照 loveit主题配置 之后，形成了现在的配置。 当前配置是在 atchetypes/default.md 文件中，设置 lastmod: {{ .Date }}。config/_default/hugo.toml 中设置 enableGitInfo = true， 同时在 config/_default/params.toml 中，找到 [gitInfo] 选项，设置 repo 为自己 public 目录发布的仓库地址。这样就会在文章左下角和一开始的信息标识处显示更新时间。 这里的文章修改时间很玄学，要么新创建的文章上面信息展示的地方没有修改时间，要么地下的修改时间没有提交的 hash 值，要么修改的文章信息没有变化。最近一次成功修改还是通过 git 将 content 和 public 中的所有文件都删除，然后再提交之后才可以进行时间修改的，但是这个时候所有文章的修改时间都一样了。所以目前初步认为起关键作用的还是 content 目录下面文件的 git 提交时间，之后修改了文件，就不直接使用 add 进行添加了，而是把文件先删除，之后再提交，这样不知道会不会正确显示修改时间。 验证发现 git add . 也能发挥作用，但是修改后直接进行 hugo --gc --minify 提交发现不会出现修改信息，之后本地使用 hugo server -D 反而出现了修改时间。之后尝试首先本地部署，再进行生成，发现该效果会呈现出最新的修改时间。（这里的办法没用，目前得到的信息就是本次的修改不会改变本次的修改时间，只有下一次的 push 才会真正显示出上一次的修改，所以目前只能这样了，只要修改时间不像之前一样突然没有了就行）。 网站图标 对于网站图标实在是束手无策，一开始采用官网配置，但是给的利用网站不能生成符合要求的一系列文件，同时把生成文件都放在/static目录下，最后会把这些文件生成在/public根目录下，很不喜，所以放弃了这种方法。后来尝试和 author 的 avatar 属性配置一样，把 svg 图片放在images目录下，但是展示不出来。最后看到别人文章，发现直接使用图床的图片可以生成，所以我现在也是利用这样的方式展示网站图标。 阅读原始文档 可以看到左下角存在 阅读原始文档 的选项，点击就直接可以看到 markdown 的原文本了，当然这个是我们不想要的（虽然网页直接下载 pdf 也是一样的）。因此我们可以设置配置中的 outputs.toml 文件，在 page 中去除 markdown，这样点击就不会看到我们的源码了。 20241109163031 Git 提交 受上面 配置文章修改时间 的影响，记录下这里的 git 操作，以便之后忘记了还可以看这里进行会议。 # 本地预览渲染效果 hugo server -D # 最小化生成渲染文件 hugo --gc --minify # 将修改和新增的文件信息都添加到暂存区 git add . # 将删除文件信息添加到暂存区 git rm xxx # 根据暂存区信息提交代码到本地仓库 git commit -m \"xxx\" # 推送本地仓库代码到远程仓库 git push -u origin main 经过上面的操作，就会把代码传到 github 上了，之后使用 GitHub Action 把 public 传到公开仓库中，之后就可以根据静态页面进行查看了。这里还可以使用 Vscode 的提交板块，它应该和 jetbrains 的产品一样，内置了删除的操作，所以我们只需要写 commit 信息然后一直点击按钮就可以进行提交了，不需要区分添加修改和删除操作（这里我没有试过，只是猜测，但是 jetbrains 和 As 的 commit 是这样设计的）。 数学公式 本来这个只是一个小问题，但是后来发现只要公式渲染出现问题，大概就是这个原因，所以记录一下 fixit 的数学公式渲染。主要的解决方案就是在 fixit 数学公式 的“关于转义字符相关的注意事项”，这里就是 Hugo 渲染的时候，数学公式中的有些字符和 HTML 产生冲突，所以需要转义处理。这里已经罗列了很多需要转移的字符，但是除此之外还有一些，这里通过 Latex 语法来显示额外也需要进行转义的字符： { -\u003e \\\\{ } -\u003e \\\\} $ -\u003e \\\\$ 报错归纳 github action 报错 在使用 GitHub Action 时，一直采用的 hugo-version: latest，本来没什么问题，但是 24 年年初出错了，显示了下面的内容。 20250103210011 然后到处纠错，尝试根据报错把上面 阅读原始文档 图片中 home 一栏的 search 给删除，但是会向前报错 offline。于是怀疑时因为 Fixit 更新导致的问题，于是将这个更改为本地版本号，发现成功自动化部署。于是之后就把 version 固定为下面临近一次成功部署的版本号，之后尝试成功，可以使用。 20250103210437 ","date":"2024.11.1","objectID":"/blog/posts/config/fixit/:0:0","tags":["config"],"title":"Fixit 配置","uri":"/blog/posts/config/fixit/"},{"categories":["config"],"content":"一些关于 git 的操作，更多可以看看 深入Git。 20241101105334 相关命令 # 本地仓库初始化 git init # 将文件提交到暂存区 git add \u003cfile_name\u003e git add . # 添加全部修改和新增文件 # 将文件提交到本地仓库 git commit -m \"commit information\" \u003cfile_name\u003e git commit -m \"commit inforamtion\" # 提交全部到本地仓库 # 添加远程仓库，这里是因为存在多个 git 用户所进行的配置，正常为 git@github:czTangt/blog.git git remote add origin git@github_czTangt:czTangt/blog.git # 提交到远程仓库 git push -u origin \u003cbranch_name\u003e git push -f # 强制提交 # 拉取远程仓库 git pull \u003cremote_name\u003e \u003cremote_branch_name\u003e # 这里是从远程仓库 remote_name 拉取指定分支 remote_branch_name 的更新并合并到当前分支。 # remote_name 通常是远程仓库的别名，例如默认的 origin，表示克隆时配置的远程仓库。 # git pull 是 git fetch 和 git merge 的组合操作，首先获取远程更新，然后尝试合并到当前分支。 # 分支操作 git branch -a # 查看所有分支 git branch \u003clocal_branch_name\u003e # 创建本地分支 git checkout \u003clocal_branch_name\u003e # 切换本地分支 git checkout -b \u003clocal_branch_name\u003e # 创建本地分支并切换 git branch -d \u003clocal_branch_name\u003e # 删除本地分支 git checkout -b \u003clocal_branch_name\u003e origin/\u003cremote_branch_name\u003e # 创建本地分支并与远程分支连接 git push origin --delete \u003cremote_branch_name\u003e # 删除远程分支 # 分支冲突 # 在 git 当中，通常合并分支可以自动完成。如果遇到分支冲突，需要手动选择要保留的分支，然后再次进行 git commit。 # 恢复文件为之前提交的状态 git checkout commit_version -- \u003cfile_name\u003e # 首先从 git log 获取某次提交的 commit_version，然后执行命令可以手动恢复这次提交的特定文件 文件删除 对于 Git 而言，git add . 会将所有修改、新增的文件信息提交到暂存区，之后使用 git commit -m \"xxx\" 会将暂存区的文件信息提交到本地仓库。但是这种方法是对于新增和修改的文件而言，对于删除的文件信息不会进行更新。所以可以采用两种方案： 使用 git rm xxx 一个一个手动删除文件（rm 命令可以使用 git rm -r xxx 递归目录进行删除），之后这些文件删除信息就提交到暂存区了，后续就可以继续使用 git commit -m \"xxx\" 来将代码提交到本地仓库。 使用 git commit -am 命令，该命令会在提交到本地仓库时，先更新修改和删除的文件信息到暂存区（注意它不会提交新增加的文件信息）。所以加了 -a 在 commit 的时候，可以帮助省一步 git add，但是也只是对修改和删除文件有效，新文件还是要 git add，不然就是 untracked 状态。 综上所述：git add 和 git rm 都是等价的操作，前者添加修改和新增文件信息，后者添加删除文件信息，它们都是将文件信息提交到暂存区。之后使用 git commit -m \"xxx\" 来将暂存区的文件信息提交到本地仓库，最后使用 git push -u origin main 来提交本地仓库代码到远程仓库的 main 分支。 远程仓库到自己仓库 拉取别人的仓库到自己仓库，主要应对github中没有对应仓库的情况繁琐指南，存在对应仓库，直接进行 fork，然后在本地添加自己的远程。简单的操作如下： git branch -r | grep -v '\\-\u003e' | while read remote; do git branch --track \"${remote#origin/}\" \"$remote\";done # 获取所有远程分支到本地 git fetch --all # 获取该项目远程库的所有分支及其内容 git fetch --tags # 获取该项目远程库的标签(没标签就不必了) git remote rename origin old-origin # 将原来的origin重命名一下 git remote add origin git@172.28.3.77:xs-soc/test-code.git # 指定需要迁移到新的目标地址(自己的仓库) git push origin --all # 推送所有分支及其内容 git push --tags # 推送所有标签及其内容 git remote rm origin # 删除当前远程库 git branch -M main # 重命名主要分支仓库 git push -u origin main # 推送到指定分支 Git 加速 git失败的原因绝大多数都是网络问题，所以挂代理是最为推荐的选择。以下是起作用的一些方法 通用方法，更换 git 的代理为 443 SSH：连接到主机github.com端口22：连接时间超时 但是对于 wsl，直接使用最新 wsl2 共用主机的代理即可（最为推荐），不嫌麻烦可以给配置个代理 配置wsl镜像 Windows10系统下配置WSL2自动走Clash代理，之后clash打开allow lan模式即可 WSL2内使用Windows的v2ray代理 | Nafx’s Blog，这是v2的模式，首先最后面设置，然后前面配置bashrc 有时候最后的方法会起点作用 git clone失败解决方案 clone 问题 这里某一次 git clone 时出现了克隆后文件直接显示为已修改状态问题，文件对比发现应该是换行符的问题。Git 在处理文本文件时，会根据不同平台的换行符进行处理。如果源仓库使用了不同于克隆环境的换行符，那么 Git 会将这些差异作为文件修改的一部分。所以可以使用 Git 的 autocrlf 配置将文件换行符转换为克隆环境的格式。 git config --global core.autocrlf true ","date":"2024.11.1","objectID":"/blog/posts/config/git/:0:0","tags":["config"],"title":"Some about Git","uri":"/blog/posts/config/git/"},{"categories":["Course"],"content":"记录一下对于南大软院编译原理课程的学习。 Lexer Re Automata 这里记录词法分析，正则表达式，自动机的相关知识。 正则表达式与自动机理论 课程目标 这里讲解怎么写一个自动化词法分析器生成器。根据前面的理论，我们使用 ANTLR4 来生成词法分析器，其实质上是我们使用 ANTLR4 利用正则表达式（regular expression -\u003e RE）的规则来进行生成词法分析器。同时我们还学习了利用 java 来手写词法分析器，实质就是在使用 java 代码模拟状态转移图，它也就是自动机。那么我们来看 ANTLR4 原理，他就是把 .g4 文件转化为 .java 文件，也就是把正则表达式转化为了自动机，然后通过模拟自动机就可以得到词法分析器了。 因此我们的目标就是通过正则表达式来直接得到得到一个词法分析器。 compile 由上图，我们构建词法分析器就是把 RE 转化为 DFA（有穷状态自动机 Deterministic FInite Automata），然后再转化为词法分析器，但是这个过程往往是困难的，所以我们采用简略的方法，通过先转化为 NFA（不确定的又穷状态自动机Nondeteeministic Finite Automata），再转化为 DFA，再进行后续的操作。 编程语言介绍 语言是字符串构成的集合。 根据这句高度抽象的结论，我们会一层层进行解剖。 字符 字母表 $\\Sigma$ 是一个有限的符号集合，符号没有意义，它的语义是后来自己赋予的。 字符串 字符表 $\\Sigma$ 上的串(s) 是由 $\\Sigma$ 中符号构成的一个有穷序列。 其中 $\\epsilon$ 是空串，我们定义它为零，即 $|\\epsilon| = 0$ 字符串之间存在运算 连接运算， $x = day, y = houce, xy = dayhouce, \\epsilon s = s \\epsilon = s$ 指数运算，$s^{0} \\triangleq \\epsilon$，$s^{i} \\triangleq ss^{i-1}, i\u003e0$，这里存在上标就是连接的意思 语言 语言是给定字母表 $\\Sigma$ 上一个任意的可数的串集合。 $\\empty$，这一个是空集，什么语言都没有；${ \\epsilon }$，这个里面有一个语言，不过是个空串 举例：id：${a,b,c,d,a1}$；ws：${blank, tab, newline }$，if：${ if }$ 我们知道语言是串的集合，正因为是集合，所以我们可以通过集合操作构造新的语言 compile RE 每个正则表达式 r 对应一个正则语言 L(r)。正则表达式是语法（ID：[a-zA-Z][a-zA-Z0-9]*），正则语言是语义（{a1,a2,ab,……}） 语法 给定字母表，$\\Sigma$ 上的正则表达式由且仅由以下规则定义： $\\epsilon$ 是正则表达式 $\\forall a \\in \\Sigma$，a 是正则表达式 如果 r 是正则表达式，则 (r) 是正则表达式 如果 r 与 s 是正则表达式，则 r | s，rs，r* 也是正则表达式 运算优先级：$() \\succ * \\succ 连接 \\succ |$ ，例子：$(a) \\mid ((b)^{*} (c)) \\equiv a | b^{*} c$ 语义 正则表达式对应的正则语言 $L(r)$ $L(\\epsilon) = { \\epsilon}$ $L(a) = a, \\forall a \\in \\Sigma$ $L((r)) = L(r)$ $L(r|s)=L(r) \\cup L(s)\\quad L(rs)=L(r)L(s)\\quad L(r^{*})=(L(r))^{*}$ 符号 compile compile 自动机 NFA 语法 非确定性有穷自动机 $\\mathcal{A}$ 是一个五元组 $\\mathcal{A} = (\\Sigma, S, s_0, \\delta, F)$ 字母表 $\\Sigma (\\epsilon \\notin \\Sigma)$ 有穷的状态集合 $S$ 唯一的初始状态 $s_0 \\in S$，这里的唯一不是强求，因为可以转化为唯一形态，转化方法就是前面再添加ige初始状态，然后通过 ${\\epsilon }$ 边转移到原始初始状态即可。 状态转移函数 $\\delta$，$\\delta: S \\times (\\Sigma \\cup {\\epsilon}) \\rightarrow 2^S$ 接受状态集合 $F \\subseteq S$，下图的 3 就是接受状态 这里非确定一个就是指接受统一字符的状态转移不唯一，如下图的 0 号节点，它接受字符 a 可以跑到两个状态上去；另一个就是可能存在 ${ \\epsilon }$ 边，在没有字符驱动的情况下自发的跑到另外一个状态。 compile 上面的状态转移图没有规定如果碰到其他的字符该怎么处理，所以下图就约定所有没有对应出边的字符默认指向 空状态 $\\empty$，也就是 $(\\Sigma \\cup {\\epsilon})$，它表示达到自身，也意味着一个死状态。 compile 语义 有穷自动机是一类及其简单的计算装置，它可以识别（接收/拒绝）$\\Sigma$ 上的字符串 接收 （非确定性）有穷自动机 $\\mathcal{A}$ 接受字符串 x，当且仅当存在一条从开始状态 $s_0$ 到某个接受状态 $f \\in F$ 、标号为 x 的路径。 对于上面的状态转移图，只有 3 是接受状态，因此 $aabb \\in L(\\mathcal{a}), ababab \\notin L(\\mathcal{A})$ 因此，$\\mathcal{A}$ 定义了一种语言 $L(\\mathcal{A})$：它能接受的所有字符串构成的集合。所以根据上方状态转移图，可以得到自动机语言：$L(\\mathcal{A}) = L((a|b)^*abb)$ 由上面的语义，我们可以得到自动机的两个基本问题 Membership 问题：给定字符串 $x$，$x \\in L(\\mathcal{A})?$ $L(\\mathcal{A})$ 究竟是什么？ DFA 语法 确定性有穷自动机 $\\mathcal{A}$ 是一个五元组 $\\mathcal{A} = (\\Sigma, S, s_0, \\delta, F)$ 字母表 $\\Sigma (\\epsilon \\notin \\Sigma)$ 有穷的状态集合 $S$ 唯一的初始状态 $s_0 \\in S$，这个唯一是一定需要的 状态转移函数 $\\delta$，$\\delta: S \\times \\Sigma \\rightarrow S$ 接受状态集合 $F \\subseteq S$，下图的 3 就是接受状态 compile 这里的约定就是：所有没有对应出边的字符串默认指向一个“死状态” 语义 上图的自动机语言还是 $L(\\mathcal{A}) = L((a|b)^*abb)$，也就是上面的 NFA 和下面的 DFA 等价的。因此可以看出 NFA 适合去表达一个语言，容易得出语言是什么；而 DFA 则是因为状态的转移确定，适合写词法分析器。即 NFA 简介易于理解，便于描述语言 $L(\\mathcal{A})$；DFA易于判断$x \\in L(\\mathcal{A})$，适合产生词法分析器。那么转换就是 $RE \\Rightarrow NFA \\Rightarrow DFA \\Rightarrow$ 词法分析器。 相互转换 这里就是根据下面这张图，使得正则表达式和自动机之间相互转换。 compile RE -\u003e NFA 采用 Thompson 构造法，使得 $r \\Rightarrow NFA$，要求 $L(N(r)) = L(r)$，即两个语言等价。这里就是对于正则表达式语法的每个规则来定义自动机，然后最后将这些自动机按规则进行组合就得到了 NFA。 $N(r)$ 的性质以及 Thompson 构造法复杂度分析 $N(r)$ 的开始状态和接受状态均唯一 开始状态没有入边，接受状态没有出边 $N(r)$ 的状态数 $|S| \u003c 2 \\times |r|$（$|r|: r$ 中运算符和运算分量的总和） 每个状态最多有两个 $\\epsilon \\text{-}$ 入边与两个 $\\epsilon \\text{-}$ 出边 $\\forall a \\in \\Sigma$，每个状态最多有一个 $a \\text{-}$ 入边与一个 $a\\text{-}$ 出边 自动机构造如下： compile NFA -\u003e DFA 原理 采用子集构造法，也就是用 DFA 模拟 NFA。 compile 下面就是从 NFA 到 DFA 的构造对应表，有了这张表就有了自动机。之所以是子集构造法，是因为构造出来的 DFA 对应于 NFA 的一个状态子集。同时这里因为在 NFA 中 10 是接受状态，所以在 DFA 中，对应的 E 也是接收状态。 compile 形式化描述子集构造法 这里根据上图的转化，会得到两个重要的公式： $\\epsilon$ 闭包：从状态 s 开始，只通过 $\\epsilon \\text{-}$ 转移可达的状态集合 $\\epsilon\\text{-closure}(s)={t\\in S_N|s\\xrightarrow{\\epsilon^*}t}$，这个公式的含义就是把 NFA 中的初始状态归结于 DFA 中的初始状态。上图中 NFA 的 ${0,1,2,4,7}","date":"2024.10.31","objectID":"/blog/posts/course/compilers-course/:0:0","tags":["Course","compile"],"title":"Compilers Course","uri":"/blog/posts/course/compilers-course/"},{"categories":["programming"],"content":"这里是 python 使用技巧的记录，包括日常使用和数据之间的转换。 基础知识 字符串 \"\"\" \"\"\" 可以存储数行字符串 text = \"\"\"learn python the smart way 2nd edition hello word\"\"\" 使用 enumerate() 可以获得元素的序号 for idx, c in enumerate(text): print(idx, c) # -\u003e 0 l, 1 e, 2 a, ... str.split 会把字符串划分为一个列表，依照空格进行划分 for word in text.split(): print(word) # -\u003e ['learn', 'python', 'the', ..., 'world'] str.splitlines 会把字符串划分为一个列表，依照\"\\n\"进行划分 for line in text.splitlines(): # -\u003e ['learn python the smart way 2nd edition', 'hello word'] if(line.startswith(\"hello\")): # startswith print(line) 函数 接收不定长参数，*args 表示参数数目不定，可以看成一个元组，把第一个参数后面的参数当作元组中的元素 def add(x, *args): total = x for arg in args: total += arg return total print(add_args(1, 2, 3, 4)) # -\u003e 10 (1+2+3+4) 上面的函数不能使用关键词传入参数，要使用关键词 **kwargs，它表示参数数目不定，相当于一个字典，键和值对应于键值对 def add(x, **kwargs): total = x for arg, value in kwargs.items(): print(\"adding %s=%s\" % (arg,value)) total += value return total print(add_kwargs(10, a=5, b=3)) # -\u003e 18 (10+5+3) # 综合使用方法如下： def foo(*args, **kwargs): print(args, kwargs) foo(2, 3, x='bar', z=10) map 方法生成序列，map(aFun, aSeq)，函数 aFun 应用到序列 aSeq 上的每一个元素上，返回一个列表，不管这个序列原来是什么类型。事实上，根据函数参数的多少，map 可以接受多组序列，将其对应的元素作为参数传入函数。 def square(a, b, c): return a**2 + b + c a = [1, 2, 3] b = (4, 5, 6) print(list(map(square, a, b, b))) # -\u003e [9, 14, 21] 文件读写 python 提供安全的 with 来进行文件读写，当 with 块的内容结束后，Python 会自动调用它的 close 方法，确保读写的安全。 模式 描述 r 只读。该文件必须已存在。 r+ 可读可写。该文件必须已存在，写为追加在文件内容末尾。 rb 表示以二进制方式读取文件。该文件必须已存在。 w 只写。打开即默认创建一个新文件，如果文件已存在，则覆盖写（即文件内原始数据会被新写入的数据清空覆盖）。 w+ 写读。打开创建新文件并写入数据，如果文件已存在，则覆盖写。 wb 表示以二进制写方式打开，只能写文件， 如果文件不存在，创建该文件；如果文件已存在，则覆盖写。 a 追加写。若打开的是已有文件则直接对已有文件操作，若打开文件不存在则创建新文件，只能执行写（追加在后面），不能读。 a+ 追加读写。打开文件方式与写入方式和a一样，但是可以读。需注意的是你若刚用a+打开一个文件，一般不能直接读取，因为此时光标已经是文件末尾，除非你把光标移动到初始位置或任意非末尾的位置。 import os # 删除文件 os.remove('newfile.txt') # 使用 with 安全写入文件 with open('newfile.txt','w+') as f: for i in range(30): x = 1.0 / (i - 10) f.write('hello world: ' + str(i) + '\\n') # 读取并打印文件内容 with open('newfile.txt', 'r') as f: content = f.read() print(content) # 这里注意打开文件后面的模式，若是携带了 'b'，则读取或者写入的需要是 bytes 类型，没有则是 str 类型。 其他 通过 split 对 “,” 进行分割，使得一行可以输入多个值。 a, b = input().split(\",\") # 5, 10 print(f\"a = {a}, b = {b}\") # -\u003e a = 5, b = 10 print 操作，默认每次输入后会换行，控制结尾的参数是 end，设置 end 把 \"\\n\" 替换成了 \"//\"。同时它一次也可以输出多个内容，默认以空格分隔，这里控制分割的参数就是 sep，修改之后空格变成 \"//\"。 print(\"data\", end=\"//\") print(\"Data\", \"whale\", sep=\"//\") 数据转换 这里强制自己使用 bytes 类型，因为 bytes 保存的就是原始的字节（二进制格式）数据，因此对象通途很广。 bytes 介绍 bytes 是不可变对象，类似字符串（str），一旦创建无法修改内容；若需修改，需转换为可变的 bytearray 类型。 b = b'hello' # b[0] = 97 # 报错！不可修改 # 转为 bytearray 后可修改 ba = bytearray(b) ba[0] = 65 # 修改第一个字节为 ASCII 65（即 'A'） print(ba) # 输出: bytearray(b'Aello') print(bytes(ba)) # 输出: b'Aello' bytes 存在三种创建方式： 字面量语法：使用 b 前缀 + 引号（仅允许 ASCII 字符）； 编码转换：通过字符串的 .encode() 方法生成（需指定编码格式，如 utf-8）； 构造函数：直接传入整数列表或可迭代对象（范围 0-255）。 # 字面量创建 b1 = b'abc' # 有效，ASCII 字符 # b2 = b'中国' # 报错！非 ASCII 字符需编码 # 编码转换 b2 = '中国'.encode('utf-8') # 输出: b'\\xe4\\xb8\\xad\\xe5\\x9b\\xbd' # 构造函数创建 b3 = bytes([65, 66, 67]) # 输出: b'ABC' 访问 bytes 的元素时，返回的是整数（0-255）而非字符。 b = b'abc' print(b[0]) # 输出: 97 (整数) 二进制操作与文件处理 文件模式：以 'rb' 或 'wb' 模式读写文件时，返回或操作的是 bytes。 二进制方法：如 split()、replace() 需用字节语法（如 b'\\n'）。 # 写入二进制文件 with open('data.bin', 'wb') as f: f.write(b'\\x48\\x65\\x6c\\x6c\\x6f') # 写入 'Hello' 的二进制 # 读取并分割字节 with open('data.bin', 'rb') as f: data = f.read() print(data.split(b'\\x6c')) # 输出: [b'He', b'', b'o'] 支持类似字符串的操作 切片、拼接、重复：语法与字符串一致。 成员检查：使用 in 判断字节是否存在。 b = b'abcde' print(b[1:3]) # 输出: b'bc'（仍是 bytes 对象） print(b + b'xyz') # 输出: b'abcdexyz' print(b * 2) # 输出: b'abcdeabcde' print(b'a' in b) # 输出: True 相互转换 str 类型 bytes -\u003e str b = b\"abcdefg\\n\" str1 = str(b, encoding = \"utf-8\") str2 = b.decode(\"utf-8\") # 若是确认 b 为 ASCII，那么 utf-8 可以不写 print(str1) # 和 str2 一样，输出： abcdefg\\n（\\n 就是换行，只是转化为原本的格式） str -\u003e bytes text = \"abcdeg\\n\" b1 = text.encode() b2 = bytes(text, encoding = \"utf-8\") print(b1) # 和 b2 一样，输出： b'abcdeg\\n' hex 的 str 类型 bytes -\u003e hex 的 str 类型 b = b\"abcdefg\" h = b.hex() print(h) # 输出： 61626364656667 hex 的 str 类型 -\u003e bytes h = \"61626364656667\" b = bytes.fromhex(h) print(b) # 输出：b'abcdefg' 长整型 长整型 -","date":"2024.10.31","objectID":"/blog/posts/programming/python/:0:0","tags":["programming"],"title":"Some about Python","uri":"/blog/posts/programming/python/"},{"categories":null,"content":"🔆关于我 战战兢兢，如临深渊，如履薄冰。 总是瞎折腾，看到好玩的总会转移当前的注意力。喜欢细致地写东西，妄想真能教会什么。 🐶 系统/软件安全领域的菜狗 📚 信息安全专业 🌐 仓库：czTangt 📬关于博客 个人知识整理零散，因此希望通过博客来进行归纳。同时也想认真对待自己写的东西，希望此博客存储一些好的笔记，但是现在看还是存在许多不足😭。 博客内容以安卓逆向和静态分析为主，主要记录自己的学习过程。同时也尽量保证知道原理才下笔记录，想给阅读者提供更容易理解的笔记。 联系方式 📮 邮箱：Y3ouVGFuZ3RAZ21haWwuY29t ","date":"2024.10.29","objectID":"/blog/about/:0:0","tags":null,"title":"About","uri":"/blog/about/"}]
<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>Large Language Model - czTang</title><meta name=author content="czTang">
<meta name=description content="这里主要记录在大模型原理和技术课程中的学习。
"><meta name=keywords content='AI'><meta itemprop=name content="Large Language Model"><meta itemprop=description content="这里主要记录在大模型原理和技术课程中的学习。"><meta itemprop=datePublished content="2025-01-17T10:17:51+08:00"><meta itemprop=dateModified content="2025-01-17T11:08:21+08:00"><meta itemprop=wordCount content="5787"><meta itemprop=keywords content="AI"><meta property="og:url" content="https://czTangt.github.io/blog/posts/ai/large_language_model/"><meta property="og:site_name" content="czTang"><meta property="og:title" content="Large Language Model"><meta property="og:description" content="这里主要记录在大模型原理和技术课程中的学习。"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-01-17T10:17:51+08:00"><meta property="article:modified_time" content="2025-01-17T11:08:21+08:00"><meta property="article:tag" content="AI"><meta name=twitter:card content="summary"><meta name=twitter:title content="Large Language Model"><meta name=twitter:description content="这里主要记录在大模型原理和技术课程中的学习。"><meta name=application-name content="FixIt"><meta name=apple-mobile-web-app-title content="FixIt"><meta name=theme-color data-light=#f8f8f8 data-dark=#252627 content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel=icon href=https://nuthecz.oss-cn-hangzhou.aliyuncs.com/file/202410312135963.svg><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical type=text/html href=https://czTangt.github.io/blog/posts/ai/large_language_model/ title="Large Language Model - czTang"><link rel=prev type=text/html href=https://czTangt.github.io/blog/posts/staticanalysis/data-flow-analysis/ title="03 Data Flow Analysis"><link rel=stylesheet href=/blog/css/style.min.css><link rel=preload href=/blog/lib/fontawesome-free/all.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/blog/lib/fontawesome-free/all.min.css></noscript><link rel=preload href=/blog/lib/animate/animate.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/blog/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Large Language Model","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/czTangt.github.io\/blog\/posts\/ai\/large_language_model\/"},"genre":"posts","keywords":"AI","wordcount":5787,"url":"https:\/\/czTangt.github.io\/blog\/posts\/ai\/large_language_model\/","datePublished":"2025-01-17T10:17:51+08:00","dateModified":"2025-01-17T11:08:21+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"czTang"},"description":""}</script><script src=/blog/js/head/color-scheme.min.js></script></head><body data-header-desktop=sticky data-header-mobile=auto><div class=wrapper data-page-style=normal><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper data-github-corner=left><div class=header-title><a href=/blog/ title=czTang><span class=header-title-pre><i class='fa fa-coffee'>&nbsp</i></span><span class=header-title-text>czTang</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/blog/archives/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> Archives</a></li><li class=menu-item><a class=menu-link href=/blog/categories/><i class="fa-solid fa-folder-tree fa-fw fa-sm" aria-hidden=true></i> Categories</a></li><li class=menu-item><a class=menu-link href=/blog/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> Tags</a></li><li class=menu-item><a class=menu-link href=/blog/about/><i class="fa-solid fa-user fa-fw fa-sm" aria-hidden=true></i> About</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容…… id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/blog/ title=czTang><span class=header-title-pre><i class='fa fa-coffee'>&nbsp</i></span><span class=header-title-text>czTang</span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容…… id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/blog/archives/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> Archives</a></li><li class=menu-item><a class=menu-link href=/blog/categories/><i class="fa-solid fa-folder-tree fa-fw fa-sm" aria-hidden=true></i> Categories</a></li><li class=menu-item><a class=menu-link href=/blog/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> Tags</a></li><li class=menu-item><a class=menu-link href=/blog/about/><i class="fa-solid fa-user fa-fw fa-sm" aria-hidden=true></i> About</a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=container><aside class="aside-collection animate__animated animate__fadeIn animate__faster" aria-label=合集><div class="details collection-details open"><div class="details-summary collection-summary"><i class="fa-solid fa-layer-group fa-fw" aria-hidden=true></i>
<span class=collection-name title=合集>AI</span>
<span class=collection-count>1</span><i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class="details-content collection-content"><nav><ul class=collection-list><li class=collection-item><span class=active title="Large Language Model">Large Language Model</span></li></ul><div class=collection-nav-simple><i class="fa-solid fa-angle-left fa-fw collection-nav-item text-secondary" aria-hidden=true></i><span class=text-secondary>1/1</span><i class="fa-solid fa-angle-right fa-fw collection-nav-item text-secondary" aria-hidden=true></i></div></nav></div></div></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>Large Language Model</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://github.com/czTangt title=作者 target=_blank rel="external nofollow noopener noreferrer author" class=author><img loading=lazy src=/blog/images/avatar.jpg alt=czTang data-title=czTang width=20 height=20 class=avatar style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'>&nbsp;czTang</a></span><span class=post-included-in>&nbsp;收录于 <a href=/blog/categories/ai/ class=post-category title="分类 - AI"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> AI</a> 和 <a href=/blog/collections/ai/ class=post-collection title="合集 - AI"><i class="fa-solid fa-layer-group fa-fw" aria-hidden=true></i> AI</a></span></div><div class=post-meta-line><span title="发布于 2025-01-17 10:17:51"><i class="fa-solid fa-calendar-days fa-fw me-1" aria-hidden=true></i><time datetime=2025.1.17>2025.1.17</time></span>&nbsp;<span title="更新于 2025-01-17 11:08:21"><i class="fa-regular fa-calendar-check fa-fw me-1" aria-hidden=true></i><time datetime=2025.1.17>2025.1.17</time></span>&nbsp;<span title="5787 字"><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden=true></i>约 5800 字</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden=true></i>预计阅读 12 分钟</span>&nbsp;</div></div><div class="details toc" id=toc-static data-kept=false><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fa-solid fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#语言模型基础>语言模型基础</a><ul><li><a href=#基于统计方法的语言模型>基于统计方法的语言模型</a><ul><li><a href=#n-grams-语言模型>n-grams 语言模型</a></li><li><a href=#n-grams-的统计学原理>n-grams 的统计学原理</a></li></ul></li><li><a href=#基于-rnn-的语言模型>基于 RNN 的语言模型</a><ul><li><a href=#rnn-的基本原理>RNN 的基本原理</a></li><li><a href=#基于-rnn-的语言模型-1>基于 RNN 的语言模型</a></li></ul></li><li><a href=#基于-transformer-的语言模型>基于 Transformer 的语言模型</a><ul><li><a href=#transformer-的基本原理>Transformer 的基本原理</a></li><li><a href=#基于-transformer-的语言模型-1>基于 Transformer 的语言模型</a></li></ul></li><li><a href=#语言模型的采样方法>语言模型的采样方法</a></li><li><a href=#语言模型的评测>语言模型的评测</a></li></ul></li><li><a href=#大语言模型架构>大语言模型架构</a><ul><li><a href=#大数据与大模型>大数据与大模型</a></li><li><a href=#大语言模型架构概览>大语言模型架构概览</a><ul><li><a href=#主流模型架构>主流模型架构</a></li><li><a href=#注意力矩阵>注意力矩阵</a></li></ul></li><li><a href=#基于-encoder-only-架构>基于 Encoder-only 架构</a><ul><li><a href=#bert-模型>BERT 模型</a></li><li><a href=#bert-衍生模型>BERT 衍生模型</a></li></ul></li><li><a href=#基于-encoder-decoder-架构>基于 Encoder-Decoder 架构</a><ul><li><a href=#t5-模型>T5 模型</a></li><li><a href=#bart-模型>BART 模型</a></li></ul></li><li><a href=#基于-decoder-only-架构>基于 Decoder-only 架构</a><ul><li><a href=#gpt-系列>GPT 系列</a></li><li><a href=#llama-系列>LLaMA 系列</a></li></ul></li><li><a href=#非-transformer-架构>非 Transformer 架构</a></li></ul></li><li><a href=#prompt-工程>Prompt 工程</a><ul><li><a href=#prompt-工程简介>Prompt 工程简介</a><ul><li><a href=#定义与背景>定义与背景</a></li><li><a href=#核心思想与重要性>核心思想与重要性</a></li><li><a href=#关键要素>关键要素</a></li></ul></li><li><a href=#上下文学习>上下文学习</a><ul><li><a href=#定义与核心思想>定义与核心思想</a></li><li><a href=#形式与示例选择>形式与示例选择</a></li><li><a href=#影响因素与优化策略>影响因素与优化策略</a></li></ul></li><li><a href=#思维链>思维链</a><ul><li><a href=#定义与核心思想-1>定义与核心思想</a></li><li><a href=#主要模式与应用场景>主要模式与应用场景</a></li><li><a href=#优化策略与未来方向>优化策略与未来方向</a></li></ul></li><li><a href=#prompt-技巧>Prompt 技巧</a></li><li><a href=#相关应用>相关应用</a></li></ul></li></ul></nav></div></div><div class=content id=content><p>这里主要记录在<a href="https://www.bilibili.com/video/BV1PB6XYFET2/?spm_id_from=333.1387.collection.video_card.click" target=_blank rel="external nofollow noopener noreferrer">大模型原理和技术</a>课程中的学习。</p><h2 id=语言模型基础 class=heading-element><span>语言模型基础</span>
<a href=#%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e5%9f%ba%e7%a1%80 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>语言是概率的。并且，语言的概率性与认知的概率性存在着密不可分的关系。语言模型（Language Models, LMs）旨在准确预测语言符号的概率。，语言模型经历了从规则模型到统计模型，再到神经网络模型的发展历程，逐步从呆板的机械式问答程序成长为具有强大泛化能力的多任务智能模型。下面按照语言模型发展的顺序依次进行讲解。</p><h3 id=基于统计方法的语言模型 class=heading-element><span>基于统计方法的语言模型</span>
<a href=#%e5%9f%ba%e4%ba%8e%e7%bb%9f%e8%ae%a1%e6%96%b9%e6%b3%95%e7%9a%84%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=n-grams-语言模型 class=heading-element><span>n-grams 语言模型</span>
<a href=#n-grams-%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>定义</strong>：n-grams 是一种基于统计的语言模型，通过统计语料库中词序列的频率来预测语言符号的概率。</li><li><strong>计算方法</strong>：n-grams 模型通过计算词序列的相对频率来预测文本的概率。公式为：
$$
P_{n-grams}(w_{1:N}) = \prod_{i=n}^{N} \frac{C(w_{i-n+1}:i)}{C(w_{i-n+1}:i-1)}
$$
其中，$C(w_{i-n+1}:i)$ 是词序列在语料库中出现的次数。</li><li><strong>马尔可夫假设</strong>：n-grams 模型基于 n 阶马尔可夫假设，即当前词的概率只与前 n 个词有关。</li><li><strong>零概率问题</strong>：当 n 较大时，语料库中可能找不到与 n-gram 完全匹配的词序列，导致零概率问题。可以通过平滑技术来缓解。</li></ul><h4 id=n-grams-的统计学原理 class=heading-element><span>n-grams 的统计学原理</span>
<a href=#n-grams-%e7%9a%84%e7%bb%9f%e8%ae%a1%e5%ad%a6%e5%8e%9f%e7%90%86 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>极大似然估计</strong>：n-grams 模型通过极大似然估计来近似词序列的概率。具体来说，n-grams 模型通过统计词序列的频率来估计条件概率 $P(w_i|w_{i-n+1}:i-1)$。</li></ul><h3 id=基于-rnn-的语言模型 class=heading-element><span>基于 RNN 的语言模型</span>
<a href=#%e5%9f%ba%e4%ba%8e-rnn-%e7%9a%84%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=rnn-的基本原理 class=heading-element><span>RNN 的基本原理</span>
<a href=#rnn-%e7%9a%84%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>循环传播范式</strong>：RNN 通过环路将历史状态叠加到当前状态上，从而能够基于历史信息进行预测。</li><li><strong>隐状态</strong>：RNN 的隐状态 $h_t$ 通过以下公式计算：
$$
h_t = g(W_H h_{t-1} + W_I x_t)
$$
其中，$g(\cdot)$ 是激活函数，$W_H$ 和 $W_I$ 是权重矩阵。</li><li><strong>梯度消失与爆炸</strong>：RNN 在训练过程中容易遇到梯度消失或梯度爆炸问题，可以通过 GRU 或 LSTM 等门控结构来缓解。</li></ul><h4 id=基于-rnn-的语言模型-1 class=heading-element><span>基于 RNN 的语言模型</span>
<a href=#%e5%9f%ba%e4%ba%8e-rnn-%e7%9a%84%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b-1 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>预测下一个词</strong>：基于 RNN 的语言模型通过当前词和隐状态来预测下一个词的概率：
$$
P(w_{i+1}|w_{1:i}) = P(w_{i+1}|w_i, h_{i-1})
$$</li><li><strong>损失函数</strong>：通常使用交叉熵损失函数来训练 RNN 语言模型：
$$
l_{CE}(o_i) = -\log o_i [w_{i+1}]
$$</li><li><strong>Teacher Forcing</strong>：在训练过程中，使用标准答案作为下一轮的输入，以减少错误级联放大问题。</li></ul><h3 id=基于-transformer-的语言模型 class=heading-element><span>基于 Transformer 的语言模型</span>
<a href=#%e5%9f%ba%e4%ba%8e-transformer-%e7%9a%84%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=transformer-的基本原理 class=heading-element><span>Transformer 的基本原理</span>
<a href=#transformer-%e7%9a%84%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>注意力机制</strong>：Transformer 通过自注意力机制将前文信息叠加到当前状态上。自注意力层的输出为：
$$
Attention(x_t) = \sum_{i=1}^{t} \alpha_{t,i} v_i
$$
其中，$\alpha_{t,i}$ 是注意力权重。</li><li><strong>全连接前馈层</strong>：全连接前馈层负责记忆存储，公式为：
$$
FFN(v) = \max(0, W_1 v + b_1) W_2 + b_2
$$</li><li><strong>层正则化与残差连接</strong>：层正则化用于加速训练，残差连接用于缓解梯度消失问题。</li></ul><h4 id=基于-transformer-的语言模型-1 class=heading-element><span>基于 Transformer 的语言模型</span>
<a href=#%e5%9f%ba%e4%ba%8e-transformer-%e7%9a%84%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b-1 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>下一词预测</strong>：Transformer 语言模型通过上文预测下一个词的概率：
$$
P(w_{i+1}|w_{1:i}) = o_i [w_{i+1}]
$$</li><li><strong>损失函数</strong>：同样使用交叉熵损失函数进行训练。</li></ul><h3 id=语言模型的采样方法 class=heading-element><span>语言模型的采样方法</span>
<a href=#%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%e9%87%87%e6%a0%b7%e6%96%b9%e6%b3%95 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ol><li><p><strong>概率最大化方法</strong>：</p><ul><li><strong>贪心搜索</strong>：每轮选择概率最大的词，容易陷入局部最优。</li><li><strong>波束搜索</strong>：每轮保留多个候选词，最终选择联合概率最大的词序列。</li></ul></li><li><p><strong>随机采样方法</strong>：</p><ul><li><strong>Top-K 采样</strong>：每轮选择概率最高的 K 个词，然后根据概率分布进行随机采样。</li><li><strong>Top-P 采样</strong>：设定概率阈值 p，选择累积概率超过 p 的词进行采样。</li><li><strong>Temperature 机制</strong>：通过调整 Temperature 参数来控制采样的随机性。</li></ul></li></ol><h3 id=语言模型的评测 class=heading-element><span>语言模型的评测</span>
<a href=#%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%e8%af%84%e6%b5%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ol><li><p><strong>内在评测</strong>：</p><ul><li><strong>困惑度（Perplexity）</strong>：衡量语言模型对测试文本的“困惑”程度，困惑度越低，模型性能越好。
$$
PPL(s_{test}) = P(w_{1:N})^{-\frac{1}{N}}
$$</li></ul></li><li><p><strong>外在评测</strong>：</p><ul><li><strong>基于统计指标的评测</strong>：如 BLEU 和 ROUGE，通过计算生成文本与标准答案的重合程度来评估模型性能。</li><li><strong>基于语言模型的评测</strong>：如 BERTScore 和 G-EVAL，利用语言模型的上下文词嵌入或生成能力来评估生成文本的质量。</li></ul></li></ol><h2 id=大语言模型架构 class=heading-element><span>大语言模型架构</span>
<a href=#%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e6%9e%b6%e6%9e%84 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><h3 id=大数据与大模型 class=heading-element><span>大数据与大模型</span>
<a href=#%e5%a4%a7%e6%95%b0%e6%8d%ae%e4%b8%8e%e5%a4%a7%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ol><li><p><strong>大数据与大模型的关系</strong>：</p><ul><li>数据规模的增长为模型提供了更丰富的信息源，模型规模的扩大增加了模型的表达能力。</li><li>模型规模和数据规模的增长共同作用，提升了模型的性能和新功能的涌现。</li><li><strong>扩展法则</strong>：<ul><li><strong>Kaplan-McCandlish 扩展法则</strong>：模型性能与模型规模和数据规模高度正相关，模型规模的增长速度应略快于数据规模。</li><li><strong>Chinchilla 扩展法则</strong>：数据集规模与模型规模同等重要，理想的数据集大小应为模型规模的20倍。</li></ul></li></ul></li><li><p><strong>涌现能力</strong>：</p><ul><li>随着模型规模和数据规模的提升，大语言模型涌现出新的能力，如上下文学习、常识推理、代码生成、逻辑推理等。</li><li>这些能力并非通过特定任务训练获得，而是随着模型复杂度的提升自然涌现。</li></ul></li></ol><h3 id=大语言模型架构概览 class=heading-element><span>大语言模型架构概览</span>
<a href=#%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e6%9e%b6%e6%9e%84%e6%a6%82%e8%a7%88 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=主流模型架构 class=heading-element><span>主流模型架构</span>
<a href=#%e4%b8%bb%e6%b5%81%e6%a8%a1%e5%9e%8b%e6%9e%b6%e6%9e%84 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>Encoder-only 架构</strong>：仅使用编码器，适合自然语言理解任务，如文本分类、情感分析等。</li><li><strong>Encoder-Decoder 架构</strong>：包含编码器和解码器，适合序列到序列任务，如机器翻译、文本摘要等。</li><li><strong>Decoder-only 架构</strong>：仅使用解码器，适合开放式生成任务，如文本生成、故事生成等。</li></ul><h4 id=注意力矩阵 class=heading-element><span>注意力矩阵</span>
<a href=#%e6%b3%a8%e6%84%8f%e5%8a%9b%e7%9f%a9%e9%98%b5 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>Encoder-only</strong>：双向注意力，捕捉输入序列中所有Token的关系。</li><li><strong>Encoder-Decoder</strong>：结合编码器的双向注意力和解码器的单向注意力，适合复杂生成任务。</li><li><strong>Decoder-only</strong>：单向注意力，适合自回归生成任务。</li></ul><h3 id=基于-encoder-only-架构 class=heading-element><span>基于 Encoder-only 架构</span>
<a href=#%e5%9f%ba%e4%ba%8e-encoder-only-%e6%9e%b6%e6%9e%84 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=bert-模型 class=heading-element><span>BERT 模型</span>
<a href=#bert-%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>结构</strong>：基于 Transformer 编码器，包含多层自注意力和前馈网络。</li><li><strong>预训练任务</strong>：掩码语言建模（MLM）和下文预测（NSP）。</li><li><strong>下游任务</strong>：文本分类、问答系统、语义相似度计算等。</li></ul><h4 id=bert-衍生模型 class=heading-element><span>BERT 衍生模型</span>
<a href=#bert-%e8%a1%8d%e7%94%9f%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>RoBERTa</strong>：优化了 BERT 的预训练过程，使用更大的数据集和动态掩码。</li><li><strong>ALBERT</strong>：通过参数共享和嵌入分解减少参数量，提升训练效率。</li><li><strong>ELECTRA</strong>：引入生成器-判别器架构，提升训练效率和下游任务表现。</li></ul><h3 id=基于-encoder-decoder-架构 class=heading-element><span>基于 Encoder-Decoder 架构</span>
<a href=#%e5%9f%ba%e4%ba%8e-encoder-decoder-%e6%9e%b6%e6%9e%84 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=t5-模型 class=heading-element><span>T5 模型</span>
<a href=#t5-%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>结构</strong>：统一的文本到文本生成框架，适合多种 NLP 任务。</li><li><strong>预训练任务</strong>：Span Corruption，预测被掩码的连续文本片段。</li><li><strong>下游任务</strong>：通过 Prompt 工程和微调适配多种任务。</li></ul><h4 id=bart-模型 class=heading-element><span>BART 模型</span>
<a href=#bart-%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>结构</strong>：结合编码器和解码器，适合文本生成和理解任务。</li><li><strong>预训练任务</strong>：多种文本破坏任务，如 Token 遮挡、句子打乱等。</li><li><strong>下游任务</strong>：文本生成、文本摘要、问答系统等。</li></ul><h3 id=基于-decoder-only-架构 class=heading-element><span>基于 Decoder-only 架构</span>
<a href=#%e5%9f%ba%e4%ba%8e-decoder-only-%e6%9e%b6%e6%9e%84 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=gpt-系列 class=heading-element><span>GPT 系列</span>
<a href=#gpt-%e7%b3%bb%e5%88%97 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>GPT-1</strong>：初代 Decoder-only 模型，使用下一词预测任务进行预训练。</li><li><strong>GPT-2</strong>：增加模型规模和预训练数据，提升任务泛化能力。</li><li><strong>GPT-3</strong>：大幅增加模型规模和数据规模，涌现出上下文学习能力。</li><li><strong>ChatGPT 和 GPT-4</strong>：引入人类反馈强化学习（RLHF），提升指令跟随能力。</li></ul><h4 id=llama-系列 class=heading-element><span>LLaMA 系列</span>
<a href=#llama-%e7%b3%bb%e5%88%97 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>LLaMA1</strong>：小模型+大数据理念，优化了 Transformer 的嵌入和注意力机制。</li><li><strong>LLaMA2</strong>：增加预训练数据规模，引入人类反馈强化学习。</li><li><strong>LLaMA3</strong>：大幅增加预训练数据规模，提升跨语言处理能力。</li></ul><h3 id=非-transformer-架构 class=heading-element><span>非 Transformer 架构</span>
<a href=#%e9%9d%9e-transformer-%e6%9e%b6%e6%9e%84 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ol><li><p><strong>状态空间模型（SSM）</strong>：</p><ul><li><strong>SSM</strong>：通过状态变量捕捉系统状态的变化，适合处理长序列数据。</li><li><strong>RWKV</strong>：结合RNN和Transformer的优点，实现高效的长序列处理。</li><li><strong>Mamba</strong>：引入选择机制和硬件感知算法，提升长序列处理效率。</li></ul></li><li><p><strong>测试时训练（TTT）</strong>：</p><ul><li><strong>TTT</strong>：在推理阶段动态更新模型参数，提升长上下文建模能力。</li><li><strong>优势</strong>：线性时间复杂度，适合处理超长序列任务。</li></ul></li></ol><h2 id=prompt-工程 class=heading-element><span>Prompt 工程</span>
<a href=#prompt-%e5%b7%a5%e7%a8%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><h3 id=prompt-工程简介 class=heading-element><span>Prompt 工程简介</span>
<a href=#prompt-%e5%b7%a5%e7%a8%8b%e7%ae%80%e4%bb%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=定义与背景 class=heading-element><span>定义与背景</span>
<a href=#%e5%ae%9a%e4%b9%89%e4%b8%8e%e8%83%8c%e6%99%af class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>Prompt 工程是指通过精心设计的指令（Prompt）来引导生成式人工智能模型执行特定任务，而无需进行繁琐的微调。它是用户输入给模型的指令或问题，通常以自然语言的形式呈现，目的是引导模型生成符合任务需求的输出。传统的自然语言处理（NLP）研究遵循 “预训练-微调-预测” 范式，即在大规模语料库上进行预训练，然后针对特定任务进行微调，最后在微调后的模型上进行预测。然而，随着大语言模型（LLM）的规模和能力的提升，一种新的范式—— “预训练-提示预测” 应运而生。这种范式通过精心设计的 Prompt 直接引导模型适应下游任务，避免了微调的高昂成本。</p><h4 id=核心思想与重要性 class=heading-element><span>核心思想与重要性</span>
<a href=#%e6%a0%b8%e5%bf%83%e6%80%9d%e6%83%b3%e4%b8%8e%e9%87%8d%e8%a6%81%e6%80%a7 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>Prompt 工程的核心思想是通过设计合适的 Prompt，将新任务转化为模型在预训练阶段已经熟悉的形式，从而利用模型的泛化能力完成任务。大语言模型在预训练阶段学习了大量的语言知识和任务模式，具备强大的 <strong>泛化能力</strong>。同时，大语言模型还具备强大的 <strong>指令跟随能力</strong>，能够根据用户的指令生成符合预期的输出。Prompt 工程通过设计清晰、具体的指令，确保模型能够准确理解任务需求并生成高质量的输出。</p><p>Prompt 工程的重要性体现在多个方面。首先，它避免了传统微调方法带来的高昂成本。传统的微调方法需要针对每个任务进行特定的训练，耗费大量的计算资源和时间。而 Prompt 工程通过设计有效的 Prompt，避免了微调带来的高昂成本。其次，Prompt 工程提供了一种灵活的方式来执行各种任务，用户只需通过修改 Prompt 即可引导模型适应不同的任务需求。最后，Prompt 工程在文本生成、情感分析、问答系统、代码生成等多个领域都有广泛的应用，能够显著提升模型的性能。</p><h4 id=关键要素 class=heading-element><span>关键要素</span>
<a href=#%e5%85%b3%e9%94%ae%e8%a6%81%e7%b4%a0 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>Prompt 工程的成功依赖于对模型和任务的深入理解。一个有效的 Prompt 通常由四个关键要素组成：任务说明、上下文、问题和输出格式。任务说明用于明确描述模型需要完成的任务，确保模型理解任务的核心要求。上下文则提供与任务相关的背景信息或示例，帮助模型更好地理解任务。问题是用户的具体问题或需要处理的信息，为模型提供明确的起点。输出格式则指定模型输出的格式，如 JSON、XML 等，确保输出结构化和易于处理。</p><h3 id=上下文学习 class=heading-element><span>上下文学习</span>
<a href=#%e4%b8%8a%e4%b8%8b%e6%96%87%e5%ad%a6%e4%b9%a0 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=定义与核心思想 class=heading-element><span>定义与核心思想</span>
<a href=#%e5%ae%9a%e4%b9%89%e4%b8%8e%e6%a0%b8%e5%bf%83%e6%80%9d%e6%83%b3 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>上下文学习（In-Context Learning, ICL）是一种通过构造特定的 Prompt 来引导大语言模型理解并学习下游任务的范式。这些特定的 Prompt 中通常包含任务说明和一系列示例，模型能够从这些上下文信息中学习任务的逻辑和规则，从而在没有额外训练的情况下生成符合任务要求的输出。上下文学习的核心思想是利用大语言模型在预训练阶段学到的泛化能力，通过提供任务相关的上下文信息，使模型能够快速适应新的任务。</p><p>与传统的微调方法不同，上下文学习不需要对模型进行额外的训练，而是通过设计有效的 Prompt 来引导模型完成任务。这种方法特别适用于需要快速适应新任务的场景，例如用户通过 API 或页面与大语言模型进行交互时。上下文学习的出现为 “语言模型即服务”（LLM as a Service）模式奠定了坚实的基础。</p><h4 id=形式与示例选择 class=heading-element><span>形式与示例选择</span>
<a href=#%e5%bd%a2%e5%bc%8f%e4%b8%8e%e7%a4%ba%e4%be%8b%e9%80%89%e6%8b%a9 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>上下文学习可以根据提供的示例数量分为三种形式：零样本（Zero-shot）、单样本（One-shot）和少样本（Few-shot）。零样本上下文学习仅提供任务说明，不提供任何示例，依赖模型的泛化能力完成任务。单样本上下文学习提供一个示例，帮助模型理解任务的基本模式。少样本上下文学习则提供少量示例（通常几个至十几个），显著提升模型在特定任务上的表现。</p><p>示例的选择对上下文学习的效果至关重要。示例的选择主要依赖于相似性和多样性。相似性是指选择与待解决问题最为相近的示例，帮助模型更好地理解任务。多样性则要求示例涵盖尽量广的内容，扩大示例对任务的覆盖范围，增强模型应对各种问题的能力。常见的示例选择方法包括直接检索、聚类检索和迭代检索。直接检索根据相似性选择示例，聚类检索通过聚类保证示例的多样性，而迭代检索则兼顾相似性和多样性，动态选择示例。</p><h4 id=影响因素与优化策略 class=heading-element><span>影响因素与优化策略</span>
<a href=#%e5%bd%b1%e5%93%8d%e5%9b%a0%e7%b4%a0%e4%b8%8e%e4%bc%98%e5%8c%96%e7%ad%96%e7%95%a5 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>上下文学习的性能受到多种因素的影响，包括预训练数据、模型规模以及演示示例的质量。预训练数据的领域丰富度和任务多样性直接影响模型的上下文学习能力。模型规模越大，上下文学习的能力通常越强，尤其是在参数数量达到亿级别及以上的模型中，上下文学习的效果更为显著。</p><p>演示示例的质量也对上下文学习的效果有重要影响。示例的格式、输入-输出映射的正确性、示例数量和顺序都会影响模型的表现。例如，在复杂推理任务中，使用思维链（Chain of Thought, CoT）形式的示例可以显著提升模型的推理能力。此外，增加示例数量通常能够提升上下文学习的性能，但随着示例数量的增多，性能提升的速率会逐渐减缓。</p><p>为了优化上下文学习的效果，可以采取以下策略：</p><ol><li><strong>设计清晰的 Prompt</strong>：确保任务说明明确，上下文信息丰富且相关，输出格式规范。</li><li><strong>选择合适的示例</strong>：根据任务需求选择相似性和多样性兼备的示例，帮助模型更好地理解任务。</li><li><strong>调整示例顺序</strong>：不同的示例顺序可能对模型的表现产生显著影响，可以通过实验找到最优的示例顺序。</li></ol><h3 id=思维链 class=heading-element><span>思维链</span>
<a href=#%e6%80%9d%e7%bb%b4%e9%93%be class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=定义与核心思想-1 class=heading-element><span>定义与核心思想</span>
<a href=#%e5%ae%9a%e4%b9%89%e4%b8%8e%e6%a0%b8%e5%bf%83%e6%80%9d%e6%83%b3-1 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>思维链（Chain of Thought, CoT）是一种通过模拟人类解决复杂问题时的思考过程，引导大语言模型生成中间推理步骤的 Prompt 范式。它的核心思想是通过在 Prompt 中嵌入逐步推理的示例或提示，帮助模型在生成答案的过程中引入逻辑连贯的中间步骤，从而显著提升模型在复杂推理任务中的表现。</p><p>传统的语言模型在处理简单任务（如文本分类、情感分析）时表现良好，但在面对需要复杂推理的任务（如算术求解、常识判断、符号推理）时，往往表现不佳。这种现象被称为“Flat Scaling Curves”，即模型规模的扩大并未带来预期的性能提升。思维链技术的出现解决了这一问题，它通过引导模型逐步推理，显著提升了模型在复杂任务中的表现。</p><p>思维链的核心在于构造合适的 Prompt，以触发模型生成推理路径。早期的方法通过在 Prompt 中加入少量包含推理过程的示例（Few-Shot Demonstrations），引导模型模仿这些示例逐步生成答案。随着技术的发展，思维链衍生出了多种变体，如 Zero-Shot CoT、Auto-CoT、思维树（Tree of Thoughts, ToT）和思维图（Graph of Thoughts, GoT）等。</p><h4 id=主要模式与应用场景 class=heading-element><span>主要模式与应用场景</span>
<a href=#%e4%b8%bb%e8%a6%81%e6%a8%a1%e5%bc%8f%e4%b8%8e%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>思维链技术可以根据推理方式的不同分为三种主要模式：按部就班、三思后行和集思广益。</p><ol><li><p><strong>按部就班</strong>：</p><ul><li><strong>特点</strong>：模型逐步推理，逻辑连贯，推理路径形成一条清晰的链条。</li><li><strong>代表方法</strong>：CoT、Zero-Shot CoT、Auto-CoT。</li><li><strong>应用场景</strong>：适用于需要逐步推理的任务，如算术求解、逻辑推理等。</li></ul></li><li><p><strong>三思后行</strong>：</p><ul><li><strong>特点</strong>：模型在每一步推理中评估当前情况，选择最佳推理方向，允许回溯和重新选择。</li><li><strong>代表方法</strong>：思维树（ToT）、思维图（GoT）。</li><li><strong>应用场景</strong>：适用于需要探索多种推理路径的任务，如创意写作、复杂问题求解等。</li></ul></li><li><p><strong>集思广益</strong>：</p><ul><li><strong>特点</strong>：模型生成多条推理路径，整合后得到最优答案。</li><li><strong>代表方法</strong>：Self-Consistency。</li><li><strong>应用场景</strong>：适用于需要高准确性和可靠性的任务，如代码生成、复杂决策等。</li></ul></li></ol><h4 id=优化策略与未来方向 class=heading-element><span>优化策略与未来方向</span>
<a href=#%e4%bc%98%e5%8c%96%e7%ad%96%e7%95%a5%e4%b8%8e%e6%9c%aa%e6%9d%a5%e6%96%b9%e5%90%91 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>思维链技术的成功依赖于 Prompt 的设计和模型的推理能力。为了进一步提升思维链的效果，可以采取以下优化策略：</p><ol><li><strong>调整推理详细程度</strong>：根据任务需求调整思维链的详细程度。对于简单任务，可以直接给出最终答案；对于复杂任务，则需要展示完整的推理步骤。</li><li><strong>结合多种模式</strong>：根据任务特点灵活选择思维链的模式。例如，在需要高准确性的任务中使用 Self-Consistency，在需要创意的任务中使用 ToT 或 GoT。</li><li><strong>优化示例选择</strong>：选择与任务高度相关的示例，确保示例的多样性和代表性，帮助模型更好地理解任务。</li></ol><p>未来，思维链技术可能会在以下方向进一步发展：</p><ul><li><strong>自动化推理</strong>：通过自动生成推理路径，减少对人工示例的依赖。</li><li><strong>多模态推理</strong>：将思维链技术应用于多模态任务，如图像生成、视频理解等。</li><li><strong>个性化推理</strong>：根据用户需求生成个性化的推理路径，提升用户体验。</li></ul><h3 id=prompt-技巧 class=heading-element><span>Prompt 技巧</span>
<a href=#prompt-%e6%8a%80%e5%b7%a7 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h3 id=相关应用 class=heading-element><span>相关应用</span>
<a href=#%e7%9b%b8%e5%85%b3%e5%ba%94%e7%94%a8 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="更新于 2025-01-17 11:08:21">更新于 2025.1.17&nbsp;
<a class=git-hash href=https://github.com/czTangt/blog.git/commit/188e24e67760453595950f4694296bf50e85667a rel="external nofollow noopener noreferrer" target=_blank title="commit by czTangt(cz.tangt@gmail.com) 188e24e67760453595950f4694296bf50e85667a: add llm architecture"><i class="fa-solid fa-hashtag fa-fw" aria-hidden=true></i>188e24e</a></span></div><div class=post-info-license><span><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div><div class=post-info-line><div class=post-info-md><span><a href="https://github.com/czTangt/blog.git/blob/main/content/posts%5cAI%5cllm.md?plain=1" title=查看源码 target=_blank rel="external nofollow noopener noreferrer" class=link-to-source>查看源码</a></span><span><a href=https://github.com/czTangt/blog.git/edit/main/content/posts%5cAI%5cllm.md title=编辑此页 target=_blank rel="external nofollow noopener noreferrer" class=link-to-edit>编辑此页</a></span><span><a href="https://github.com/czTangt/blog.git/issues/new?title=[BUG]%20Large+Language+Model&amp;body=%7cField%7cValue%7c%0A%7c-%7c-%7c%0A%7cTitle%7cLarge+Language+Model%7c%0A%7cURL%7chttps://czTangt.github.io/blog/posts/ai/large_language_model/%7c%0A%7cFilename%7chttps://github.com/czTangt/blog.git/blob/main/content/posts%5cAI%5cllm.md?plain=1%7c" title=报告问题 target=_blank rel="external nofollow noopener noreferrer" class=link-to-report>报告问题</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 X" data-sharer=twitter data-url=https://czTangt.github.io/blog/posts/ai/large_language_model/ data-title="Large Language Model" data-hashtags=AI><i class="fa-brands fa-x-twitter fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=https://czTangt.github.io/blog/posts/ai/large_language_model/ data-hashtag=AI><i class="fa-brands fa-facebook-square fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=https://czTangt.github.io/blog/posts/ai/large_language_model/ data-title="Large Language Model"><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/blog/tags/ai/ class=post-tag title="标签 - AI">AI</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/blog/>主页</a></span></section></div><div class=post-nav><a href=/blog/posts/staticanalysis/data-flow-analysis/ class=post-nav-item rel=prev title="03 Data Flow Analysis"><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>03 Data Flow Analysis</a></div></div></article><aside class=toc id=toc-auto aria-label=目录><h2 class=toc-title>目录&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden=true></i></h2><div class=toc-content id=toc-content-auto></div></aside></main><footer class=footer><div class=footer-container><div class="footer-line powered order-1">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.136.5"><img class=hugo-icon src=/blog/images/hugo.min.svg alt="Hugo logo"> Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.3.17-30a67c4b"><img class=fixit-icon src=/blog/images/fixit.min.svg alt="FixIt logo"> FixIt</a></div><div class="footer-line copyright order-2" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2024 - 2025</span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class="variant-numeric d-none">0%</span></div></div><a href=https://github.com/czTangt/blog title="View source on GitHub" target=_blank rel="external nofollow" class="github-corner left d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true" width="56" height="56"><path d="M0 0 115 115h15l12 27L250 250V0z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentcolor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4l13.9-13.8C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8z" fill="currentcolor" class="octo-body"/></svg></a><div id=mask></div><noscript><div class=noscript-warning>该网站在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=stylesheet href=/blog/lib/lightgallery/css/lightgallery-bundle.min.css><link rel=preload href=/blog/lib/katex/katex.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/blog/lib/katex/katex.min.css></noscript><link rel=stylesheet href=/blog/lib/cookieconsent/cookieconsent.min.css><script src=/blog/lib/autocomplete/autocomplete.min.js defer></script><script src=/blog/lib/fuse/fuse.min.js defer></script><script src=/blog/lib/lightgallery/lightgallery.min.js defer></script><script src=/blog/lib/lightgallery/plugins/thumbnail/lg-thumbnail.min.js defer></script><script src=/blog/lib/lightgallery/plugins/zoom/lg-zoom.min.js defer></script><script src=/blog/lib/sharer/sharer.min.js async defer></script><script src=/blog/lib/katex/katex.min.js defer></script><script src=/blog/lib/katex/auto-render.min.js defer></script><script src=/blog/lib/katex/mhchem.min.js defer></script><script src=/blog/lib/cookieconsent/cookieconsent.min.js defer></script><script src=/blog/js/codeblock.js defer></script><script src=https://libs.baidu.com/jquery/2.1.4/jquery.min.js defer></script><script>window.config={code:{copyTitle:"复制到剪贴板",editLockTitle:"锁定可编辑代码块",editUnLockTitle:"解锁可编辑代码块",editable:!0,maxShownLines:10},comment:{enable:!1},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验。"},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},lightgallery:!0,math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{distance:100,findAllMatches:!1,fuseIndexURL:"/blog/search.json",highlightTag:"em",ignoreFieldNorm:!1,ignoreLocation:!1,isCaseSensitive:!1,location:0,maxResultLength:10,minMatchCharLength:2,noResultsFound:"没有找到结果",snippetLength:30,threshold:.3,type:"fuse",useExtendedSearch:!1},version:"v0.3.17-30a67c4b"}</script><script src=/blog/js/theme.min.js defer></script></body></html>
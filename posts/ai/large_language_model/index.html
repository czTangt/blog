<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>Large Language Model - czTang</title><meta name=author content="czTang">
<meta name=description content="这里主要记录在大模型原理和技术课程中的学习。
"><meta name=keywords content='AI'><meta itemprop=name content="Large Language Model"><meta itemprop=description content="这里主要记录在大模型原理和技术课程中的学习。"><meta itemprop=datePublished content="2025-01-17T10:17:51+08:00"><meta itemprop=dateModified content="2025-01-18T21:56:15+08:00"><meta itemprop=wordCount content="15354"><meta itemprop=keywords content="AI"><meta property="og:url" content="https://czTangt.github.io/blog/posts/ai/large_language_model/"><meta property="og:site_name" content="czTang"><meta property="og:title" content="Large Language Model"><meta property="og:description" content="这里主要记录在大模型原理和技术课程中的学习。"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-01-17T10:17:51+08:00"><meta property="article:modified_time" content="2025-01-18T21:56:15+08:00"><meta property="article:tag" content="AI"><meta name=twitter:card content="summary"><meta name=twitter:title content="Large Language Model"><meta name=twitter:description content="这里主要记录在大模型原理和技术课程中的学习。"><meta name=application-name content="FixIt"><meta name=apple-mobile-web-app-title content="FixIt"><meta name=theme-color data-light=#f8f8f8 data-dark=#252627 content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel=icon href=https://nuthecz.oss-cn-hangzhou.aliyuncs.com/file/202410312135963.svg><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical type=text/html href=https://czTangt.github.io/blog/posts/ai/large_language_model/ title="Large Language Model - czTang"><link rel=prev type=text/html href=https://czTangt.github.io/blog/posts/staticanalysis/data-flow-analysis/ title="03 Data Flow Analysis"><link rel=next type=text/html href=https://czTangt.github.io/blog/posts/config/docker/ title=Docker><link rel=stylesheet href=/blog/css/style.min.css><link rel=preload href=/blog/lib/fontawesome-free/all.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/blog/lib/fontawesome-free/all.min.css></noscript><link rel=preload href=/blog/lib/animate/animate.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/blog/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Large Language Model","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/czTangt.github.io\/blog\/posts\/ai\/large_language_model\/"},"genre":"posts","keywords":"AI","wordcount":15354,"url":"https:\/\/czTangt.github.io\/blog\/posts\/ai\/large_language_model\/","datePublished":"2025-01-17T10:17:51+08:00","dateModified":"2025-01-18T21:56:15+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"czTang"},"description":""}</script><script src=/blog/js/head/color-scheme.min.js></script></head><body data-header-desktop=sticky data-header-mobile=auto><div class=wrapper data-page-style=normal><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper data-github-corner=left><div class=header-title><a href=/blog/ title=czTang><span class=header-title-pre><i class='fa fa-coffee'>&nbsp</i></span><span class=header-title-text>czTang</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/blog/archives/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> Archives</a></li><li class=menu-item><a class=menu-link href=/blog/categories/><i class="fa-solid fa-folder-tree fa-fw fa-sm" aria-hidden=true></i> Categories</a></li><li class=menu-item><a class=menu-link href=/blog/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> Tags</a></li><li class=menu-item><a class=menu-link href=/blog/about/><i class="fa-solid fa-user fa-fw fa-sm" aria-hidden=true></i> About</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容…… id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/blog/ title=czTang><span class=header-title-pre><i class='fa fa-coffee'>&nbsp</i></span><span class=header-title-text>czTang</span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容…… id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/blog/archives/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> Archives</a></li><li class=menu-item><a class=menu-link href=/blog/categories/><i class="fa-solid fa-folder-tree fa-fw fa-sm" aria-hidden=true></i> Categories</a></li><li class=menu-item><a class=menu-link href=/blog/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> Tags</a></li><li class=menu-item><a class=menu-link href=/blog/about/><i class="fa-solid fa-user fa-fw fa-sm" aria-hidden=true></i> About</a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=container><aside class="aside-collection animate__animated animate__fadeIn animate__faster" aria-label=合集><div class="details collection-details open"><div class="details-summary collection-summary"><i class="fa-solid fa-layer-group fa-fw" aria-hidden=true></i>
<span class=collection-name title=合集>Research</span>
<span class=collection-count>2</span><i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class="details-content collection-content"><nav><ul class=collection-list><li class=collection-item><a href=/blog/posts/ai/ai_knowledge/ title="AI Knowledge">AI Knowledge</a></li><li class=collection-item><span class=active title="Large Language Model">Large Language Model</span></li></ul><div class=collection-nav-simple><a href=/blog/posts/ai/ai_knowledge/ class=collection-nav-item rel=prev title="AI Knowledge"><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i></a><span class=text-secondary>2/2</span><i class="fa-solid fa-angle-right fa-fw collection-nav-item text-secondary" aria-hidden=true></i></div></nav></div></div></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>Large Language Model</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://github.com/czTangt title=作者 target=_blank rel="external nofollow noopener noreferrer author" class=author><img loading=lazy src=/blog/images/avatar.jpg alt=czTang data-title=czTang width=20 height=20 class=avatar style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'>&nbsp;czTang</a></span><span class=post-included-in>&nbsp;收录于 <a href=/blog/categories/ai/ class=post-category title="分类 - AI"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> AI</a> 和 <a href=/blog/collections/research/ class=post-collection title="合集 - Research"><i class="fa-solid fa-layer-group fa-fw" aria-hidden=true></i> Research</a></span></div><div class=post-meta-line><span title="发布于 2025-01-17 10:17:51"><i class="fa-solid fa-calendar-days fa-fw me-1" aria-hidden=true></i><time datetime=2025.1.17>2025.1.17</time></span>&nbsp;<span title="更新于 2025-01-18 21:56:15"><i class="fa-regular fa-calendar-check fa-fw me-1" aria-hidden=true></i><time datetime=2025.1.18>2025.1.18</time></span>&nbsp;<span title="15354 字"><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden=true></i>约 15400 字</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden=true></i>预计阅读 31 分钟</span>&nbsp;</div></div><div class="details toc" id=toc-static data-kept=false><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fa-solid fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#语言模型基础>语言模型基础</a><ul><li><a href=#基于统计方法的语言模型>基于统计方法的语言模型</a><ul><li><a href=#n-grams-语言模型>n-grams 语言模型</a></li><li><a href=#n-grams-的统计学原理>n-grams 的统计学原理</a></li></ul></li><li><a href=#基于-rnn-的语言模型>基于 RNN 的语言模型</a><ul><li><a href=#rnn-的基本原理>RNN 的基本原理</a></li><li><a href=#基于-rnn-的语言模型-1>基于 RNN 的语言模型</a></li></ul></li><li><a href=#基于-transformer-的语言模型>基于 Transformer 的语言模型</a><ul><li><a href=#transformer-的基本原理>Transformer 的基本原理</a></li><li><a href=#基于-transformer-的语言模型-1>基于 Transformer 的语言模型</a></li></ul></li><li><a href=#语言模型的采样方法>语言模型的采样方法</a></li><li><a href=#语言模型的评测>语言模型的评测</a></li></ul></li><li><a href=#大语言模型架构>大语言模型架构</a><ul><li><a href=#大数据与大模型>大数据与大模型</a></li><li><a href=#大语言模型架构概览>大语言模型架构概览</a><ul><li><a href=#主流模型架构>主流模型架构</a></li><li><a href=#注意力矩阵>注意力矩阵</a></li></ul></li><li><a href=#基于-encoder-only-架构>基于 Encoder-only 架构</a><ul><li><a href=#bert-模型>BERT 模型</a></li><li><a href=#bert-衍生模型>BERT 衍生模型</a></li></ul></li><li><a href=#基于-encoder-decoder-架构>基于 Encoder-Decoder 架构</a><ul><li><a href=#t5-模型>T5 模型</a></li><li><a href=#bart-模型>BART 模型</a></li></ul></li><li><a href=#基于-decoder-only-架构>基于 Decoder-only 架构</a><ul><li><a href=#gpt-系列>GPT 系列</a></li><li><a href=#llama-系列>LLaMA 系列</a></li></ul></li><li><a href=#非-transformer-架构>非 Transformer 架构</a></li></ul></li><li><a href=#prompt-工程>Prompt 工程</a><ul><li><a href=#prompt-工程简介>Prompt 工程简介</a><ul><li><a href=#定义与背景>定义与背景</a></li><li><a href=#核心思想与重要性>核心思想与重要性</a></li><li><a href=#关键要素>关键要素</a></li></ul></li><li><a href=#上下文学习>上下文学习</a><ul><li><a href=#定义与核心思想>定义与核心思想</a></li><li><a href=#形式与示例选择>形式与示例选择</a></li><li><a href=#影响因素与优化策略>影响因素与优化策略</a></li></ul></li><li><a href=#思维链>思维链</a><ul><li><a href=#定义与核心思想-1>定义与核心思想</a></li><li><a href=#主要模式与应用场景>主要模式与应用场景</a></li><li><a href=#优化策略与未来方向>优化策略与未来方向</a></li></ul></li><li><a href=#prompt-技巧>Prompt 技巧</a><ul><li><a href=#规范-prompt-编写>规范 Prompt 编写</a></li><li><a href=#合理归纳提问>合理归纳提问</a></li><li><a href=#适时使用思维链cot>适时使用思维链（CoT）</a></li><li><a href=#善用心理暗示>善用心理暗示</a></li></ul></li><li><a href=#相关应用>相关应用</a><ul><li><a href=#基于大模型的-agent>基于大模型的 Agent</a></li><li><a href=#数据合成>数据合成</a></li><li><a href=#text-to-sql>Text-to-SQL</a></li></ul></li></ul></li><li><a href=#参数高效微调>参数高效微调</a><ul><li><a href=#简介>简介</a></li><li><a href=#参数附加方法>参数附加方法</a><ul><li><a href=#加在输入>加在输入</a></li><li><a href=#加在模型>加在模型</a><ul><li><a href=#prefix-tuning>Prefix-tuning</a></li><li><a href=#adapter-tuning>Adapter-tuning</a></li><li><a href=#adapterfusion>AdapterFusion</a></li></ul></li><li><a href=#加在输出>加在输出</a></li></ul></li><li><a href=#参数选择方法>参数选择方法</a><ul><li><a href=#基于规则的方法>基于规则的方法</a><ul><li><a href=#bitfit>BitFit</a></li><li><a href=#其他基于规则的方法>其他基于规则的方法</a></li></ul></li><li><a href=#基于学习的方法>基于学习的方法</a><ul><li><a href=#child-tuning>Child-tuning</a></li><li><a href=#其他基于学习的方法>其他基于学习的方法</a></li></ul></li></ul></li><li><a href=#低秩适配方法>低秩适配方法</a><ul><li><a href=#lora>LoRA</a><ul><li><a href=#方法实现>方法实现</a></li><li><a href=#参数效率分析>参数效率分析</a></li></ul></li><li><a href=#lora-相关变体>LoRA 相关变体</a></li><li><a href=#基于-lora-插件的任务泛化>基于 LoRA 插件的任务泛化</a></li></ul></li><li><a href=#实践与应用>实践与应用</a><ul><li><a href=#peft-实践>PEFT 实践</a><ul><li><a href=#peft-主流框架>PEFT 主流框架</a></li><li><a href=#hf-peft-框架使用>HF-PEFT 框架使用</a></li><li><a href=#peft-相关技巧>PEFT 相关技巧</a></li></ul></li><li><a href=#peft-应用>PEFT 应用</a><ul><li><a href=#表格数据查询>表格数据查询</a></li><li><a href=#表格数据分析>表格数据分析</a></li></ul></li></ul></li></ul></li></ul></nav></div></div><div class=content id=content><p>这里主要记录在<a href="https://www.bilibili.com/video/BV1PB6XYFET2/?spm_id_from=333.1387.collection.video_card.click" target=_blank rel="external nofollow noopener noreferrer">大模型原理和技术</a>课程中的学习。</p><h2 id=语言模型基础 class=heading-element><span>语言模型基础</span>
<a href=#%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e5%9f%ba%e7%a1%80 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>语言是概率的。并且，语言的概率性与认知的概率性存在着密不可分的关系。语言模型（Language Models, LMs）旨在准确预测语言符号的概率。，语言模型经历了从规则模型到统计模型，再到神经网络模型的发展历程，逐步从呆板的机械式问答程序成长为具有强大泛化能力的多任务智能模型。下面按照语言模型发展的顺序依次进行讲解。</p><h3 id=基于统计方法的语言模型 class=heading-element><span>基于统计方法的语言模型</span>
<a href=#%e5%9f%ba%e4%ba%8e%e7%bb%9f%e8%ae%a1%e6%96%b9%e6%b3%95%e7%9a%84%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=n-grams-语言模型 class=heading-element><span>n-grams 语言模型</span>
<a href=#n-grams-%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>定义</strong>：n-grams 是一种基于统计的语言模型，通过统计语料库中词序列的频率来预测语言符号的概率。</li><li><strong>计算方法</strong>：n-grams 模型通过计算词序列的相对频率来预测文本的概率。公式为：
$$
P_{n-grams}(w_{1:N}) = \prod_{i=n}^{N} \frac{C(w_{i-n+1}:i)}{C(w_{i-n+1}:i-1)}
$$
其中，$C(w_{i-n+1}:i)$ 是词序列在语料库中出现的次数。</li><li><strong>马尔可夫假设</strong>：n-grams 模型基于 n 阶马尔可夫假设，即当前词的概率只与前 n 个词有关。</li><li><strong>零概率问题</strong>：当 n 较大时，语料库中可能找不到与 n-gram 完全匹配的词序列，导致零概率问题。可以通过平滑技术来缓解。</li></ul><h4 id=n-grams-的统计学原理 class=heading-element><span>n-grams 的统计学原理</span>
<a href=#n-grams-%e7%9a%84%e7%bb%9f%e8%ae%a1%e5%ad%a6%e5%8e%9f%e7%90%86 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>极大似然估计</strong>：n-grams 模型通过极大似然估计来近似词序列的概率。具体来说，n-grams 模型通过统计词序列的频率来估计条件概率 $P(w_i|w_{i-n+1}:i-1)$。</li></ul><h3 id=基于-rnn-的语言模型 class=heading-element><span>基于 RNN 的语言模型</span>
<a href=#%e5%9f%ba%e4%ba%8e-rnn-%e7%9a%84%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=rnn-的基本原理 class=heading-element><span>RNN 的基本原理</span>
<a href=#rnn-%e7%9a%84%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>循环传播范式</strong>：RNN 通过环路将历史状态叠加到当前状态上，从而能够基于历史信息进行预测。</li><li><strong>隐状态</strong>：RNN 的隐状态 $h_t$ 通过以下公式计算：
$$
h_t = g(W_H h_{t-1} + W_I x_t)
$$
其中，$g(\cdot)$ 是激活函数，$W_H$ 和 $W_I$ 是权重矩阵。</li><li><strong>梯度消失与爆炸</strong>：RNN 在训练过程中容易遇到梯度消失或梯度爆炸问题，可以通过 GRU 或 LSTM 等门控结构来缓解。</li></ul><h4 id=基于-rnn-的语言模型-1 class=heading-element><span>基于 RNN 的语言模型</span>
<a href=#%e5%9f%ba%e4%ba%8e-rnn-%e7%9a%84%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b-1 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>预测下一个词</strong>：基于 RNN 的语言模型通过当前词和隐状态来预测下一个词的概率：
$$
P(w_{i+1}|w_{1:i}) = P(w_{i+1}|w_i, h_{i-1})
$$</li><li><strong>损失函数</strong>：通常使用交叉熵损失函数来训练 RNN 语言模型：
$$
l_{CE}(o_i) = -\log o_i [w_{i+1}]
$$</li><li><strong>Teacher Forcing</strong>：在训练过程中，使用标准答案作为下一轮的输入，以减少错误级联放大问题。</li></ul><h3 id=基于-transformer-的语言模型 class=heading-element><span>基于 Transformer 的语言模型</span>
<a href=#%e5%9f%ba%e4%ba%8e-transformer-%e7%9a%84%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=transformer-的基本原理 class=heading-element><span>Transformer 的基本原理</span>
<a href=#transformer-%e7%9a%84%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>注意力机制</strong>：Transformer 通过自注意力机制将前文信息叠加到当前状态上。自注意力层的输出为：
$$
Attention(x_t) = \sum_{i=1}^{t} \alpha_{t,i} v_i
$$
其中，$\alpha_{t,i}$ 是注意力权重。</li><li><strong>全连接前馈层</strong>：全连接前馈层负责记忆存储，公式为：
$$
FFN(v) = \max(0, W_1 v + b_1) W_2 + b_2
$$</li><li><strong>层正则化与残差连接</strong>：层正则化用于加速训练，残差连接用于缓解梯度消失问题。</li></ul><h4 id=基于-transformer-的语言模型-1 class=heading-element><span>基于 Transformer 的语言模型</span>
<a href=#%e5%9f%ba%e4%ba%8e-transformer-%e7%9a%84%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b-1 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>下一词预测</strong>：Transformer 语言模型通过上文预测下一个词的概率：
$$
P(w_{i+1}|w_{1:i}) = o_i [w_{i+1}]
$$</li><li><strong>损失函数</strong>：同样使用交叉熵损失函数进行训练。</li></ul><h3 id=语言模型的采样方法 class=heading-element><span>语言模型的采样方法</span>
<a href=#%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%e9%87%87%e6%a0%b7%e6%96%b9%e6%b3%95 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ol><li><p><strong>概率最大化方法</strong>：</p><ul><li><strong>贪心搜索</strong>：每轮选择概率最大的词，容易陷入局部最优。</li><li><strong>波束搜索</strong>：每轮保留多个候选词，最终选择联合概率最大的词序列。</li></ul></li><li><p><strong>随机采样方法</strong>：</p><ul><li><strong>Top-K 采样</strong>：每轮选择概率最高的 K 个词，然后根据概率分布进行随机采样。</li><li><strong>Top-P 采样</strong>：设定概率阈值 p，选择累积概率超过 p 的词进行采样。</li><li><strong>Temperature 机制</strong>：通过调整 Temperature 参数来控制采样的随机性。</li></ul></li></ol><h3 id=语言模型的评测 class=heading-element><span>语言模型的评测</span>
<a href=#%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e7%9a%84%e8%af%84%e6%b5%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ol><li><p><strong>内在评测</strong>：</p><ul><li><strong>困惑度（Perplexity）</strong>：衡量语言模型对测试文本的“困惑”程度，困惑度越低，模型性能越好。
$$
PPL(s_{test}) = P(w_{1:N})^{-\frac{1}{N}}
$$</li></ul></li><li><p><strong>外在评测</strong>：</p><ul><li><strong>基于统计指标的评测</strong>：如 BLEU 和 ROUGE，通过计算生成文本与标准答案的重合程度来评估模型性能。</li><li><strong>基于语言模型的评测</strong>：如 BERTScore 和 G-EVAL，利用语言模型的上下文词嵌入或生成能力来评估生成文本的质量。</li></ul></li></ol><h2 id=大语言模型架构 class=heading-element><span>大语言模型架构</span>
<a href=#%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e6%9e%b6%e6%9e%84 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><h3 id=大数据与大模型 class=heading-element><span>大数据与大模型</span>
<a href=#%e5%a4%a7%e6%95%b0%e6%8d%ae%e4%b8%8e%e5%a4%a7%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ol><li><p><strong>大数据与大模型的关系</strong>：</p><ul><li>数据规模的增长为模型提供了更丰富的信息源，模型规模的扩大增加了模型的表达能力。</li><li>模型规模和数据规模的增长共同作用，提升了模型的性能和新功能的涌现。</li><li><strong>扩展法则</strong>：<ul><li><strong>Kaplan-McCandlish 扩展法则</strong>：模型性能与模型规模和数据规模高度正相关，模型规模的增长速度应略快于数据规模。</li><li><strong>Chinchilla 扩展法则</strong>：数据集规模与模型规模同等重要，理想的数据集大小应为模型规模的20倍。</li></ul></li></ul></li><li><p><strong>涌现能力</strong>：</p><ul><li>随着模型规模和数据规模的提升，大语言模型涌现出新的能力，如上下文学习、常识推理、代码生成、逻辑推理等。</li><li>这些能力并非通过特定任务训练获得，而是随着模型复杂度的提升自然涌现。</li></ul></li></ol><h3 id=大语言模型架构概览 class=heading-element><span>大语言模型架构概览</span>
<a href=#%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e6%9e%b6%e6%9e%84%e6%a6%82%e8%a7%88 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=主流模型架构 class=heading-element><span>主流模型架构</span>
<a href=#%e4%b8%bb%e6%b5%81%e6%a8%a1%e5%9e%8b%e6%9e%b6%e6%9e%84 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>Encoder-only 架构</strong>：仅使用编码器，适合自然语言理解任务，如文本分类、情感分析等。</li><li><strong>Encoder-Decoder 架构</strong>：包含编码器和解码器，适合序列到序列任务，如机器翻译、文本摘要等。</li><li><strong>Decoder-only 架构</strong>：仅使用解码器，适合开放式生成任务，如文本生成、故事生成等。</li></ul><h4 id=注意力矩阵 class=heading-element><span>注意力矩阵</span>
<a href=#%e6%b3%a8%e6%84%8f%e5%8a%9b%e7%9f%a9%e9%98%b5 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>Encoder-only</strong>：双向注意力，捕捉输入序列中所有Token的关系。</li><li><strong>Encoder-Decoder</strong>：结合编码器的双向注意力和解码器的单向注意力，适合复杂生成任务。</li><li><strong>Decoder-only</strong>：单向注意力，适合自回归生成任务。</li></ul><h3 id=基于-encoder-only-架构 class=heading-element><span>基于 Encoder-only 架构</span>
<a href=#%e5%9f%ba%e4%ba%8e-encoder-only-%e6%9e%b6%e6%9e%84 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=bert-模型 class=heading-element><span>BERT 模型</span>
<a href=#bert-%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>结构</strong>：基于 Transformer 编码器，包含多层自注意力和前馈网络。</li><li><strong>预训练任务</strong>：掩码语言建模（MLM）和下文预测（NSP）。</li><li><strong>下游任务</strong>：文本分类、问答系统、语义相似度计算等。</li></ul><h4 id=bert-衍生模型 class=heading-element><span>BERT 衍生模型</span>
<a href=#bert-%e8%a1%8d%e7%94%9f%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>RoBERTa</strong>：优化了 BERT 的预训练过程，使用更大的数据集和动态掩码。</li><li><strong>ALBERT</strong>：通过参数共享和嵌入分解减少参数量，提升训练效率。</li><li><strong>ELECTRA</strong>：引入生成器-判别器架构，提升训练效率和下游任务表现。</li></ul><h3 id=基于-encoder-decoder-架构 class=heading-element><span>基于 Encoder-Decoder 架构</span>
<a href=#%e5%9f%ba%e4%ba%8e-encoder-decoder-%e6%9e%b6%e6%9e%84 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=t5-模型 class=heading-element><span>T5 模型</span>
<a href=#t5-%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>结构</strong>：统一的文本到文本生成框架，适合多种 NLP 任务。</li><li><strong>预训练任务</strong>：Span Corruption，预测被掩码的连续文本片段。</li><li><strong>下游任务</strong>：通过 Prompt 工程和微调适配多种任务。</li></ul><h4 id=bart-模型 class=heading-element><span>BART 模型</span>
<a href=#bart-%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>结构</strong>：结合编码器和解码器，适合文本生成和理解任务。</li><li><strong>预训练任务</strong>：多种文本破坏任务，如 Token 遮挡、句子打乱等。</li><li><strong>下游任务</strong>：文本生成、文本摘要、问答系统等。</li></ul><h3 id=基于-decoder-only-架构 class=heading-element><span>基于 Decoder-only 架构</span>
<a href=#%e5%9f%ba%e4%ba%8e-decoder-only-%e6%9e%b6%e6%9e%84 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=gpt-系列 class=heading-element><span>GPT 系列</span>
<a href=#gpt-%e7%b3%bb%e5%88%97 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>GPT-1</strong>：初代 Decoder-only 模型，使用下一词预测任务进行预训练。</li><li><strong>GPT-2</strong>：增加模型规模和预训练数据，提升任务泛化能力。</li><li><strong>GPT-3</strong>：大幅增加模型规模和数据规模，涌现出上下文学习能力。</li><li><strong>ChatGPT 和 GPT-4</strong>：引入人类反馈强化学习（RLHF），提升指令跟随能力。</li></ul><h4 id=llama-系列 class=heading-element><span>LLaMA 系列</span>
<a href=#llama-%e7%b3%bb%e5%88%97 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ul><li><strong>LLaMA1</strong>：小模型+大数据理念，优化了 Transformer 的嵌入和注意力机制。</li><li><strong>LLaMA2</strong>：增加预训练数据规模，引入人类反馈强化学习。</li><li><strong>LLaMA3</strong>：大幅增加预训练数据规模，提升跨语言处理能力。</li></ul><h3 id=非-transformer-架构 class=heading-element><span>非 Transformer 架构</span>
<a href=#%e9%9d%9e-transformer-%e6%9e%b6%e6%9e%84 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ol><li><p><strong>状态空间模型（SSM）</strong>：</p><ul><li><strong>SSM</strong>：通过状态变量捕捉系统状态的变化，适合处理长序列数据。</li><li><strong>RWKV</strong>：结合RNN和Transformer的优点，实现高效的长序列处理。</li><li><strong>Mamba</strong>：引入选择机制和硬件感知算法，提升长序列处理效率。</li></ul></li><li><p><strong>测试时训练（TTT）</strong>：</p><ul><li><strong>TTT</strong>：在推理阶段动态更新模型参数，提升长上下文建模能力。</li><li><strong>优势</strong>：线性时间复杂度，适合处理超长序列任务。</li></ul></li></ol><h2 id=prompt-工程 class=heading-element><span>Prompt 工程</span>
<a href=#prompt-%e5%b7%a5%e7%a8%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><h3 id=prompt-工程简介 class=heading-element><span>Prompt 工程简介</span>
<a href=#prompt-%e5%b7%a5%e7%a8%8b%e7%ae%80%e4%bb%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=定义与背景 class=heading-element><span>定义与背景</span>
<a href=#%e5%ae%9a%e4%b9%89%e4%b8%8e%e8%83%8c%e6%99%af class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>Prompt 工程是指通过精心设计的指令（Prompt）来引导生成式人工智能模型执行特定任务，而无需进行繁琐的微调。它是用户输入给模型的指令或问题，通常以自然语言的形式呈现，目的是引导模型生成符合任务需求的输出。传统的自然语言处理（NLP）研究遵循 “预训练-微调-预测” 范式，即在大规模语料库上进行预训练，然后针对特定任务进行微调，最后在微调后的模型上进行预测。然而，随着大语言模型（LLM）的规模和能力的提升，一种新的范式—— “预训练-提示预测” 应运而生。这种范式通过精心设计的 Prompt 直接引导模型适应下游任务，避免了微调的高昂成本。</p><h4 id=核心思想与重要性 class=heading-element><span>核心思想与重要性</span>
<a href=#%e6%a0%b8%e5%bf%83%e6%80%9d%e6%83%b3%e4%b8%8e%e9%87%8d%e8%a6%81%e6%80%a7 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>Prompt 工程的核心思想是通过设计合适的 Prompt，将新任务转化为模型在预训练阶段已经熟悉的形式，从而利用模型的泛化能力完成任务。大语言模型在预训练阶段学习了大量的语言知识和任务模式，具备强大的 <strong>泛化能力</strong>。同时，大语言模型还具备强大的 <strong>指令跟随能力</strong>，能够根据用户的指令生成符合预期的输出。Prompt 工程通过设计清晰、具体的指令，确保模型能够准确理解任务需求并生成高质量的输出。</p><p>Prompt 工程的重要性体现在多个方面。首先，它避免了传统微调方法带来的高昂成本。传统的微调方法需要针对每个任务进行特定的训练，耗费大量的计算资源和时间。而 Prompt 工程通过设计有效的 Prompt，避免了微调带来的高昂成本。其次，Prompt 工程提供了一种灵活的方式来执行各种任务，用户只需通过修改 Prompt 即可引导模型适应不同的任务需求。最后，Prompt 工程在文本生成、情感分析、问答系统、代码生成等多个领域都有广泛的应用，能够显著提升模型的性能。</p><h4 id=关键要素 class=heading-element><span>关键要素</span>
<a href=#%e5%85%b3%e9%94%ae%e8%a6%81%e7%b4%a0 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>Prompt 工程的成功依赖于对模型和任务的深入理解。一个有效的 Prompt 通常由四个关键要素组成：任务说明、上下文、问题和输出格式。任务说明用于明确描述模型需要完成的任务，确保模型理解任务的核心要求。上下文则提供与任务相关的背景信息或示例，帮助模型更好地理解任务。问题是用户的具体问题或需要处理的信息，为模型提供明确的起点。输出格式则指定模型输出的格式，如 JSON、XML 等，确保输出结构化和易于处理。</p><h3 id=上下文学习 class=heading-element><span>上下文学习</span>
<a href=#%e4%b8%8a%e4%b8%8b%e6%96%87%e5%ad%a6%e4%b9%a0 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=定义与核心思想 class=heading-element><span>定义与核心思想</span>
<a href=#%e5%ae%9a%e4%b9%89%e4%b8%8e%e6%a0%b8%e5%bf%83%e6%80%9d%e6%83%b3 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>上下文学习（In-Context Learning, ICL）是一种通过构造特定的 Prompt 来引导大语言模型理解并学习下游任务的范式。这些特定的 Prompt 中通常包含任务说明和一系列示例，模型能够从这些上下文信息中学习任务的逻辑和规则，从而在没有额外训练的情况下生成符合任务要求的输出。上下文学习的核心思想是利用大语言模型在预训练阶段学到的泛化能力，通过提供任务相关的上下文信息，使模型能够快速适应新的任务。</p><p>与传统的微调方法不同，上下文学习不需要对模型进行额外的训练，而是通过设计有效的 Prompt 来引导模型完成任务。这种方法特别适用于需要快速适应新任务的场景，例如用户通过 API 或页面与大语言模型进行交互时。上下文学习的出现为 “语言模型即服务”（LLM as a Service）模式奠定了坚实的基础。</p><h4 id=形式与示例选择 class=heading-element><span>形式与示例选择</span>
<a href=#%e5%bd%a2%e5%bc%8f%e4%b8%8e%e7%a4%ba%e4%be%8b%e9%80%89%e6%8b%a9 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>上下文学习可以根据提供的示例数量分为三种形式：零样本（Zero-shot）、单样本（One-shot）和少样本（Few-shot）。零样本上下文学习仅提供任务说明，不提供任何示例，依赖模型的泛化能力完成任务。单样本上下文学习提供一个示例，帮助模型理解任务的基本模式。少样本上下文学习则提供少量示例（通常几个至十几个），显著提升模型在特定任务上的表现。</p><p>示例的选择对上下文学习的效果至关重要。示例的选择主要依赖于相似性和多样性。相似性是指选择与待解决问题最为相近的示例，帮助模型更好地理解任务。多样性则要求示例涵盖尽量广的内容，扩大示例对任务的覆盖范围，增强模型应对各种问题的能力。常见的示例选择方法包括直接检索、聚类检索和迭代检索。直接检索根据相似性选择示例，聚类检索通过聚类保证示例的多样性，而迭代检索则兼顾相似性和多样性，动态选择示例。</p><h4 id=影响因素与优化策略 class=heading-element><span>影响因素与优化策略</span>
<a href=#%e5%bd%b1%e5%93%8d%e5%9b%a0%e7%b4%a0%e4%b8%8e%e4%bc%98%e5%8c%96%e7%ad%96%e7%95%a5 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>上下文学习的性能受到多种因素的影响，包括预训练数据、模型规模以及演示示例的质量。预训练数据的领域丰富度和任务多样性直接影响模型的上下文学习能力。模型规模越大，上下文学习的能力通常越强，尤其是在参数数量达到亿级别及以上的模型中，上下文学习的效果更为显著。</p><p>演示示例的质量也对上下文学习的效果有重要影响。示例的格式、输入-输出映射的正确性、示例数量和顺序都会影响模型的表现。例如，在复杂推理任务中，使用思维链（Chain of Thought, CoT）形式的示例可以显著提升模型的推理能力。此外，增加示例数量通常能够提升上下文学习的性能，但随着示例数量的增多，性能提升的速率会逐渐减缓。</p><p>为了优化上下文学习的效果，可以采取以下策略：</p><ol><li><strong>设计清晰的 Prompt</strong>：确保任务说明明确，上下文信息丰富且相关，输出格式规范。</li><li><strong>选择合适的示例</strong>：根据任务需求选择相似性和多样性兼备的示例，帮助模型更好地理解任务。</li><li><strong>调整示例顺序</strong>：不同的示例顺序可能对模型的表现产生显著影响，可以通过实验找到最优的示例顺序。</li></ol><h3 id=思维链 class=heading-element><span>思维链</span>
<a href=#%e6%80%9d%e7%bb%b4%e9%93%be class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=定义与核心思想-1 class=heading-element><span>定义与核心思想</span>
<a href=#%e5%ae%9a%e4%b9%89%e4%b8%8e%e6%a0%b8%e5%bf%83%e6%80%9d%e6%83%b3-1 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>思维链（Chain of Thought, CoT）是一种通过模拟人类解决复杂问题时的思考过程，引导大语言模型生成中间推理步骤的 Prompt 范式。它的核心思想是通过在 Prompt 中嵌入逐步推理的示例或提示，帮助模型在生成答案的过程中引入逻辑连贯的中间步骤，从而显著提升模型在复杂推理任务中的表现。</p><p>传统的语言模型在处理简单任务（如文本分类、情感分析）时表现良好，但在面对需要复杂推理的任务（如算术求解、常识判断、符号推理）时，往往表现不佳。这种现象被称为“Flat Scaling Curves”，即模型规模的扩大并未带来预期的性能提升。思维链技术的出现解决了这一问题，它通过引导模型逐步推理，显著提升了模型在复杂任务中的表现。</p><p>思维链的核心在于构造合适的 Prompt，以触发模型生成推理路径。早期的方法通过在 Prompt 中加入少量包含推理过程的示例（Few-Shot Demonstrations），引导模型模仿这些示例逐步生成答案。随着技术的发展，思维链衍生出了多种变体，如 Zero-Shot CoT、Auto-CoT、思维树（Tree of Thoughts, ToT）和思维图（Graph of Thoughts, GoT）等。</p><h4 id=主要模式与应用场景 class=heading-element><span>主要模式与应用场景</span>
<a href=#%e4%b8%bb%e8%a6%81%e6%a8%a1%e5%bc%8f%e4%b8%8e%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>思维链技术可以根据推理方式的不同分为三种主要模式：按部就班、三思后行和集思广益。</p><ol><li><p><strong>按部就班</strong>：</p><ul><li><strong>特点</strong>：模型逐步推理，逻辑连贯，推理路径形成一条清晰的链条。</li><li><strong>代表方法</strong>：CoT、Zero-Shot CoT、Auto-CoT。</li><li><strong>应用场景</strong>：适用于需要逐步推理的任务，如算术求解、逻辑推理等。</li></ul></li><li><p><strong>三思后行</strong>：</p><ul><li><strong>特点</strong>：模型在每一步推理中评估当前情况，选择最佳推理方向，允许回溯和重新选择。</li><li><strong>代表方法</strong>：思维树（ToT）、思维图（GoT）。</li><li><strong>应用场景</strong>：适用于需要探索多种推理路径的任务，如创意写作、复杂问题求解等。</li></ul></li><li><p><strong>集思广益</strong>：</p><ul><li><strong>特点</strong>：模型生成多条推理路径，整合后得到最优答案。</li><li><strong>代表方法</strong>：Self-Consistency。</li><li><strong>应用场景</strong>：适用于需要高准确性和可靠性的任务，如代码生成、复杂决策等。</li></ul></li></ol><h4 id=优化策略与未来方向 class=heading-element><span>优化策略与未来方向</span>
<a href=#%e4%bc%98%e5%8c%96%e7%ad%96%e7%95%a5%e4%b8%8e%e6%9c%aa%e6%9d%a5%e6%96%b9%e5%90%91 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>思维链技术的成功依赖于 Prompt 的设计和模型的推理能力。为了进一步提升思维链的效果，可以采取以下优化策略：</p><ol><li><strong>调整推理详细程度</strong>：根据任务需求调整思维链的详细程度。对于简单任务，可以直接给出最终答案；对于复杂任务，则需要展示完整的推理步骤。</li><li><strong>结合多种模式</strong>：根据任务特点灵活选择思维链的模式。例如，在需要高准确性的任务中使用 Self-Consistency，在需要创意的任务中使用 ToT 或 GoT。</li><li><strong>优化示例选择</strong>：选择与任务高度相关的示例，确保示例的多样性和代表性，帮助模型更好地理解任务。</li></ol><p>未来，思维链技术可能会在以下方向进一步发展：</p><ul><li><strong>自动化推理</strong>：通过自动生成推理路径，减少对人工示例的依赖。</li><li><strong>多模态推理</strong>：将思维链技术应用于多模态任务，如图像生成、视频理解等。</li><li><strong>个性化推理</strong>：根据用户需求生成个性化的推理路径，提升用户体验。</li></ul><h3 id=prompt-技巧 class=heading-element><span>Prompt 技巧</span>
<a href=#prompt-%e6%8a%80%e5%b7%a7 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>Prompt 技巧通过 <strong>规范 Prompt 编写</strong>、<strong>合理归纳提问</strong>、<strong>适时使用思维链</strong> 和 <strong>善用心理暗示</strong>，显著提升了大语言模型的交互效率和输出质量。规范 Prompt 编写确保模型准确理解任务需求，合理归纳提问帮助模型提供更详细、准确的回答，适时使用思维链提升模型在复杂推理任务中的表现，善用心理暗示则通过角色扮演和情景代入生成更符合预期的内容。这些技巧的结合使用，能够最大化地发挥大语言模型的潜力，使其在多样化的应用场景中发挥出卓越的性能。</p><h4 id=规范-prompt-编写 class=heading-element><span>规范 Prompt 编写</span>
<a href=#%e8%a7%84%e8%8c%83-prompt-%e7%bc%96%e5%86%99 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>编写规范的 Prompt 是确保大语言模型生成高质量输出的基础。一个有效的 Prompt 通常由四个关键要素组成：任务说明、上下文、问题和输出格式。任务说明用于明确描述模型需要完成的任务，确保模型理解任务的核心要求。上下文则提供与任务相关的背景信息或示例，帮助模型更好地理解任务。问题是用户的具体问题或需要处理的信息，为模型提供明确的起点。输出格式则指定模型输出的格式，如 JSON、XML 等，确保输出结构化和易于处理。</p><p>在设计 Prompt 时，任务说明应尽量明确和具体，避免模糊不清的描述。例如，在情感分类任务中，任务说明“判断下面句子的情感为积极还是消极”比“分类下面的句子”更加清晰。上下文应丰富且相关，避免包含冗余或不必要的信息。输出格式应规范，确保模型生成的输出易于解析和处理。此外，Prompt 的排版也非常重要，使用分隔符、空白和缩进可以增强 Prompt 的可读性，帮助模型更好地理解任务。</p><h4 id=合理归纳提问 class=heading-element><span>合理归纳提问</span>
<a href=#%e5%90%88%e7%90%86%e5%bd%92%e7%ba%b3%e6%8f%90%e9%97%ae class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>在与大语言模型的交互中，提问的质量直接影响到信息触达的效率和深度。一个精心设计的提问不仅能够明确表达需求，还能引导模型聚焦于问题的核心，从而获得精准且有价值的答案。合理归纳提问的策略主要包括复杂问题拆解和追问。</p><ol><li><strong>复杂问题拆解</strong>：<ul><li><strong>特点</strong>：将复杂问题分解为多个子问题，逐步引导模型回答。</li><li><strong>应用场景</strong>：适用于需要深入分析的复杂任务，如数据分析、决策支持等。</li></ul></li><li><strong>追问</strong>：<ul><li><strong>特点</strong>：通过连续提问引导模型提供更详细、准确的回答。</li><li><strong>形式</strong>：<ul><li><strong>深入追问</strong>：挖掘特定话题的深层信息。</li><li><strong>扩展追问</strong>：拓宽讨论的广度，收集更多相关信息。</li><li><strong>反馈追问</strong>：指出模型输出中的错误或不足，请求更正或澄清。</li></ul></li></ul></li></ol><h4 id=适时使用思维链cot class=heading-element><span>适时使用思维链（CoT）</span>
<a href=#%e9%80%82%e6%97%b6%e4%bd%bf%e7%94%a8%e6%80%9d%e7%bb%b4%e9%93%becot class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>思维链技术（Chain of Thought, CoT）在处理涉及复杂推理的任务时非常有效。通过引导模型生成中间推理步骤，可以显著提升模型在算术、常识判断和符号推理等任务中的表现。然而，并非所有任务都适合使用 CoT，因此需要根据任务类别、模型规模和模型能力来决定是否使用 CoT。</p><ol><li><p><strong>任务类别</strong>：</p><ul><li>适合使用 CoT 的任务：算术求解、逻辑推理、符号推理等需要复杂推理的任务。</li><li>不适合使用 CoT 的任务：情感分类、简单问答等任务，标准的 Prompt 方法已足够有效。</li></ul></li><li><p><strong>模型规模</strong>：</p><ul><li>适合使用 CoT 的模型：参数量超过千亿的巨型模型，如 GPT-4、PaLM 等。</li><li>不适合使用 CoT 的模型：规模较小的模型可能生成逻辑不连贯的思维链，导致结果不准确。</li></ul></li><li><p><strong>模型能力</strong>：</p><ul><li>未经推理微调的模型：适合使用 CoT，能够显著提升推理能力。</li><li>经过推理微调的模型：如 ChatGPT、GPT-4，可能已经内化了 CoT 推理路径，无需显式使用 CoT。</li></ul></li></ol><h4 id=善用心理暗示 class=heading-element><span>善用心理暗示</span>
<a href=#%e5%96%84%e7%94%a8%e5%bf%83%e7%90%86%e6%9a%97%e7%a4%ba class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>心理暗示是一种通过角色扮演和情景代入的方式，引导大语言模型生成更符合预期的内容的技术。通过为大语言模型设定特定的角色或情景，可以显著提升模型在特定任务中的表现。</p><ol><li><strong>角色扮演</strong>：<ul><li><strong>特点</strong>：通过设定特定角色，引导模型生成更符合角色需求的内容。</li></ul></li><li><strong>情景代入</strong>：<ul><li><strong>特点</strong>：将模型置于特定情境中，生成更具深度和情感共鸣的回答。</li></ul></li></ol><h3 id=相关应用 class=heading-element><span>相关应用</span>
<a href=#%e7%9b%b8%e5%85%b3%e5%ba%94%e7%94%a8 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>Prompt 工程在多个领域展现了广泛的应用前景。基于大语言模型的 Agent 通过角色扮演、记忆检索、任务规划和行动执行，能够自主完成复杂任务。数据合成技术通过生成高质量的训练数据，缓解了数据资源枯竭的问题。Text-to-SQL 技术通过自然语言查询生成 SQL 语句，降低了数据查询的门槛。GPTs 则通过自定义 Prompt 和工具，实现了个性化的模型定制。这些应用场景充分展示了 Prompt 工程在提升大语言模型交互和执行能力方面的独特优势和广阔前景。</p><h4 id=基于大模型的-agent class=heading-element><span>基于大模型的 Agent</span>
<a href=#%e5%9f%ba%e4%ba%8e%e5%a4%a7%e6%a8%a1%e5%9e%8b%e7%9a%84-agent class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>基于大语言模型的智能体（Agent）是一种能够自主感知环境并采取行动以实现特定目标的实体。Agent 的核心能力包括规划、决策、工具调用等复杂操作，这些操作依赖于 Prompt 工程技术的支持。Agent 的框架通常由四个模块组成：配置模块、记忆模块、计划模块和行动模块。</p><ol><li><strong>配置模块</strong>：通过角色扮演技术定义 Agent 的角色，设定 Agent 的背景、技能和职责。这些角色设定信息以上下文的形式嵌入到每次交互的 Prompt 中，确保 Agent 的行为符合角色需求。</li><li><strong>记忆模块</strong>：存储 Agent 的知识与交互记忆，通过检索增强技术获取相关记忆。记忆模块利用上下文学习技术构造和优化查询，帮助 Agent 更精准地检索到相关记忆。</li><li><strong>计划模块</strong>：将复杂任务分解为多个子任务，通过思维链技术进行任务规划。计划模块利用少样本示例调整子任务的粒度，确保任务流程的顺畅与高效。</li><li><strong>行动模块</strong>：将计划模块生成的计划转化为具体的行动步骤，并借助外部工具执行这些步骤。行动模块通过调用 API 接口的示例作为上下文，生成调用 API 的代码并执行。</li></ol><h4 id=数据合成 class=heading-element><span>数据合成</span>
<a href=#%e6%95%b0%e6%8d%ae%e5%90%88%e6%88%90 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>数据合成是通过大语言模型生成高质量训练数据的技术，能够缓解高质量数据资源枯竭的问题。数据合成的代表性方法是 Self-Instruct，它通过多步骤调用大语言模型，生成大量丰富且多样化的指令数据。</p><ol><li><strong>构建任务池</strong>：人工设计少量指令数据作为初始任务池。</li><li><strong>指令生成</strong>：从任务池中随机抽取示例，生成新的指令。</li><li><strong>指令分类</strong>：将生成的指令分类为分类任务或生成任务。</li><li><strong>数据生成</strong>：根据指令生成输入和回答部分。</li><li><strong>数据过滤</strong>：去除低质量或重复的数据，确保生成的数据质量。</li></ol><p>数据合成的意义在于，它不仅能够缓解高质量数据资源的枯竭问题，还能通过生成多样化的数据集，提高模型的泛化能力和鲁棒性。此外，数据合成还能在保护隐私的前提下，为特定领域的垂直数据提供有效的补充。</p><h4 id=text-to-sql class=heading-element><span>Text-to-SQL</span>
<a href=#text-to-sql class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>Text-to-SQL 技术将自然语言查询翻译成可以在数据库中执行的 SQL 语句，是实现零代码或低代码数据查询的有效途径。传统的 Text-to-SQL 方法需要大量训练数据，而基于大语言模型的零样本 Text-to-SQL 方法则通过 Prompt 工程技术优化生成效果。</p><ol><li><strong>清晰提示（Clear Prompting）</strong>：<ul><li><strong>清晰布局</strong>：通过明确符号划分指令、上下文和问题，确保指令模板清晰。</li><li><strong>清晰上下文</strong>：设计零样本 Prompt，指示模型从数据库中召回与问题相关的表和列。</li></ul></li><li><strong>提示校准（Calibration with Hints）</strong>：通过角色扮演技术校准模型的偏差，确保生成的 SQL 语句准确。</li><li><strong>一致输出（Consistent Output）</strong>：使用 Self-Consistency 方法对多种推理路径进行采样，选择一致的答案。</li></ol><h2 id=参数高效微调 class=heading-element><span>参数高效微调</span>
<a href=#%e5%8f%82%e6%95%b0%e9%ab%98%e6%95%88%e5%be%ae%e8%b0%83 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><h3 id=简介 class=heading-element><span>简介</span>
<a href=#%e7%ae%80%e4%bb%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p><strong>参数高效微调（Parameter-Efficient Fine-Tuning, PEFT）</strong> 是一种针对大语言模型在垂直领域适配的技术。由于大语言模型在预训练阶段通常使用海量数据，但在某些垂直领域（如医学、金融、法学等）中，预训练数据涉及较少，导致模型在这些领域的表现不佳。为了提升模型在这些领域的性能，通常需要对其进行微调。然而，大语言模型的参数量巨大，全量微调的成本高昂，尤其是在计算资源和存储资源有限的情况下，难以实现。因此，参数高效微调技术应运而生，旨在通过减少需要更新的参数量，降低微调成本，同时保持模型的性能。</p><p>在介绍参数高效微调之前，首先需要回顾两种常见的下游任务适配方法：上下文学习和指令微调。上下文学习通过设计提示词（Prompt）来驱动模型完成任务，无需更新模型参数，具有快速适配的优势。然而，上下文学习的性能通常不如微调，且提示词的设计需要大量人工成本，不同提示词的效果差异较大。此外，随着提示词中样例的增加，推理阶段的计算代价也会显著增加。指令微调则是通过构建指令数据集，对模型进行监督微调，使其能够更好地理解和执行各种自然语言处理任务。尽管指令微调能够显著提升模型在下游任务上的性能，但其计算资源需求较高，尤其是在大模型上，全量微调需要大量的内存和计算资源，普通消费级GPU难以胜任。</p><p>为了克服上下文学习和指令微调的局限性，参数高效微调技术通过仅更新 <strong>模型的一小部分参数</strong>，显著降低了微调的计算和存储成本。主流的参数高效微调方法可以分为三类：<strong>参数附加方法</strong>、<strong>参数选择方法</strong> 和 <strong>低秩适配方法</strong>。参数附加方法通过在模型中添加新的、较小的可训练模块（如适配器层）来实现高效微调；参数选择方法则通过选择性地更新模型中的部分参数（如偏置项或特定层的参数）来减少计算负担；低秩适配方法则通过低秩矩阵近似原始权重更新矩阵，仅微调低秩矩阵，从而大幅减少参数量。</p><p>参数高效微调的优势主要体现在以下几个方面：1) 计算效率高：由于仅更新少量参数，PEFT显著降低了训练时的计算资源消耗；2) 存储效率高：通过减少需要微调的参数量，PEFT降低了微调模型的存储需求，特别适用于内存受限的设备；3) 适应性强：PEFT能够快速适应不同任务，而无需重新训练整个模型，使得模型在面对变化环境时具有更高的灵活性。</p><p>总的来说，参数高效微调技术为大语言模型在垂直领域的应用提供了一种高效、低成本的解决方案，能够在保证性能的同时，显著降低微调的计算和存储成本。</p><h3 id=参数附加方法 class=heading-element><span>参数附加方法</span>
<a href=#%e5%8f%82%e6%95%b0%e9%99%84%e5%8a%a0%e6%96%b9%e6%b3%95 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>参数附加方法（Additional Parameter Methods）是参数高效微调（PEFT）中的一类重要技术，通过在模型中添加新的、较小的可训练模块来实现高效微调。这类方法的核心思想是冻结原始模型的参数，仅微调新加入的模块，从而显著减少需要更新的参数量。根据附加参数的位置不同，参数附加方法可以分为三类：加在输入、加在模型以及加在输出。每一类方法都有其独特的实现方式和优势。</p><h4 id=加在输入 class=heading-element><span>加在输入</span>
<a href=#%e5%8a%a0%e5%9c%a8%e8%be%93%e5%85%a5 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>加在输入的方法主要通过在模型的输入嵌入中引入额外的可训练参数来实现微调。最具代表性的方法是 <strong>Prompt-tuning</strong>。Prompt-tuning 在模型的输入中引入可微分的连续张量，通常称为 <strong>软提示（Soft prompt）</strong>。软提示作为输入的一部分，与实际的文本数据一起被送入模型。在微调过程中，仅软提示的参数会被更新，其他参数保持不变，从而实现参数高效微调。</p><p>具体实现步骤如下：</p><ol><li><strong>输入嵌入</strong>：给定一个包含 $ n $ 个 token 的输入文本序列 ${w_1, w_2, \ldots, w_n}$，首先通过嵌入层将其转化为输入嵌入矩阵 $ X \in R^{n \times d} $，其中 $ d $ 是嵌入空间的维度。</li><li><strong>软提示嵌入</strong>：新加入的软提示参数被表示为软提示嵌入矩阵 $ P \in R^{m \times d} $，其中 $ m $ 是软提示长度。</li><li><strong>拼接输入</strong>：将软提示嵌入与输入嵌入矩阵拼接，形成一个新的矩阵 $[P; X] \in R^{(m+n) \times d} $，然后输入到 Transformer 模型中进行处理。</li><li><strong>训练过程</strong>：通过反向传播最大化输出概率似然进行模型训练，仅更新软提示参数 $ P $。</li></ol><p><strong>优势</strong>：</p><ul><li><strong>内存效率高</strong>：Prompt-tuning 显著降低了内存需求。例如，T5-XXL 模型对于特定任务的模型需要 11B 参数，但经过 Prompt-tuning 的模型只需要 20480 个参数（假设软提示长度为 5）。</li><li><strong>多任务能力</strong>：可以使用单一冻结模型进行多任务适应。传统的模型微调需要为每个下游任务学习并保存任务特定的完整预训练模型副本，而 Prompt-tuning 只需要为每个任务存储一个特定的小的任务提示模块。</li><li><strong>缩放特性</strong>：随着模型参数量的增加，Prompt-tuning 的性能会逐渐增强，并且在 10B 参数量下的性能接近全参数微调的性能。</li></ul><h4 id=加在模型 class=heading-element><span>加在模型</span>
<a href=#%e5%8a%a0%e5%9c%a8%e6%a8%a1%e5%9e%8b class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>加在模型的方法通过在预训练模型的隐藏层中插入额外的参数或模块来实现微调。代表性的方法包括 <strong>Prefix-tuning</strong>、<strong>Adapter-tuning</strong> 和 <strong>AdapterFusion</strong>。</p><h5 id=prefix-tuning class=heading-element><span>Prefix-tuning</span>
<a href=#prefix-tuning class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h5><p>Prefix-tuning 与 Prompt-tuning 类似，但它不仅将软提示添加到输入嵌入中，还将一系列连续的可训练前缀（Prefixes，即 Soft-prompt）插入到输入嵌入以及 Transformer 注意力模块中。具体来说，Prefix-tuning 引入了一组可学习的向量 $ P_k $ 和 $ P_v $，这些向量被添加到所有 Transformer 注意力模块中的键 $ K $ 和值 $ V $ 之前。</p><p><strong>优势</strong>：</p><ul><li><strong>参数效率</strong>：只有前缀参数在微调过程中被更新，显著减少了训练参数量。</li><li><strong>任务适应性</strong>：前缀参数可以针对不同的下游任务进行定制，微调方式灵活。</li><li><strong>保持预训练知识</strong>：由于预训练模型的原始参数保持不变，Prefix-tuning 能够保留预训练过程中学到的知识。</li></ul><h5 id=adapter-tuning class=heading-element><span>Adapter-tuning</span>
<a href=#adapter-tuning class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h5><p>Adapter-tuning 向预训练语言模型中插入新的可学习的神经网络模块，称为 <strong>适配器（Adapter）</strong>。适配器模块通常采用瓶颈结构，即一个上投影层、一个非线性映射和一个下投影层组成的全连接模块。适配器被插入到 Transformer 的每一个多头注意力层和全连接层之后。</p><p><strong>优势</strong>：</p><ul><li><strong>参数效率</strong>：适配器模块的参数数量远小于原始模型的参数量，显著减少了微调时的计算和存储需求。</li><li><strong>灵活性</strong>：适配器模块可以设计得更为复杂，例如使用多个投影层或不同的激活函数和参数初始化策略。</li></ul><h5 id=adapterfusion class=heading-element><span>AdapterFusion</span>
<a href=#adapterfusion class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h5><p>AdapterFusion 是一种两阶段学习的方法，先学习多个任务，对每个任务进行知识提取；再“融合”来自多个任务的知识。具体步骤如下：</p><ol><li><strong>知识提取</strong>：对每个任务分别训练适配器模块，用于学习特定任务的知识。</li><li><strong>知识组合</strong>：将不同任务的适配器模块进行融合，以实现知识组合。</li></ol><p><strong>优势</strong>：</p><ul><li><strong>任务泛化</strong>：通过融合多个任务的适配器模块，AdapterFusion 能够实现任务泛化，提升模型在新任务上的表现。</li></ul><h4 id=加在输出 class=heading-element><span>加在输出</span>
<a href=#%e5%8a%a0%e5%9c%a8%e8%be%93%e5%87%ba class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>加在输出的方法主要通过在模型的输出端进行调整来实现微调，代表性的方法是 <strong>代理微调（Proxy-tuning）</strong>。代理微调提供了一种轻量级的解码时算法，允许在不直接修改大语言模型权重的前提下，通过仅访问模型输出词汇表预测分布，来实现对大语言模型的进一步定制化调整。具体来说，代理微调通过计算专家模型和反专家模型之间的 logits 分布差异，然后将其加到代理模型的下一个词预测的 logits 分布中。</p><p><strong>优势</strong>：</p><ul><li><strong>计算成本低</strong>：通过代理微调，可以将较小模型中学习到的知识迁移到更大的模型中，大幅节省了计算成本。</li><li><strong>黑盒模型适用</strong>：由于仅需要获取模型的输出分布，而不需要原始的模型权重，因此该方法对于黑盒模型同样适用。</li></ul><h3 id=参数选择方法 class=heading-element><span>参数选择方法</span>
<a href=#%e5%8f%82%e6%95%b0%e9%80%89%e6%8b%a9%e6%96%b9%e6%b3%95 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p><strong>参数选择方法（Parameter Selection Methods）</strong> 是参数高效微调（PEFT）中的另一类重要技术，其核心思想是 <strong>选择性更新模型中的部分参数</strong>，而冻结其余参数。与参数附加方法不同，参数选择方法不需要向模型添加额外的参数，从而避免了在推理阶段引入额外的计算成本。参数选择方法通常分为两类：<strong>基于规则的方法</strong> 和 <strong>基于学习的方法</strong>。</p><h4 id=基于规则的方法 class=heading-element><span>基于规则的方法</span>
<a href=#%e5%9f%ba%e4%ba%8e%e8%a7%84%e5%88%99%e7%9a%84%e6%96%b9%e6%b3%95 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>基于规则的方法通过人工经验或预定义的规则来选择需要更新的参数。最具代表性的方法是 <strong>BitFit</strong>。</p><h5 id=bitfit class=heading-element><span>BitFit</span>
<a href=#bitfit class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h5><p>BitFit 是一种简单但有效的参数选择方法，它仅优化神经网络中的每一层的 <strong>偏置项（Biases）</strong> 以及任务特定的分类头。由于偏置项在模型总参数中所占比例极小（约 0.08%~0.09%），BitFit 具有极高的参数效率。</p><p><strong>优势</strong>：</p><ul><li><strong>参数效率高</strong>：BitFit 仅微调少量参数，但在 GLUE Benchmark 等任务上表现与全量微调相当，甚至在某些任务上表现更好。</li><li><strong>优化稳定性</strong>：BitFit 允许使用更大的学习率，优化过程更加稳定。</li></ul><p><strong>局限性</strong>：</p><ul><li><strong>小模型验证</strong>：BitFit 目前仅在小模型（如 BERT、RoBERTa 等）上进行了验证，在更大模型上的性能表现尚不明确。</li></ul><h5 id=其他基于规则的方法 class=heading-element><span>其他基于规则的方法</span>
<a href=#%e5%85%b6%e4%bb%96%e5%9f%ba%e4%ba%8e%e8%a7%84%e5%88%99%e7%9a%84%e6%96%b9%e6%b3%95 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h5><p>除了 BitFit，还有一些其他基于规则的方法通过仅微调特定的 Transformer 层来提高参数效率。例如：</p><ul><li><strong>Lee 等人</strong> 提出仅对 BERT 和 RoBERTa 的最后四分之一层进行微调，便能实现全量微调 90% 的性能。</li><li><strong>Pafi</strong> 选择具有最小绝对值的模型参数作为可训练参数。</li></ul><h4 id=基于学习的方法 class=heading-element><span>基于学习的方法</span>
<a href=#%e5%9f%ba%e4%ba%8e%e5%ad%a6%e4%b9%a0%e7%9a%84%e6%96%b9%e6%b3%95 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>基于学习的方法在模型训练过程中 <strong>自动选择可训练的参数子集</strong>。最具代表性的方法是 <strong>Child-tuning</strong>。</p><h5 id=child-tuning class=heading-element><span>Child-tuning</span>
<a href=#child-tuning class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h5><p>Child-tuning 通过梯度掩码矩阵策略实现仅对选中的子网络进行梯度更新，而屏蔽子网络梯度以外的梯度，从而实现对微调参数的选择。具体来说，Child-tuning 引入了一个与模型参数矩阵同维度的 0-1 掩码矩阵 $ M_t $，用于选择每一轮迭代的子网络 $ C_t $，仅更新该子网络的参数。</p><p><strong>变体</strong>：</p><ul><li><strong>Child-tuning$_F$</strong>：任务无关的变体，通过伯努利分布随机生成子网络掩码。</li><li><strong>Child-tuning$_D$</strong>：任务驱动的变体，利用费舍尔信息矩阵（FIM）估计特定任务相关参数的重要性，选择具有最高费舍尔信息的参数作为子网络。</li></ul><p><strong>优势</strong>：</p><ul><li><strong>减少计算负担</strong>：通过梯度屏蔽减少了计算负担，同时减少了模型的假设空间，降低了过拟合的风险。</li><li><strong>任务适应性</strong>：Child-tuning 能够改善大语言模型在多种下游任务中的表现，尤其是在训练数据有限的情况下。</li></ul><p><strong>局限性</strong>：</p><ul><li><strong>计算代价</strong>：子网络的选择需要额外的计算代价，特别是在任务驱动的变体中，费舍尔信息的计算十分耗时。</li></ul><h5 id=其他基于学习的方法 class=heading-element><span>其他基于学习的方法</span>
<a href=#%e5%85%b6%e4%bb%96%e5%9f%ba%e4%ba%8e%e5%ad%a6%e4%b9%a0%e7%9a%84%e6%96%b9%e6%b3%95 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h5><p>除了 Child-tuning，还有一些其他基于学习的参数选择方法：</p><ul><li><strong>FishMask</strong>：使用费舍尔信息来计算掩码，并在每个训练周期动态重新计算。</li><li><strong>LT-SFT</strong>：根据参数重要性，选择在初始微调阶段变化最大的参数子集形成掩码。</li><li><strong>SAM</strong>：通过二阶逼近方法解析求解优化函数，帮助决定参数掩码。</li></ul><h3 id=低秩适配方法 class=heading-element><span>低秩适配方法</span>
<a href=#%e4%bd%8e%e7%a7%a9%e9%80%82%e9%85%8d%e6%96%b9%e6%b3%95 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p><strong>低秩适配方法（Low-rank Adaptation Methods）</strong> 是参数高效微调（PEFT）中的一类重要技术，其核心思想是通过 <strong>低秩矩阵近似原始权重更新矩阵</strong>，并仅微调低秩矩阵，从而大幅减少微调时的参数量和内存开销。低秩适配方法的理论基础是 <strong>低维固有维度假设</strong>，即过参数化模型的固有维度很低，因此可以通过低秩矩阵来近似全参数更新。</p><h4 id=lora class=heading-element><span>LoRA</span>
<a href=#lora class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p><strong>LoRA（Low-Rank Adaptation）</strong> 是最经典的低秩适配方法，它通过将参数更新矩阵分解为两个低秩矩阵来实现高效微调。</p><h5 id=方法实现 class=heading-element><span>方法实现</span>
<a href=#%e6%96%b9%e6%b3%95%e5%ae%9e%e7%8e%b0 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h5><ol><li><strong>参数分解</strong>：给定一个密集神经网络层，其参数矩阵为 $ W_0 \in R^{d \times k} $，LoRA 将参数更新矩阵 $ \Delta W $ 分解为两个低秩矩阵 $ B \in R^{d \times r} $ 和 $ A \in R^{r \times k} $，其中 $ r \ll \min\{d, k\} $。</li><li><strong>更新公式</strong>：更新后的权重矩阵为：
$
W = W_0 + \alpha BA
$
其中，$ \alpha $ 是缩放因子，用于控制 LoRA 权重的大小。</li><li><strong>训练过程</strong>：在训练过程中，固定预训练模型的参数，仅微调 $ B $ 和 $ A $ 的参数。</li></ol><p><strong>优势</strong>：</p><ul><li><strong>参数效率高</strong>：LoRA 仅微调部分低秩参数，显著减少了训练参数量。例如，在 LLaMA2-7B 模型中，LoRA 微调的参数量不到全量微调的千分之一。</li><li><strong>推理延迟低</strong>：LoRA 不会增加推理延迟，且具有可插拔性，训练后可以将 LoRA 参数与模型参数分离。</li><li><strong>任务泛化能力强</strong>：LoRA 插件可以组合使用，实现跨任务泛化。</li></ul><h5 id=参数效率分析 class=heading-element><span>参数效率分析</span>
<a href=#%e5%8f%82%e6%95%b0%e6%95%88%e7%8e%87%e5%88%86%e6%9e%90 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h5><ul><li><strong>内存使用</strong>：LoRA 显著减少了显存使用。例如，在 LLaMA2-7B 模型上，全量微调需要约 60GB 显存，而 LoRA 仅需约 23GB 显存。</li><li><strong>训练速度</strong>：由于涉及到的参数计算减少，LoRA 的反向传播速度比全量微调快 1.9 倍。</li></ul><h4 id=lora-相关变体 class=heading-element><span>LoRA 相关变体</span>
<a href=#lora-%e7%9b%b8%e5%85%b3%e5%8f%98%e4%bd%93 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>尽管 LoRA 在许多下游任务上表现良好，但在复杂任务（如数学推理）上，LoRA 与全量微调之间仍存在性能差距。为了弥补这一差距，许多 LoRA 变体被提出，主要从以下三个角度进行改进：</p><ol><li>打破低秩瓶颈：LoRA 的低秩更新特性限制了模型记忆新知识和适应复杂任务的能力。一些方法通过增加 LoRA 的秩或引入高秩更新机制来打破低秩瓶颈。<ul><li><strong>ReLoRA</strong>：通过周期性地将 LoRA 模块合并到大语言模型中，并重新初始化 LoRA 模块和优化器状态，允许模型通过多次低秩更新累积成高秩状态。</li></ul></li><li>动态秩分配：不同层的权重重要性可能不同，因此需要为每个层分配不同的秩。<ul><li><strong>AdaLoRA</strong>：通过奇异值分解（SVD）动态调整不同层中 LoRA 模块的秩，并根据梯度权重乘积大小的移动平均值构造奇异值的重要性得分，对不重要的奇异值进行剪枝。</li></ul></li><li>训练过程优化：LoRA 的收敛速度较慢，且对超参数敏感，容易过拟合。一些方法通过优化训练过程来提升 LoRA 的性能。<ul><li><strong>DoRA</strong>：将预训练权重分解为方向和大小两个组件，并仅对方向组件施加 LoRA 进行参数化，以增强训练稳定性。</li></ul></li></ol><h4 id=基于-lora-插件的任务泛化 class=heading-element><span>基于 LoRA 插件的任务泛化</span>
<a href=#%e5%9f%ba%e4%ba%8e-lora-%e6%8f%92%e4%bb%b6%e7%9a%84%e4%bb%bb%e5%8a%a1%e6%b3%9b%e5%8c%96 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>LoRA 的可插拔特性使其能够封装为插件，用于多任务学习和任务泛化。它是一个多 LoRA 组合的框架，通过将已学习的 LoRA 模块进行加权组合，实现跨任务泛化。具体步骤如下：</p><ol><li><strong>组合阶段</strong>：将多个 LoRA 模块通过逐元素线性加权组合为单一模块：
$
\hat{m} = (w_1A_1 + w_2A_2 + \cdots + w_NA_N) (w_1B_1 + w_2B_2 + \cdots + w_NB_N)
$
其中，$ w_i $ 是第 $ i $ 个 LoRA 模块的权重。</li><li><strong>适应阶段</strong>：通过无梯度方法（如 Shiwa）自适应地学习权重组合，以完成对新任务的适应。</li></ol><p><strong>优势</strong>：</p><ul><li><strong>任务泛化能力强</strong>：LoRAHub 能够将多个任务的能力迁移到新任务上，提供了一种高效的跨任务学习范式。</li></ul><h3 id=实践与应用 class=heading-element><span>实践与应用</span>
<a href=#%e5%ae%9e%e8%b7%b5%e4%b8%8e%e5%ba%94%e7%94%a8 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p><strong>参数高效微调（PEFT）</strong> 技术在实际应用中展现了强大的潜力，尤其是在资源受限的环境下，能够显著提升大语言模型在特定任务上的性能。本节将介绍 PEFT 的实践框架及其在不同垂直领域中的应用案例。</p><h4 id=peft-实践 class=heading-element><span>PEFT 实践</span>
<a href=#peft-%e5%ae%9e%e8%b7%b5 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>在实际应用中，PEFT 技术的实施和优化至关重要。本小节将详细介绍 PEFT 的主流框架、使用方法及相关技巧。</p><h5 id=peft-主流框架 class=heading-element><span>PEFT 主流框架</span>
<a href=#peft-%e4%b8%bb%e6%b5%81%e6%a1%86%e6%9e%b6 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h5><p>目前最流行的 PEFT 框架是由 Hugging Face 开发的开源库 <strong>HF-PEFT</strong>，它集成了多种先进的微调技术，如 LoRA、Adapter-tuning、Prompt-tuning 和 IA3 等。</p><p><strong>HF-PEFT 的优势</strong>：</p><ul><li><strong>高效灵活性</strong>：支持与 Hugging Face 的其他工具（如 Transformers、Diffusers 和 Accelerate）无缝集成，适用于从单机到分布式环境的多样化训练和推理场景。</li><li><strong>易用性</strong>：提供了详细的文档、快速入门指南和示例代码，帮助用户快速上手。</li><li><strong>社区支持</strong>：拥有活跃的社区支持，鼓励用户贡献代码和改进。</li></ul><h5 id=hf-peft-框架使用 class=heading-element><span>HF-PEFT 框架使用</span>
<a href=#hf-peft-%e6%a1%86%e6%9e%b6%e4%bd%bf%e7%94%a8 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h5><p>使用 HF-PEFT 框架进行模型微调的步骤如下：</p><ol><li><strong>安装与配置</strong>：首先安装 HF-PEFT 框架及其依赖项（主要是 Hugging Face 的 Transformers 库）。</li><li><strong>选择模型与数据</strong>：根据任务需求，挑选合适的预训练模型，并准备相应的训练数据集。</li><li><strong>确定微调策略</strong>：选择适合任务的微调方法，例如 LoRA 或适配器技术。</li><li><strong>模型准备</strong>：加载预训练模型并为选定的微调方法进行配置，包括任务类型、推理模式、参数值等。</li><li><strong>模型训练</strong>：定义完整的训练流程，包括损失函数、优化器设置，并执行训练，同时可应用数据增强和学习率调度等技术。</li></ol><h5 id=peft-相关技巧 class=heading-element><span>PEFT 相关技巧</span>
<a href=#peft-%e7%9b%b8%e5%85%b3%e6%8a%80%e5%b7%a7 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h5><p>HF-PEFT 提供了多种参数高效微调技术，以下是一些常用的参数设置方法：</p><ul><li><p><strong>Prompt Tuning</strong>：</p><ul><li><code>num_virtual_tokens</code>：表示软提示的长度，通常设置在 10-20 之间。</li><li><code>prompt_tuning_init</code>：表示 prompt 参数的初始化方式，可以选择随机初始化或文本初始化。</li></ul></li><li><p><strong>Prefix Tuning</strong>：</p><ul><li><code>num_virtual_tokens</code>：与 Prompt Tuning 类似，表示构造的 virtual tokens 的数量。</li><li><code>encoder_hidden_size</code>：表示用于 Prefix 编码的多层感知机（MLP）层的大小。</li></ul></li><li><p><strong>LoRA</strong>：</p><ul><li><code>r</code>：秩的大小，通常选择较小的值（如 4、8、16）。</li><li><code>lora_alpha</code>：缩放因子，用于控制 LoRA 权重的大小。</li><li><code>lora_dropout</code>：LoRA 层的 dropout 比率，用于正则化防止过拟合。</li><li><code>target_modules</code>：指定模型中 LoRA 要应用的模块，如注意力机制中的 query、key、value 矩阵。</li></ul></li></ul><h4 id=peft-应用 class=heading-element><span>PEFT 应用</span>
<a href=#peft-%e5%ba%94%e7%94%a8 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>PEFT 技术在多个垂直领域中展现了强大的应用潜力，尤其是在表格数据处理和金融领域的 Text-to-SQL 生成任务中。</p><h5 id=表格数据查询 class=heading-element><span>表格数据查询</span>
<a href=#%e8%a1%a8%e6%a0%bc%e6%95%b0%e6%8d%ae%e6%9f%a5%e8%af%a2 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h5><p>表格数据查询是处理和分析表格数据的关键步骤，通常需要编写复杂的 SQL 代码。为了降低 SQL 编写的门槛，<strong>Text-to-SQL</strong> 技术应运而生，它能够将自然语言文本自动翻译成 SQL 代码。</p><p><strong>FinSQL</strong> 是一个面向金融领域的 Text-to-SQL 框架，其核心思想是通过 PEFT 技术对基座模型进行微调，提升模型在少样本场景下的性能。FinSQL 的框架包括以下三个部分：</p><ol><li><strong>提示构造</strong>：通过不同策略增强原始数据，并构造高效检索器，检索与用户查询相关的表格和字段。</li><li><strong>参数高效微调</strong>：采用 LoRAHub 融合多个 LoRA 模块，提高模型在少样本场景下的性能。</li><li><strong>输出校准</strong>：修正生成 SQL 中的语法错误，并使用 Self-Consistency 方法选择一致性 SQL。</li></ol><p><strong>优势</strong>：</p><ul><li><strong>性能提升</strong>：FinSQL 显著提升了金融领域 Text-to-SQL 任务的准确性和效率。</li><li><strong>复杂查询处理</strong>：FinSQL 在处理复杂金融查询时展现了强大的能力，为金融领域的数据分析和决策支持提供了技术支撑。</li></ul><h5 id=表格数据分析 class=heading-element><span>表格数据分析</span>
<a href=#%e8%a1%a8%e6%a0%bc%e6%95%b0%e6%8d%ae%e5%88%86%e6%9e%90 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h5><p>表格数据的特点（如缺乏局部性、包含多种数据类型）使得传统的深度学习方法难以直接应用。大语言模型的参数中编码了大量先验知识，能够有效弥补表格数据特征不足的问题。</p><p><strong>TabLLM</strong> 是一个基于大语言模型的少样本表格数据分类框架，其核心思想是将表格数据序列化为自然语言字符串，并附上分类问题的简短描述来提示大语言模型。在少样本设置中，TabLLM 使用 LoRA 对模型进行微调，显著提升了模型在表格数据分类任务中的性能。</p><p><strong>优势</strong>：</p><ul><li><strong>少样本学习能力强</strong>：TabLLM 在多个基准数据集上超过了基于深度学习的表格分类基线方法，甚至在少样本设置下超过了梯度提升树等传统基线方法。</li><li><strong>稳健性高</strong>：由于 PEFT 只微调部分参数，TabLLM 在少量数据上进行微调时不易过拟合，性能更加稳健。</li></ul></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="更新于 2025-01-18 21:56:15">更新于 2025.1.18&nbsp;
<a class=git-hash href=https://github.com/czTangt/blog.git/commit/c10f5952ad863435e829f0f6f2cb7c13de30930b rel="external nofollow noopener noreferrer" target=_blank title="commit by czTangt(cz.tangt@gmail.com) c10f5952ad863435e829f0f6f2cb7c13de30930b: add efficient parameter fine-tuning"><i class="fa-solid fa-hashtag fa-fw" aria-hidden=true></i>c10f595</a></span></div><div class=post-info-license><span><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div><div class=post-info-line><div class=post-info-md><span><a href="https://github.com/czTangt/blog.git/blob/main/content/posts%5cAI%5cllm.md?plain=1" title=查看源码 target=_blank rel="external nofollow noopener noreferrer" class=link-to-source>查看源码</a></span><span><a href=https://github.com/czTangt/blog.git/edit/main/content/posts%5cAI%5cllm.md title=编辑此页 target=_blank rel="external nofollow noopener noreferrer" class=link-to-edit>编辑此页</a></span><span><a href="https://github.com/czTangt/blog.git/issues/new?title=[BUG]%20Large+Language+Model&amp;body=%7cField%7cValue%7c%0A%7c-%7c-%7c%0A%7cTitle%7cLarge+Language+Model%7c%0A%7cURL%7chttps://czTangt.github.io/blog/posts/ai/large_language_model/%7c%0A%7cFilename%7chttps://github.com/czTangt/blog.git/blob/main/content/posts%5cAI%5cllm.md?plain=1%7c" title=报告问题 target=_blank rel="external nofollow noopener noreferrer" class=link-to-report>报告问题</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 X" data-sharer=twitter data-url=https://czTangt.github.io/blog/posts/ai/large_language_model/ data-title="Large Language Model" data-hashtags=AI><i class="fa-brands fa-x-twitter fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=https://czTangt.github.io/blog/posts/ai/large_language_model/ data-hashtag=AI><i class="fa-brands fa-facebook-square fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=https://czTangt.github.io/blog/posts/ai/large_language_model/ data-title="Large Language Model"><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/blog/tags/ai/ class=post-tag title="标签 - AI">AI</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/blog/>主页</a></span></section></div><div class=post-nav><a href=/blog/posts/staticanalysis/data-flow-analysis/ class=post-nav-item rel=prev title="03 Data Flow Analysis"><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>03 Data Flow Analysis</a><a href=/blog/posts/config/docker/ class=post-nav-item rel=next title=Docker>Docker<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article><aside class=toc id=toc-auto aria-label=目录><h2 class=toc-title>目录&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden=true></i></h2><div class=toc-content id=toc-content-auto></div></aside></main><footer class=footer><div class=footer-container><div class="footer-line powered order-1">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.136.5"><img class=hugo-icon src=/blog/images/hugo.min.svg alt="Hugo logo"> Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.3.17-30a67c4b"><img class=fixit-icon src=/blog/images/fixit.min.svg alt="FixIt logo"> FixIt</a></div><div class="footer-line copyright order-2" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2024 - 2025</span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class="variant-numeric d-none">0%</span></div></div><a href=https://github.com/czTangt/blog title="View source on GitHub" target=_blank rel="external nofollow" class="github-corner left d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true" width="56" height="56"><path d="M0 0 115 115h15l12 27L250 250V0z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentcolor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4l13.9-13.8C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8z" fill="currentcolor" class="octo-body"/></svg></a><div id=mask></div><noscript><div class=noscript-warning>该网站在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=stylesheet href=/blog/lib/lightgallery/css/lightgallery-bundle.min.css><link rel=preload href=/blog/lib/katex/katex.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/blog/lib/katex/katex.min.css></noscript><link rel=stylesheet href=/blog/lib/cookieconsent/cookieconsent.min.css><script src=/blog/lib/autocomplete/autocomplete.min.js defer></script><script src=/blog/lib/fuse/fuse.min.js defer></script><script src=/blog/lib/lightgallery/lightgallery.min.js defer></script><script src=/blog/lib/lightgallery/plugins/thumbnail/lg-thumbnail.min.js defer></script><script src=/blog/lib/lightgallery/plugins/zoom/lg-zoom.min.js defer></script><script src=/blog/lib/sharer/sharer.min.js async defer></script><script src=/blog/lib/katex/katex.min.js defer></script><script src=/blog/lib/katex/auto-render.min.js defer></script><script src=/blog/lib/katex/mhchem.min.js defer></script><script src=/blog/lib/cookieconsent/cookieconsent.min.js defer></script><script src=/blog/js/codeblock.js defer></script><script src=https://libs.baidu.com/jquery/2.1.4/jquery.min.js defer></script><script>window.config={code:{copyTitle:"复制到剪贴板",editLockTitle:"锁定可编辑代码块",editUnLockTitle:"解锁可编辑代码块",editable:!0,maxShownLines:10},comment:{enable:!1},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验。"},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},lightgallery:!0,math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{distance:100,findAllMatches:!1,fuseIndexURL:"/blog/search.json",highlightTag:"em",ignoreFieldNorm:!1,ignoreLocation:!1,isCaseSensitive:!1,location:0,maxResultLength:10,minMatchCharLength:2,noResultsFound:"没有找到结果",snippetLength:30,threshold:.3,type:"fuse",useExtendedSearch:!1},version:"v0.3.17-30a67c4b"}</script><script src=/blog/js/theme.min.js defer></script></body></html>